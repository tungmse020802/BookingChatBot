{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12460780",
   "metadata": {},
   "source": [
    "# ğŸ¨ Booking Chatbot Demo - AI-Powered NLU\n",
    "\n",
    "## ğŸš€ NÃ¢ng cáº¥p má»›i: LLM-Powered Natural Language Understanding\n",
    "\n",
    "### Kiáº¿n trÃºc AI má»›i:\n",
    "```\n",
    "User â”€â”€â”€â–¶ LLM Intent Detector â”€â”€â”€â–¶ LLM Slot Extractor â”€â”€â”€â–¶ Working Memory\n",
    "               â”‚                          â”‚                        â”‚\n",
    "               â”‚                          â”‚                        â–¼\n",
    "               â”‚                          â”‚                  Ask Missing Info\n",
    "               â”‚                          â–¼                        â”‚\n",
    "               â”‚                   (Context-aware:                 â”‚\n",
    "               â”‚                    xem toÃ n bá»™ há»™i thoáº¡i)         â”‚\n",
    "               â–¼                                                   â–¼\n",
    "        When all slots filled                            LLM Question Generator\n",
    "               â”‚                                          (tÆ° váº¥n tá»± nhiÃªn)\n",
    "               â–¼\n",
    "          Call Real API â”€â”€â”€â–¶ Format response â”€â”€â”€â–¶ User\n",
    "```\n",
    "\n",
    "## âœ¨ TÃ­nh nÄƒng AI nÃ¢ng cao:\n",
    "\n",
    "### ğŸ§  **Intent Detection (LLM-powered)**\n",
    "- Hiá»ƒu ngá»¯ cáº£nh há»™i thoáº¡i (khÃ´ng chá»‰ cÃ¢u hiá»‡n táº¡i)\n",
    "- PhÃ¢n biá»‡t cÃ¢u tráº£ lá»i vs Ã½ Ä‘á»‹nh má»›i\n",
    "- VD: \"20/10\" sau cÃ¢u há»i \"NgÃ y tráº£ phÃ²ng?\" â†’ hiá»ƒu lÃ  tráº£ lá»i, khÃ´ng pháº£i intent má»›i\n",
    "\n",
    "### ğŸ’¬ **Slot Extraction (Context-aware)**\n",
    "- TrÃ­ch xuáº¥t tá»« **toÃ n bá»™ context** há»™i thoáº¡i\n",
    "- Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn:\n",
    "  - \"2 Ä‘Ãªm\" â†’ tÃ­nh checkout tá»« checkin\n",
    "  - \"tuáº§n sau\", \"cuá»‘i tuáº§n nÃ y\" â†’ parse ngÃ y\n",
    "  - \"18-20/10\" â†’ checkin=18/10, checkout=20/10\n",
    "  - \"nguyá»…n vÄƒn a\" (lowercase) â†’ chuáº©n hÃ³a \"Nguyá»…n VÄƒn A\"\n",
    "\n",
    "### ğŸ¯ **Conversational Question Generation**\n",
    "- Sinh cÃ¢u há»i tá»± nhiÃªn theo context\n",
    "- TÆ° váº¥n thÃ´ng minh:\n",
    "  - Khi há»i loáº¡i phÃ²ng â†’ gá»i API láº¥y giÃ¡ thá»±c vÃ  gá»£i Ã½\n",
    "  - VD: \"Em cÃ³ Standard (800k/Ä‘Ãªm), Deluxe (1.2tr/Ä‘Ãªm), anh chá»n loáº¡i nÃ o áº¡?\"\n",
    "- KhÃ´ng há»i láº¡i thÃ´ng tin Ä‘Ã£ cÃ³\n",
    "\n",
    "### ğŸ›¡ï¸ **Fallback Rule-based**\n",
    "- Tá»± Ä‘á»™ng fallback náº¿u khÃ´ng cÃ³ API key\n",
    "- Váº«n hoáº¡t Ä‘á»™ng tá»‘t vá»›i regex matching\n",
    "\n",
    "## ğŸ“‹ HÆ°á»›ng dáº«n sá»­ dá»¥ng:\n",
    "\n",
    "### **Option 1: Cháº¡y vá»›i LLM (Khuyáº¿n nghá»‹)**\n",
    "1. Láº¥y API key miá»…n phÃ­: [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
    "2. VÃ o cell **\"Cáº¥u hÃ¬nh LLM\"**, thÃªm:\n",
    "   ```python\n",
    "   GEMINI_API_KEY = \"your-api-key-here\"\n",
    "   ```\n",
    "3. Cháº¡y láº¡i notebook tá»« Ä‘áº§u (Run All)\n",
    "4. ThÆ°á»Ÿng thá»©c AI thÃ´ng minh! ğŸ‰\n",
    "\n",
    "### **Option 2: Cháº¡y Rule-based (KhÃ´ng cáº§n API key)**\n",
    "- Chá»‰ cáº§n cháº¡y notebook bÃ¬nh thÆ°á»ng\n",
    "- Há»‡ thá»‘ng tá»± Ä‘á»™ng dÃ¹ng regex fallback\n",
    "\n",
    "## ğŸ¨ Demo Gradio:\n",
    "- âœ… Intent Detection (context-aware)\n",
    "- âœ… Slot Filling (hiá»ƒu ngÃ´n ngá»¯ tá»± nhiÃªn)\n",
    "- âœ… Working Memory (lÆ°u tráº¡ng thÃ¡i)\n",
    "- âœ… TÆ° váº¥n thÃ´ng minh (dá»±a trÃªn API thá»±c)\n",
    "- âœ… Real API Integration (`http://103.38.236.148:8080/api/Room`)\n",
    "- âœ… KhÃ´ng bá»‹ vÃ²ng láº·p vÃ´ háº¡n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471c9e5",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ CÃ i Ä‘áº·t thÆ° viá»‡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c72912cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio pydantic requests google-generativeai python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e7985",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Import thÆ° viá»‡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abf951b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… google-generativeai imported successfully\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "# Import Google Generative AI\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GENAI_AVAILABLE = True\n",
    "    print(\"âœ… google-generativeai imported successfully\")\n",
    "except ImportError:\n",
    "    GENAI_AVAILABLE = False\n",
    "    print(\"âš ï¸ google-generativeai not installed. Run: pip install google-generativeai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5819a4",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Äá»‹nh nghÄ©a Schema API (Booking Request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005b4f2",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Äá»‹nh nghÄ©a Schema API (Booking Request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58573956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ Äang káº¿t ná»‘i vá»›i Room API...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Káº¿t ná»‘i API thÃ nh cÃ´ng!\n",
      "ğŸ“Š Tá»•ng sá»‘ phÃ²ng trong há»‡ thá»‘ng: 33\n",
      "\n",
      "ğŸ¨ PhÃ²ng máº«u:\n",
      "  - 101: PhÃ²ng tiÃªu chuáº©n - Trá»‘ng - 800,000.0 VNÄ/Ä‘Ãªm\n",
      "  - 1010: PhÃ²ng tiÃªu chuáº©n - Báº£o trÃ¬ - 800,000.0 VNÄ/Ä‘Ãªm\n",
      "  - 102: PhÃ²ng tiÃªu chuáº©n - Trá»‘ng - 800,000.0 VNÄ/Ä‘Ãªm\n"
     ]
    }
   ],
   "source": [
    "# Cáº¥u hÃ¬nh API\n",
    "API_BASE_URL = \"http://103.38.236.148:8080/api\"\n",
    "\n",
    "class RoomAPIClient:\n",
    "    \"\"\"Client Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i Room API\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = API_BASE_URL):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def get_rooms(self, room_type_id: Optional[int] = None, \n",
    "                  status_id: Optional[int] = None,\n",
    "                  min_price: Optional[float] = None,\n",
    "                  max_price: Optional[float] = None,\n",
    "                  page_index: int = 1,\n",
    "                  page_size: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Láº¥y danh sÃ¡ch phÃ²ng tá»« API\n",
    "        \n",
    "        Parameters:\n",
    "        - room_type_id: 1 = PhÃ²ng tiÃªu chuáº©n, 2 = VIP, 3 = Deluxe, etc.\n",
    "        - status_id: 41 = Trá»‘ng, 42 = ÄÃ£ Ä‘áº·t, 43 = Äang sá»­ dá»¥ng, 45 = Báº£o trÃ¬\n",
    "        \"\"\"\n",
    "        try:\n",
    "            params = {\n",
    "                \"PageIndex\": page_index,\n",
    "                \"PageSize\": page_size\n",
    "            }\n",
    "            \n",
    "            if room_type_id:\n",
    "                params[\"RoomTypeId\"] = room_type_id\n",
    "            if status_id:\n",
    "                params[\"StatusId\"] = status_id\n",
    "            if min_price:\n",
    "                params[\"MinPrice\"] = min_price\n",
    "            if max_price:\n",
    "                params[\"MaxPrice\"] = max_price\n",
    "            \n",
    "            response = self.session.get(\n",
    "                f\"{self.base_url}/Room\",\n",
    "                params=params,\n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get(\"isSuccess\"):\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"data\": data.get(\"data\", {}),\n",
    "                    \"message\": data.get(\"message\", \"\")\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": data.get(\"message\", \"Unknown error\"),\n",
    "                    \"data\": None\n",
    "                }\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"âŒ API Error: {str(e)}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"data\": None\n",
    "            }\n",
    "    \n",
    "    def get_available_rooms(self, room_type_name: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Láº¥y danh sÃ¡ch phÃ²ng trá»‘ng\"\"\"\n",
    "        result = self.get_rooms(status_id=41)  # 41 = Trá»‘ng\n",
    "        \n",
    "        if not result[\"success\"]:\n",
    "            return []\n",
    "        \n",
    "        rooms = result[\"data\"].get(\"items\", [])\n",
    "        \n",
    "        # Lá»c theo loáº¡i phÃ²ng náº¿u cÃ³\n",
    "        if room_type_name:\n",
    "            room_type_map = {\n",
    "                \"VIP\": [\"vip\", \"lux\", \"luxury\", \"suite\"],\n",
    "                \"Deluxe\": [\"deluxe\", \"cao cáº¥p\"],\n",
    "                \"Standard\": [\"standard\", \"tiÃªu chuáº©n\", \"thÆ°á»ng\"]\n",
    "            }\n",
    "            \n",
    "            keywords = room_type_map.get(room_type_name, [room_type_name.lower()])\n",
    "            rooms = [\n",
    "                r for r in rooms \n",
    "                if any(kw in r.get(\"roomTypeName\", \"\").lower() for kw in keywords)\n",
    "            ]\n",
    "        \n",
    "        return rooms\n",
    "    \n",
    "    def get_room_types_mapping(self) -> Dict[str, int]:\n",
    "        \"\"\"Láº¥y mapping giá»¯a tÃªn loáº¡i phÃ²ng vÃ  RoomTypeId\"\"\"\n",
    "        result = self.get_rooms()\n",
    "        \n",
    "        if not result[\"success\"]:\n",
    "            return {}\n",
    "        \n",
    "        rooms = result[\"data\"].get(\"items\", [])\n",
    "        mapping = {}\n",
    "        \n",
    "        for room in rooms:\n",
    "            type_name = room.get(\"roomTypeName\", \"\")\n",
    "            type_id = room.get(\"roomTypeId\")\n",
    "            \n",
    "            if type_name and type_id and type_name not in mapping:\n",
    "                mapping[type_name] = type_id\n",
    "        \n",
    "        return mapping\n",
    "\n",
    "# Khá»Ÿi táº¡o API Client\n",
    "api_client = RoomAPIClient()\n",
    "\n",
    "# Test API connection\n",
    "print(\"ğŸ”Œ Äang káº¿t ná»‘i vá»›i Room API...\")\n",
    "test_result = api_client.get_rooms(page_size=5)\n",
    "\n",
    "if test_result[\"success\"]:\n",
    "    total_rooms = test_result[\"data\"].get(\"totalRecords\", 0)\n",
    "    print(f\"âœ… Káº¿t ná»‘i API thÃ nh cÃ´ng!\")\n",
    "    print(f\"ğŸ“Š Tá»•ng sá»‘ phÃ²ng trong há»‡ thá»‘ng: {total_rooms}\")\n",
    "    \n",
    "    # Hiá»ƒn thá»‹ má»™t vÃ i phÃ²ng máº«u\n",
    "    sample_rooms = test_result[\"data\"].get(\"items\", [])[:3]\n",
    "    print(f\"\\nğŸ¨ PhÃ²ng máº«u:\")\n",
    "    for room in sample_rooms:\n",
    "        print(f\"  - {room['roomNumber']}: {room['roomTypeName']} - {room['statusName']} - {room['basePriceNight']:,} VNÄ/Ä‘Ãªm\")\n",
    "else:\n",
    "    print(f\"âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i API: {test_result['error']}\")\n",
    "    print(\"âš ï¸ Há»‡ thá»‘ng sáº½ sá»­ dá»¥ng dá»¯ liá»‡u mock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adaf9ec",
   "metadata": {},
   "source": [
    "# ============== Intent Detection (LLM-powered + fallback) ==============\n",
    "\n",
    "def detect_intent_llm(text: str, conversation_history: List = None) -> str:\n",
    "    \"\"\"\n",
    "    Sá»­ dá»¥ng LLM Ä‘á»ƒ phÃ¡t hiá»‡n Ã½ Ä‘á»‹nh dá»±a trÃªn ngá»¯ cáº£nh há»™i thoáº¡i\n",
    "    Returns: 'book_room', 'cancel', 'check_booking', 'unknown'\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        return None\n",
    "    \n",
    "    # Táº¡o context tá»« lá»‹ch sá»­ há»™i thoáº¡i\n",
    "    context = \"\"\n",
    "    if conversation_history:\n",
    "        recent = conversation_history[-3:]  # 3 turns gáº§n nháº¥t\n",
    "        for role, msg in recent:\n",
    "            context += f\"{role.upper()}: {msg}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"Báº¡n lÃ  trá»£ lÃ½ phÃ¢n loáº¡i Ã½ Ä‘á»‹nh (intent) trong há»‡ thá»‘ng Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n.\n",
    "\n",
    "Lá»‹ch sá»­ há»™i thoáº¡i:\n",
    "{context}\n",
    "\n",
    "CÃ¢u má»›i nháº¥t tá»« khÃ¡ch hÃ ng: \"{text}\"\n",
    "\n",
    "PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh thÃ nh Má»˜T trong cÃ¡c loáº¡i sau:\n",
    "- book_room: KhÃ¡ch muá»‘n Ä‘áº·t phÃ²ng, book phÃ²ng, reserve phÃ²ng\n",
    "- cancel: KhÃ¡ch muá»‘n há»§y Ä‘áº·t phÃ²ng\n",
    "- check_booking: KhÃ¡ch muá»‘n kiá»ƒm tra, xem thÃ´ng tin Ä‘áº·t phÃ²ng\n",
    "- unknown: KhÃ´ng rÃµ Ã½ Ä‘á»‹nh hoáº·c chá»‰ lÃ  cÃ¢u tráº£ lá»i cho cÃ¢u há»i trÆ°á»›c\n",
    "\n",
    "Tráº£ lá»i chá»‰ Má»˜T tá»«: book_room / cancel / check_booking / unknown\"\"\"\n",
    "\n",
    "    result = call_llm(prompt, temperature=0.1, max_tokens=50)\n",
    "    if result:\n",
    "        result = result.lower().strip()\n",
    "        for intent in [\"book_room\", \"cancel\", \"check_booking\", \"unknown\"]:\n",
    "            if intent in result:\n",
    "                return intent\n",
    "    return None\n",
    "\n",
    "def detect_intent_rule_based(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Fallback: phÃ¡t hiá»‡n Ã½ Ä‘á»‹nh báº±ng keyword matching\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Intent: Äáº·t phÃ²ng\n",
    "    booking_keywords = [\"Ä‘áº·t\", \"book\", \"reserve\", \"muá»‘n Ä‘áº·t\", \"Ä‘áº·t phÃ²ng\", \"booking\"]\n",
    "    if any(keyword in text_lower for keyword in booking_keywords):\n",
    "        return \"book_room\"\n",
    "    \n",
    "    # Intent: Há»§y Ä‘áº·t phÃ²ng\n",
    "    cancel_keywords = [\"há»§y\", \"huá»·\", \"cancel\"]\n",
    "    if any(keyword in text_lower for keyword in cancel_keywords):\n",
    "        return \"cancel\"\n",
    "    \n",
    "    # Intent: Kiá»ƒm tra booking\n",
    "    check_keywords = [\"kiá»ƒm tra\", \"check\", \"xem Ä‘áº·t phÃ²ng\"]\n",
    "    if any(keyword in text_lower for keyword in check_keywords):\n",
    "        return \"check_booking\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "def detect_intent(text: str, conversation_history: List = None) -> str:\n",
    "    \"\"\"\n",
    "    PhÃ¡t hiá»‡n Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng (LLM-first vá»›i fallback)\n",
    "    \"\"\"\n",
    "    # Try LLM first\n",
    "    intent = detect_intent_llm(text, conversation_history)\n",
    "    \n",
    "    # Fallback to rule-based\n",
    "    if not intent:\n",
    "        intent = detect_intent_rule_based(text)\n",
    "    \n",
    "    return intent\n",
    "\n",
    "# Test Intent Detector\n",
    "print(\"ğŸ§ª Test Intent Detector (LLM-powered):\")\n",
    "test_cases = [\n",
    "    (\"TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP\", None),\n",
    "    (\"Há»§y Ä‘áº·t phÃ²ng giÃºp tÃ´i\", None),\n",
    "    (\"Kiá»ƒm tra booking cá»§a tÃ´i\", None),\n",
    "    (\"20/10\", [(\"bot\", \"NgÃ y tráº£ phÃ²ng lÃ  ngÃ y nÃ o áº¡?\")]),  # Context-aware\n",
    "]\n",
    "for text, history in test_cases:\n",
    "    intent = detect_intent(text, history)\n",
    "    mode = \"LLM\" if LLM_ENABLED else \"Rule\"\n",
    "    print(f\"  [{mode}] '{text}' â†’ {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de09761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Schema Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a\n",
      "CÃ¡c slot báº¯t buá»™c: ['city', 'checkin', 'checkout', 'room_type', 'guest_name']\n"
     ]
    }
   ],
   "source": [
    "class BookingRequest(BaseModel):\n",
    "    \"\"\"Schema cho yÃªu cáº§u Ä‘áº·t phÃ²ng\"\"\"\n",
    "    city: Optional[str] = Field(None, description=\"ThÃ nh phá»‘\")\n",
    "    checkin: Optional[str] = Field(None, description=\"NgÃ y nháº­n phÃ²ng\")\n",
    "    checkout: Optional[str] = Field(None, description=\"NgÃ y tráº£ phÃ²ng\")\n",
    "    room_type: Optional[str] = Field(None, description=\"Loáº¡i phÃ²ng (VIP/Standard/Deluxe)\")\n",
    "    guest_name: Optional[str] = Field(None, description=\"TÃªn ngÆ°á»i Ä‘áº·t\")\n",
    "    contact: Optional[str] = Field(None, description=\"Sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email\")\n",
    "    \n",
    "    # ThÃ´ng tin bá»• sung tá»« API\n",
    "    room_id: Optional[int] = Field(None, description=\"ID phÃ²ng Ä‘Æ°á»£c chá»n\")\n",
    "    room_number: Optional[str] = Field(None, description=\"Sá»‘ phÃ²ng\")\n",
    "    price_per_night: Optional[float] = Field(None, description=\"GiÃ¡ phÃ²ng/Ä‘Ãªm\")\n",
    "\n",
    "# CÃ¡c slot báº¯t buá»™c pháº£i cÃ³\n",
    "REQUIRED_SLOTS = [\"city\", \"checkin\", \"checkout\", \"room_type\", \"guest_name\"]\n",
    "\n",
    "print(\"âœ… Schema Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a\")\n",
    "print(f\"CÃ¡c slot báº¯t buá»™c: {REQUIRED_SLOTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009cc65",
   "metadata": {},
   "source": [
    "# ============== Slot Extraction (LLM-powered + fallback) ==============\n",
    "\n",
    "def extract_slots_llm(text: str, current_slots: Dict, conversation_history: List = None, expected_slot: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Sá»­ dá»¥ng LLM Ä‘á»ƒ trÃ­ch xuáº¥t slots tá»« ngá»¯ cáº£nh tá»± nhiÃªn\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        return None\n",
    "    \n",
    "    # Context tá»« lá»‹ch sá»­\n",
    "    context = \"\"\n",
    "    if conversation_history:\n",
    "        recent = conversation_history[-5:]\n",
    "        for role, msg in recent:\n",
    "            context += f\"{role.upper()}: {msg}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"Báº¡n lÃ  trá»£ lÃ½ trÃ­ch xuáº¥t thÃ´ng tin Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n tá»« há»™i thoáº¡i tiáº¿ng Viá»‡t.\n",
    "\n",
    "Lá»‹ch sá»­ há»™i thoáº¡i:\n",
    "{context}\n",
    "\n",
    "CÃ¢u má»›i nháº¥t: \"{text}\"\n",
    "\n",
    "ThÃ´ng tin hiá»‡n cÃ³:\n",
    "{json.dumps(current_slots, ensure_ascii=False, indent=2)}\n",
    "\n",
    "{\"Bot vá»«a há»i vá»: \" + expected_slot if expected_slot else \"\"}\n",
    "\n",
    "TrÃ­ch xuáº¥t cÃ¡c thÃ´ng tin sau (giá»¯ nguyÃªn giÃ¡ trá»‹ cÅ© náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin má»›i):\n",
    "- city: ThÃ nh phá»‘ (vÃ­ dá»¥: \"ÄÃ  Láº¡t\", \"HÃ  Ná»™i\", \"TP HCM\")\n",
    "- checkin: NgÃ y nháº­n phÃ²ng (format: dd/mm hoáº·c dd/mm/yyyy)\n",
    "- checkout: NgÃ y tráº£ phÃ²ng (format: dd/mm hoáº·c dd/mm/yyyy)\n",
    "- room_type: Loáº¡i phÃ²ng (\"Standard\", \"VIP\", \"Deluxe\")\n",
    "- guest_name: TÃªn khÃ¡ch hÃ ng (há» tÃªn Ä‘áº§y Ä‘á»§)\n",
    "- contact: Sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email\n",
    "\n",
    "LÆ°u Ã½ Ä‘áº·c biá»‡t:\n",
    "- Náº¿u chá»‰ cÃ³ 1 ngÃ y vÃ  checkin Ä‘Ã£ cÃ³ â†’ gÃ¡n vÃ o checkout\n",
    "- Náº¿u cÃ³ cá»¥m \"18-20/10\" hoáº·c \"tá»« 18 Ä‘áº¿n 20/10\" â†’ checkin=18/10, checkout=20/10\n",
    "- Náº¿u nÃ³i \"2 Ä‘Ãªm\" hoáº·c \"3 ngÃ y\" â†’ tÃ­nh checkout tá»« checkin\n",
    "- Cháº¥p nháº­n tÃªn viáº¿t thÆ°á»ng hoáº·c hoa (chuáº©n hÃ³a vá» Title Case)\n",
    "- Room type: map \"tiÃªu chuáº©n\"â†’\"Standard\", \"cao cáº¥p\"â†’\"Deluxe\", \"vip/suite\"â†’\"VIP\"\n",
    "\n",
    "Tráº£ vá» JSON vá»›i cÃ¡c key trÃªn (null náº¿u khÃ´ng cÃ³):\n",
    "```json\n",
    "{{\n",
    "  \"city\": \"...\",\n",
    "  \"checkin\": \"...\",\n",
    "  \"checkout\": \"...\",\n",
    "  \"room_type\": \"...\",\n",
    "  \"guest_name\": \"...\",\n",
    "  \"contact\": \"...\"\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "    result = call_llm_json(prompt)\n",
    "    if result:\n",
    "        # Merge vá»›i current_slots (giá»¯ giÃ¡ trá»‹ cÅ© náº¿u LLM tráº£ vá» null)\n",
    "        for key in [\"city\", \"checkin\", \"checkout\", \"room_type\", \"guest_name\", \"contact\"]:\n",
    "            if result.get(key):\n",
    "                current_slots[key] = result[key]\n",
    "        return current_slots\n",
    "    return None\n",
    "\n",
    "def extract_slots_from_text(text: str, current: BookingRequest) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    Fallback: TrÃ­ch xuáº¥t thÃ´ng tin báº±ng regex (rule-based)\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 1. TrÃ­ch xuáº¥t ThÃ nh phá»‘\n",
    "    if not current.city:\n",
    "        city_patterns = [\n",
    "            r\"á»Ÿ\\s+([A-Za-zÃ€-á»¹\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"táº¡i\\s+([A-Za-zÃ€-á»¹\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"(HÃ  Ná»™i|ÄÃ  Láº¡t|SÃ i GÃ²n|TP HCM|ÄÃ  Náºµng|Nha Trang|PhÃº Quá»‘c|VÅ©ng TÃ u|Há»™i An)\"\n",
    "        ]\n",
    "        for pattern in city_patterns:\n",
    "            match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                city = match.group(1).strip()\n",
    "                if len(city) <= 40:\n",
    "                    current.city = city\n",
    "                    break\n",
    "    \n",
    "    # 2. TrÃ­ch xuáº¥t NgÃ y\n",
    "    range_match = re.search(r\"(\\d{1,2})\\s*[â€“â€”-]\\s*(\\d{1,2})[/\\-](\\d{1,2})\", text)\n",
    "    if range_match and not current.checkin:\n",
    "        day1, day2, month = range_match.groups()\n",
    "        current.checkin = f\"{day1}/{month}\"\n",
    "        current.checkout = f\"{day2}/{month}\"\n",
    "    else:\n",
    "        dates = re.findall(r\"(\\d{1,2}[/\\-]\\d{1,2}(?:[/\\-]\\d{2,4})?)\", text)\n",
    "        if dates:\n",
    "            if len(dates) == 1:\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                elif not current.checkout:\n",
    "                    # Náº¿u Ä‘Ã£ cÃ³ checkin, gÃ¡n vÃ o checkout\n",
    "                    current.checkout = dates[0]\n",
    "            else:\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                if not current.checkout:\n",
    "                    current.checkout = dates[1]\n",
    "    \n",
    "    # 3. Loáº¡i phÃ²ng\n",
    "    if not current.room_type:\n",
    "        room_patterns = {\n",
    "            \"VIP\": r\"\\b(vip|lux|luxury|suite)\\b\",\n",
    "            \"Deluxe\": r\"\\b(deluxe|cao cáº¥p)\\b\",\n",
    "            \"Standard\": r\"\\b(standard|normal|thÆ°á»ng|tiÃªu chuáº©n)\\b\"\n",
    "        }\n",
    "        for room_type, pattern in room_patterns.items():\n",
    "            if re.search(pattern, text, flags=re.IGNORECASE):\n",
    "                current.room_type = room_type\n",
    "                break\n",
    "    \n",
    "    # 4. TÃªn khÃ¡ch\n",
    "    if not current.guest_name:\n",
    "        name_patterns = [\n",
    "            r\"tÃªn lÃ \\s+([A-ZÃ€-á»¸][A-Za-zÃ€-á»¹\\s]{1,40})\",\n",
    "            r\"tÃªn\\s+([A-ZÃ€-á»¸][A-Za-zÃ€-á»¹\\s]{1,40})\",\n",
    "            r\"lÃ \\s+([A-ZÃ€-á»¸][A-Za-zÃ€-á»¹\\s]{2,40})$\",\n",
    "            r\"^([A-ZÃ€-á»¸][a-zÃ -á»¹]+(?:\\s+[A-ZÃ€-á»¸][a-zÃ -á»¹]+)+)$\"\n",
    "        ]\n",
    "        for pattern in name_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                name = match.group(1).strip()\n",
    "                if len(name.split()) >= 2 and not any(char.isdigit() for char in name):\n",
    "                    current.guest_name = name\n",
    "                    break\n",
    "    \n",
    "    # 5. Contact\n",
    "    if not current.contact:\n",
    "        email_match = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\", text)\n",
    "        if email_match:\n",
    "            current.contact = email_match.group(0)\n",
    "        else:\n",
    "            phone_match = re.search(r\"(\\+?84|0)\\s*[\\d\\-\\s]{8,12}\", text)\n",
    "            if phone_match:\n",
    "                current.contact = phone_match.group(0)\n",
    "    \n",
    "    return current\n",
    "\n",
    "def extract_slots(text: str, current: BookingRequest, conversation_history: List = None, expected_slot: str = None) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    TrÃ­ch xuáº¥t slots (LLM-first vá»›i fallback)\n",
    "    \"\"\"\n",
    "    current_dict = current.dict()\n",
    "    \n",
    "    # Try LLM first\n",
    "    llm_result = extract_slots_llm(text, current_dict, conversation_history, expected_slot)\n",
    "    \n",
    "    if llm_result:\n",
    "        # Update BookingRequest vá»›i káº¿t quáº£ tá»« LLM\n",
    "        for key, value in llm_result.items():\n",
    "            if value and hasattr(current, key):\n",
    "                setattr(current, key, value)\n",
    "        return current\n",
    "    \n",
    "    # Fallback to rule-based\n",
    "    return extract_slots_from_text(text, current)\n",
    "\n",
    "# Test Slot Filler\n",
    "print(\"ğŸ§ª Test Slot Filler (LLM-powered):\")\n",
    "test_booking = BookingRequest()\n",
    "test_text = \"TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP á»Ÿ ÄÃ  Láº¡t ngÃ y 18â€“20/10 cho Nguyá»…n VÄƒn A\"\n",
    "result = extract_slots(test_text, test_booking)\n",
    "mode = \"LLM\" if LLM_ENABLED else \"Rule\"\n",
    "print(f\"  [{mode}] Input: '{test_text}'\")\n",
    "print(f\"  Extracted: {json.dumps(result.dict(), indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1e4c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test Intent Detector:\n",
      "  'TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP' â†’ Intent: book_room\n",
      "  'Há»§y Ä‘áº·t phÃ²ng giÃºp tÃ´i' â†’ Intent: book_room\n",
      "  'Kiá»ƒm tra booking cá»§a tÃ´i' â†’ Intent: book_room\n",
      "  'Xin chÃ o' â†’ Intent: unknown\n"
     ]
    }
   ],
   "source": [
    "def detect_intent(text: str) -> str:\n",
    "    \"\"\"\n",
    "    PhÃ¡t hiá»‡n Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng\n",
    "    Returns: 'book_room', 'cancel', 'check_booking', 'unknown'\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Intent: Äáº·t phÃ²ng\n",
    "    booking_keywords = [\"Ä‘áº·t\", \"book\", \"reserve\", \"muá»‘n Ä‘áº·t\", \"Ä‘áº·t phÃ²ng\", \"booking\"]\n",
    "    if any(keyword in text_lower for keyword in booking_keywords):\n",
    "        return \"book_room\"\n",
    "    \n",
    "    # Intent: Há»§y Ä‘áº·t phÃ²ng\n",
    "    cancel_keywords = [\"há»§y\", \"huá»·\", \"cancel\"]\n",
    "    if any(keyword in text_lower for keyword in cancel_keywords):\n",
    "        return \"cancel\"\n",
    "    \n",
    "    # Intent: Kiá»ƒm tra booking\n",
    "    check_keywords = [\"kiá»ƒm tra\", \"check\", \"xem Ä‘áº·t phÃ²ng\"]\n",
    "    if any(keyword in text_lower for keyword in check_keywords):\n",
    "        return \"check_booking\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "# Test Intent Detector\n",
    "print(\"ğŸ§ª Test Intent Detector:\")\n",
    "test_cases = [\n",
    "    \"TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP\",\n",
    "    \"Há»§y Ä‘áº·t phÃ²ng giÃºp tÃ´i\",\n",
    "    \"Kiá»ƒm tra booking cá»§a tÃ´i\",\n",
    "    \"Xin chÃ o\"\n",
    "]\n",
    "for text in test_cases:\n",
    "    intent = detect_intent(text)\n",
    "    print(f\"  '{text}' â†’ Intent: {intent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba69490",
   "metadata": {},
   "source": [
    "# ============== Working Memory & Question Generation ==============\n",
    "\n",
    "# CÃ¢u há»i fallback cho tá»«ng slot\n",
    "SLOT_QUESTIONS = {\n",
    "    \"city\": \"Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?\",\n",
    "    \"checkin\": \"NgÃ y nháº­n phÃ²ng lÃ  ngÃ y nÃ o áº¡? (VD: 18/10 hoáº·c 18-10-2025)\",\n",
    "    \"checkout\": \"NgÃ y tráº£ phÃ²ng lÃ  ngÃ y nÃ o áº¡?\",\n",
    "    \"room_type\": \"Anh/chá»‹ muá»‘n Ä‘áº·t loáº¡i phÃ²ng nÃ o? (VIP/Deluxe/Standard)\",\n",
    "    \"guest_name\": \"Cho em xin tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng áº¡?\",\n",
    "    \"contact\": \"Cho em xin sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email Ä‘á»ƒ liÃªn há»‡ Ä‘Æ°á»£c khÃ´ng áº¡?\"\n",
    "}\n",
    "\n",
    "def init_memory() -> Dict[str, Any]:\n",
    "    \"\"\"Khá»Ÿi táº¡o Working Memory\"\"\"\n",
    "    return {\n",
    "        \"intent\": None,\n",
    "        \"slots\": BookingRequest().dict(),\n",
    "        \"conversation_history\": [],\n",
    "        \"expected_slot\": None,\n",
    "        \"asked_slots\": set(),\n",
    "        \"last_bot_question\": None\n",
    "    }\n",
    "\n",
    "def next_missing_slot(booking: BookingRequest) -> Optional[str]:\n",
    "    \"\"\"TÃ¬m slot tiáº¿p theo cÃ²n thiáº¿u\"\"\"\n",
    "    for slot in REQUIRED_SLOTS:\n",
    "        value = getattr(booking, slot)\n",
    "        if value is None or value == \"\":\n",
    "            return slot\n",
    "    if not booking.contact:\n",
    "        return \"contact\"\n",
    "    return None\n",
    "\n",
    "def build_booking_object(memory: Dict) -> BookingRequest:\n",
    "    \"\"\"XÃ¢y dá»±ng BookingRequest tá»« memory\"\"\"\n",
    "    return BookingRequest(**memory[\"slots\"])\n",
    "\n",
    "def update_memory_with_extracted(memory: Dict, text: str) -> Dict:\n",
    "    \"\"\"Cáº­p nháº­t memory vá»›i thÃ´ng tin má»›i (LLM-powered)\"\"\"\n",
    "    current_booking = BookingRequest(**memory[\"slots\"])\n",
    "    updated_booking = extract_slots(\n",
    "        text, \n",
    "        current_booking,\n",
    "        conversation_history=memory.get(\"conversation_history\"),\n",
    "        expected_slot=memory.get(\"expected_slot\")\n",
    "    )\n",
    "    memory[\"slots\"] = updated_booking.dict()\n",
    "    return memory\n",
    "\n",
    "def generate_question_llm(missing_slot: str, current_slots: Dict, conversation_history: List) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Sinh cÃ¢u há»i tá»± nhiÃªn báº±ng LLM dá»±a trÃªn ngá»¯ cáº£nh\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        return None\n",
    "    \n",
    "    # Láº¥y thÃ´ng tin phÃ²ng tá»« API náº¿u Ä‘ang há»i room_type\n",
    "    room_info = \"\"\n",
    "    if missing_slot == \"room_type\":\n",
    "        try:\n",
    "            result = api_client.get_rooms(page_size=50)\n",
    "            if result[\"success\"]:\n",
    "                items = result[\"data\"].get(\"items\", [])\n",
    "                prices = {}\n",
    "                for r in items:\n",
    "                    name = (r.get(\"roomTypeName\") or \"\").strip()\n",
    "                    price = r.get(\"basePriceNight\") or 0\n",
    "                    if name:\n",
    "                        prices[name] = min(prices.get(name, 10**12), price)\n",
    "                if prices:\n",
    "                    room_info = \"\\\\n\".join([f\"- {n}: {p:,} VNÄ/Ä‘Ãªm\" for n, p in sorted(prices.items(), key=lambda x: x[1])])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    context = \"\"\n",
    "    if conversation_history:\n",
    "        recent = conversation_history[-3:]\n",
    "        for role, msg in recent:\n",
    "            context += f\"{role.upper()}: {msg}\\\\n\"\n",
    "    \n",
    "    slot_desc = {\n",
    "        \"city\": \"thÃ nh phá»‘ Ä‘áº·t phÃ²ng\",\n",
    "        \"checkin\": \"ngÃ y nháº­n phÃ²ng (check-in)\",\n",
    "        \"checkout\": \"ngÃ y tráº£ phÃ²ng (check-out)\",\n",
    "        \"room_type\": \"loáº¡i phÃ²ng (Standard/VIP/Deluxe)\",\n",
    "        \"guest_name\": \"tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng\",\n",
    "        \"contact\": \"sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email liÃªn há»‡\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"Báº¡n lÃ  receptionist chuyÃªn nghiá»‡p táº¡i khÃ¡ch sáº¡n, Ä‘ang tÆ° váº¥n Ä‘áº·t phÃ²ng.\n",
    "\n",
    "Lá»‹ch sá»­ há»™i thoáº¡i:\n",
    "{context}\n",
    "\n",
    "ThÃ´ng tin Ä‘Ã£ cÃ³:\n",
    "{json.dumps({k: v for k, v in current_slots.items() if v}, ensure_ascii=False)}\n",
    "\n",
    "Báº¡n cáº§n há»i khÃ¡ch vá»: {slot_desc.get(missing_slot, missing_slot)}\n",
    "\n",
    "{f\"ThÃ´ng tin cÃ¡c loáº¡i phÃ²ng hiá»‡n cÃ³:\\\\n{room_info}\" if room_info else \"\"}\n",
    "\n",
    "HÃ£y táº¡o Má»˜T cÃ¢u há»i tá»± nhiÃªn, thÃ¢n thiá»‡n, ngáº¯n gá»n (1-2 cÃ¢u) Ä‘á»ƒ há»i thÃ´ng tin cÃ²n thiáº¿u.\n",
    "- Náº¿u há»i loáº¡i phÃ²ng vÃ  cÃ³ thÃ´ng tin giÃ¡: Ä‘Æ°a ra 2-3 lá»±a chá»n vá»›i giÃ¡ Ä‘á»ƒ khÃ¡ch dá»… chá»n\n",
    "- Tone: lá»‹ch sá»±, chuyÃªn nghiá»‡p, tá»± nhiÃªn nhÆ° ngÆ°á»i tháº­t\n",
    "- KHÃ”NG há»i láº¡i thÃ´ng tin Ä‘Ã£ cÃ³\n",
    "\n",
    "Tráº£ lá»i chá»‰ cÃ¢u há»i (khÃ´ng giáº£i thÃ­ch):\"\"\"\n",
    "\n",
    "    return call_llm(prompt, temperature=0.7, max_tokens=200)\n",
    "\n",
    "def generate_question(missing_slot: str, current_slots: Dict, conversation_history: List, asked_slots: set) -> str:\n",
    "    \"\"\"\n",
    "    Sinh cÃ¢u há»i cho slot cÃ²n thiáº¿u (LLM-first vá»›i fallback)\n",
    "    \"\"\"\n",
    "    # TrÃ¡nh há»i láº¡i náº¿u vá»«a há»i\n",
    "    if missing_slot in asked_slots:\n",
    "        # ÄÃ£ há»i rá»“i nhÆ°ng chÆ°a Ä‘iá»n Ä‘Æ°á»£c â†’ há»i láº¡i vá»›i cÃ¡ch khÃ¡c\n",
    "        if LLM_ENABLED:\n",
    "            q = generate_question_llm(missing_slot, current_slots, conversation_history)\n",
    "            if q:\n",
    "                return q\n",
    "    \n",
    "    # Try LLM\n",
    "    if LLM_ENABLED and missing_slot == \"room_type\":\n",
    "        # LuÃ´n dÃ¹ng LLM cho room_type Ä‘á»ƒ tÆ° váº¥n tá»‘t hÆ¡n\n",
    "        q = generate_question_llm(missing_slot, current_slots, conversation_history)\n",
    "        if q:\n",
    "            return q\n",
    "    \n",
    "    # Fallback\n",
    "    return SLOT_QUESTIONS.get(missing_slot, \"Vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin.\")\n",
    "\n",
    "print(\"âœ… Working Memory & Question Generator (LLM-powered)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "813b7862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test Slot Filler:\n",
      "  Input: 'TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP á»Ÿ ÄÃ  Láº¡t ngÃ y 18â€“20/10'\n",
      "  Extracted: {\n",
      "  \"city\": \"ÄÃ \",\n",
      "  \"checkin\": \"18/10\",\n",
      "  \"checkout\": \"20/10\",\n",
      "  \"room_type\": \"VIP\",\n",
      "  \"guest_name\": null,\n",
      "  \"contact\": null,\n",
      "  \"room_id\": null,\n",
      "  \"room_number\": null,\n",
      "  \"price_per_night\": null\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/4041408505.py:98: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"  Extracted: {json.dumps(result.dict(), indent=2, ensure_ascii=False)}\")\n"
     ]
    }
   ],
   "source": [
    "def extract_slots_from_text(text: str, current: BookingRequest) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    TrÃ­ch xuáº¥t thÃ´ng tin tá»« text ngÆ°á»i dÃ¹ng vÃ  cáº­p nháº­t vÃ o BookingRequest\n",
    "    Sá»­ dá»¥ng regex vÃ  rule-based matching\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 1. TrÃ­ch xuáº¥t ThÃ nh phá»‘\n",
    "    if not current.city:\n",
    "        # Pattern: \"á»Ÿ <City>\" hoáº·c \"táº¡i <City>\"\n",
    "        city_patterns = [\n",
    "            r\"á»Ÿ\\s+([A-Za-zÃ€-á»¹\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"táº¡i\\s+([A-Za-zÃ€-á»¹\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"(HÃ  Ná»™i|ÄÃ  Láº¡t|SÃ i GÃ²n|TP HCM|ÄÃ  Náºµng|Nha Trang|PhÃº Quá»‘c|VÅ©ng TÃ u|Há»™i An)\"\n",
    "        ]\n",
    "        for pattern in city_patterns:\n",
    "            match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                city = match.group(1).strip()\n",
    "                if len(city) <= 40:\n",
    "                    current.city = city\n",
    "                    break\n",
    "    \n",
    "    # 2. TrÃ­ch xuáº¥t NgÃ y (checkin/checkout)\n",
    "    # Pattern: dd/mm, dd-mm, yyyy-mm-dd, \"18â€“20/10\", \"tá»« 18 Ä‘áº¿n 20\"\n",
    "    \n",
    "    # TÃ¬m pattern \"18â€“20/10\" hoáº·c \"tá»« 18 Ä‘áº¿n 20/10\"\n",
    "    range_match = re.search(r\"(\\d{1,2})\\s*[â€“â€”-]\\s*(\\d{1,2})[/\\-](\\d{1,2})\", text)\n",
    "    if range_match and not current.checkin:\n",
    "        day1, day2, month = range_match.groups()\n",
    "        current.checkin = f\"{day1}/{month}\"\n",
    "        current.checkout = f\"{day2}/{month}\"\n",
    "    else:\n",
    "        # TÃ¬m táº¥t cáº£ ngÃ y dáº¡ng dd/mm\n",
    "        dates = re.findall(r\"(\\d{1,2}[/\\-]\\d{1,2}(?:[/\\-]\\d{2,4})?)\", text)\n",
    "        if dates:\n",
    "            if len(dates) == 1:\n",
    "                # QUAN TRá»ŒNG: Náº¿u Ä‘Ã£ cÃ³ checkin rá»“i, gÃ¡n vÃ o checkout\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                elif not current.checkout:\n",
    "                    current.checkout = dates[0]\n",
    "            elif len(dates) >= 2:\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                if not current.checkout:\n",
    "                    current.checkout = dates[1]\n",
    "    \n",
    "    # 3. TrÃ­ch xuáº¥t Loáº¡i phÃ²ng\n",
    "    if not current.room_type:\n",
    "        room_patterns = {\n",
    "            \"VIP\": r\"\\b(vip|lux|luxury|suite)\\b\",\n",
    "            \"Deluxe\": r\"\\b(deluxe|cao cáº¥p)\\b\",\n",
    "            \"Standard\": r\"\\b(standard|normal|thÆ°á»ng|tiÃªu chuáº©n)\\b\"\n",
    "        }\n",
    "        for room_type, pattern in room_patterns.items():\n",
    "            if re.search(pattern, text, flags=re.IGNORECASE):\n",
    "                current.room_type = room_type\n",
    "                break\n",
    "    \n",
    "    # 4. TrÃ­ch xuáº¥t TÃªn ngÆ°á»i Ä‘áº·t\n",
    "    if not current.guest_name:\n",
    "        name_patterns = [\n",
    "            r\"tÃªn lÃ \\s+([A-ZÃ€-á»¸][A-Za-zÃ€-á»¹\\s]{1,40})\",\n",
    "            r\"tÃªn\\s+([A-ZÃ€-á»¸][A-Za-zÃ€-á»¹\\s]{1,40})\",\n",
    "            r\"lÃ \\s+([A-ZÃ€-á»¸][A-Za-zÃ€-á»¹\\s]{2,40})$\",\n",
    "            r\"^([A-ZÃ€-á»¸][a-zÃ -á»¹]+(?:\\s+[A-ZÃ€-á»¸][a-zÃ -á»¹]+)+)$\"\n",
    "        ]\n",
    "        for pattern in name_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                name = match.group(1).strip()\n",
    "                # Validate name (khÃ´ng chá»©a sá»‘, Ã­t nháº¥t 2 tá»«)\n",
    "                if len(name.split()) >= 2 and not any(char.isdigit() for char in name):\n",
    "                    current.guest_name = name\n",
    "                    break\n",
    "    \n",
    "    # 5. TrÃ­ch xuáº¥t Contact (Email hoáº·c Phone)\n",
    "    if not current.contact:\n",
    "        # Email\n",
    "        email_match = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\", text)\n",
    "        if email_match:\n",
    "            current.contact = email_match.group(0)\n",
    "        else:\n",
    "            # Phone number\n",
    "            phone_match = re.search(r\"(\\+?84|0)\\s*[\\d\\-\\s]{8,12}\", text)\n",
    "            if phone_match:\n",
    "                current.contact = phone_match.group(0)\n",
    "    \n",
    "    return current\n",
    "\n",
    "# Test Slot Filler\n",
    "print(\"ğŸ§ª Test Slot Filler:\")\n",
    "test_booking = BookingRequest()\n",
    "test_text = \"TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP á»Ÿ ÄÃ  Láº¡t ngÃ y 18â€“20/10\"\n",
    "result = extract_slots_from_text(test_text, test_booking)\n",
    "print(f\"  Input: '{test_text}'\")\n",
    "print(f\"  Extracted: {json.dumps(result.dict(), indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d16877",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Working Memory & Slot Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "837798be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Working Memory Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh (vá»›i LLM integration)\n"
     ]
    }
   ],
   "source": [
    "# CÃ¢u há»i cho tá»«ng slot cÃ²n thiáº¿u\n",
    "SLOT_QUESTIONS = {\n",
    "    \"city\": \"Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?\",\n",
    "    \"checkin\": \"NgÃ y nháº­n phÃ²ng lÃ  ngÃ y nÃ o áº¡? (VD: 18/10 hoáº·c 18-10-2025)\",\n",
    "    \"checkout\": \"NgÃ y tráº£ phÃ²ng lÃ  ngÃ y nÃ o áº¡?\",\n",
    "    \"room_type\": \"Anh/chá»‹ muá»‘n Ä‘áº·t loáº¡i phÃ²ng nÃ o? (VIP/Deluxe/Standard)\",\n",
    "    \"guest_name\": \"Cho em xin tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng áº¡?\",\n",
    "    \"contact\": \"Cho em xin sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email Ä‘á»ƒ liÃªn há»‡ Ä‘Æ°á»£c khÃ´ng áº¡?\"\n",
    "}\n",
    "\n",
    "def init_memory() -> Dict[str, Any]:\n",
    "    \"\"\"Khá»Ÿi táº¡o Working Memory\"\"\"\n",
    "    return {\n",
    "        \"intent\": None,\n",
    "        \"slots\": BookingRequest().dict(),\n",
    "        \"conversation_history\": [],\n",
    "        \"expected_slot\": None,  # Slot Ä‘ang chá» user tráº£ lá»i\n",
    "    }\n",
    "\n",
    "def next_missing_slot(booking: BookingRequest) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    TÃ¬m slot tiáº¿p theo cÃ²n thiáº¿u\n",
    "    Returns: tÃªn slot hoáº·c None náº¿u Ä‘Ã£ Ä‘á»§\n",
    "    \"\"\"\n",
    "    for slot in REQUIRED_SLOTS:\n",
    "        value = getattr(booking, slot)\n",
    "        if value is None or value == \"\":\n",
    "            return slot\n",
    "    \n",
    "    # Contact lÃ  optional nhÆ°ng nÃªn há»i\n",
    "    if not booking.contact:\n",
    "        return \"contact\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def build_booking_object(memory: Dict) -> BookingRequest:\n",
    "    \"\"\"XÃ¢y dá»±ng BookingRequest tá»« memory\"\"\"\n",
    "    return BookingRequest(**memory[\"slots\"])\n",
    "\n",
    "def update_memory_with_extracted(memory: Dict, text: str) -> Dict:\n",
    "    \"\"\"Cáº­p nháº­t memory vá»›i thÃ´ng tin má»›i trÃ­ch xuáº¥t Ä‘Æ°á»£c - LLM-powered\"\"\"\n",
    "    current_booking = BookingRequest(**memory[\"slots\"])\n",
    "    expected_slot = memory.get(\"expected_slot\")\n",
    "    conversation_history = memory.get(\"conversation_history\", [])\n",
    "    \n",
    "    if LLM_ENABLED:\n",
    "        updated_booking = llm_extract_slots(text, current_booking, expected_slot, conversation_history)\n",
    "    else:\n",
    "        updated_booking = extract_slots_from_text(text, current_booking)\n",
    "    \n",
    "    memory[\"slots\"] = updated_booking.dict()\n",
    "    return memory\n",
    "\n",
    "print(\"âœ… Working Memory Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh (vá»›i LLM integration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd7b55",
   "metadata": {},
   "source": [
    "def handle_user_message(message: str, history: List, state: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Xá»­ lÃ½ message vá»›i LLM-powered NLU:\n",
    "    1. Detect intent (context-aware vá»›i LLM)\n",
    "    2. Extract slots (tá»« toÃ n bá»™ context, khÃ´ng chá»‰ message hiá»‡n táº¡i)\n",
    "    3. Generate natural follow-up questions (LLM)\n",
    "    4. Call Real API khi Ä‘á»§ thÃ´ng tin\n",
    "    \"\"\"\n",
    "    if state is None:\n",
    "        state = init_memory()\n",
    "    \n",
    "    # Update conversation history\n",
    "    state[\"conversation_history\"].append((\"user\", message))\n",
    "    \n",
    "    # 1. Detect intent (LLM context-aware)\n",
    "    if not state[\"intent\"]:\n",
    "        if LLM_ENABLED:\n",
    "            state[\"intent\"] = llm_detect_intent(message, state[\"conversation_history\"])\n",
    "        else:\n",
    "            state[\"intent\"] = detect_intent(message)\n",
    "        print(f\"ğŸ¯ Intent: {state['intent']} {'[LLM]' if LLM_ENABLED else '[Rule]'}\")\n",
    "    \n",
    "    # Handle non-booking intents\n",
    "    if state[\"intent\"] == \"cancel\":\n",
    "        msg = \"Äá»ƒ há»§y Ä‘áº·t phÃ²ng, vui lÃ²ng cung cáº¥p mÃ£ Ä‘áº·t phÃ²ng cá»§a báº¡n (VD: BK12345678).\"\n",
    "        history.append((\"bot\", msg))\n",
    "        state[\"conversation_history\"].append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"check_booking\":\n",
    "        msg = \"Äá»ƒ kiá»ƒm tra Ä‘áº·t phÃ²ng, vui lÃ²ng cung cáº¥p mÃ£ Ä‘áº·t phÃ²ng hoáº·c sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ Ä‘Äƒng kÃ½.\"\n",
    "        history.append((\"bot\", msg))\n",
    "        state[\"conversation_history\"].append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"unknown\":\n",
    "        msg = \"\"\"Xin chÃ o! ğŸ‘‹ TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n",
    "- ğŸ¨ Äáº·t phÃ²ng khÃ¡ch sáº¡n\n",
    "- âŒ Há»§y Ä‘áº·t phÃ²ng\n",
    "- ğŸ” Kiá»ƒm tra thÃ´ng tin Ä‘áº·t phÃ²ng\n",
    "\n",
    "Báº¡n muá»‘n lÃ m gÃ¬ áº¡?\"\"\"\n",
    "        history.append((\"bot\", msg))\n",
    "        state[\"conversation_history\"].append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    # 2. Extract slots (LLM sáº½ xem toÃ n bá»™ context)\n",
    "    state = update_memory_with_extracted(state, message)\n",
    "    booking = build_booking_object(state)\n",
    "    \n",
    "    print(f\"ğŸ“Š Slots: {json.dumps({k:v for k,v in booking.dict().items() if v}, ensure_ascii=False)}\")\n",
    "    \n",
    "    # 3. Kiá»ƒm tra slot cÃ²n thiáº¿u\n",
    "    missing = next_missing_slot(booking)\n",
    "    \n",
    "    if missing:\n",
    "        # Generate natural question (LLM-powered or API-based for room_type)\n",
    "        question = generate_question(\n",
    "            missing, \n",
    "            booking.dict(),\n",
    "            state[\"conversation_history\"],\n",
    "            state.get(\"asked_slots\", set())\n",
    "        )\n",
    "        \n",
    "        history.append((\"bot\", question))\n",
    "        state[\"conversation_history\"].append((\"bot\", question))\n",
    "        state[\"expected_slot\"] = missing\n",
    "        state.setdefault(\"asked_slots\", set()).add(missing)\n",
    "        state[\"last_bot_question\"] = question\n",
    "        \n",
    "        print(f\"â“ Asking: {missing} {'[LLM]' if LLM_ENABLED else '[Template]'}\")\n",
    "        return history, state\n",
    "    \n",
    "    # 4. Äá»§ thÃ´ng tin â†’ Call Real API\n",
    "    print(\"ğŸ“ Calling Real Booking API...\")\n",
    "    api_response = call_booking_api(booking)\n",
    "    response_msg = format_booking_response(api_response, booking)\n",
    "    \n",
    "    history.append((\"bot\", response_msg))\n",
    "    state[\"conversation_history\"].append((\"bot\", response_msg))\n",
    "    \n",
    "    # Reset\n",
    "    state = init_memory()\n",
    "    print(\"âœ… Booking completed!\")\n",
    "    \n",
    "    return history, state\n",
    "\n",
    "print(\"âœ… Dialog Manager sáºµn sÃ ng (LLM-powered NLU + Real API)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8e82bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test Real API Booking Flow:\n",
      "\n",
      "1. TÃ¬m phÃ²ng trá»‘ng tá»« API...\n",
      "ğŸ” Äang tÃ¬m phÃ²ng Standard trá»‘ng...\n",
      "ğŸ” Äang tÃ¬m phÃ²ng Standard trá»‘ng...\n",
      "âœ… TÃ¬m tháº¥y phÃ²ng: 101 - PhÃ²ng tiÃªu chuáº©n\n",
      "\n",
      "2. Booking thÃ nh cÃ´ng!\n",
      "âœ… **Äáº·t phÃ²ng thÃ nh cÃ´ng!**\n",
      "\n",
      "ğŸ“‹ **ThÃ´ng tin Ä‘áº·t phÃ²ng:**\n",
      "- ğŸ†” MÃ£ Ä‘áº·t phÃ²ng: `BKDC6908F1`\n",
      "- ğŸ¨ Sá»‘ phÃ²ng: **101**\n",
      "- ğŸ·ï¸ Loáº¡i phÃ²ng: **PhÃ²ng tiÃªu chuáº©n**\n",
      "- ğŸ“ Äá»‹a Ä‘iá»ƒm: **KhÃ¡ch sáº¡n**\n",
      "- ğŸ“… Check-in: **18/10**\n",
      "- ğŸ“… Check-out: **20/10**\n",
      "- ğŸŒ™ Sá»‘ Ä‘Ãªm: **2 Ä‘Ãªm**\n",
      "- ğŸ‘¤ TÃªn khÃ¡ch: **Nguyá»…n VÄƒn A**\n",
      "- ğŸ“ LiÃªn há»‡: **0123456789**\n",
      "- ğŸ’° GiÃ¡ phÃ²ng/Ä‘Ãªm: **800,000.0 VNÄ**\n",
      "- ğŸ’µ **Tá»•ng tiá»n: 1,600,000.0 VNÄ**\n",
      "\n",
      "Cáº£m Æ¡n quÃ½ khÃ¡ch Ä‘Ã£ sá»­ dá»¥ng dá»‹ch vá»¥! ğŸ™\n",
      "\n",
      "_ÄÃ¢y lÃ  booking tá»« API thá»±c: http://103.38.236.148:8080/api/Room_\n",
      "\n",
      "âœ… TÃ¬m tháº¥y phÃ²ng: 101 - PhÃ²ng tiÃªu chuáº©n\n",
      "\n",
      "2. Booking thÃ nh cÃ´ng!\n",
      "âœ… **Äáº·t phÃ²ng thÃ nh cÃ´ng!**\n",
      "\n",
      "ğŸ“‹ **ThÃ´ng tin Ä‘áº·t phÃ²ng:**\n",
      "- ğŸ†” MÃ£ Ä‘áº·t phÃ²ng: `BKDC6908F1`\n",
      "- ğŸ¨ Sá»‘ phÃ²ng: **101**\n",
      "- ğŸ·ï¸ Loáº¡i phÃ²ng: **PhÃ²ng tiÃªu chuáº©n**\n",
      "- ğŸ“ Äá»‹a Ä‘iá»ƒm: **KhÃ¡ch sáº¡n**\n",
      "- ğŸ“… Check-in: **18/10**\n",
      "- ğŸ“… Check-out: **20/10**\n",
      "- ğŸŒ™ Sá»‘ Ä‘Ãªm: **2 Ä‘Ãªm**\n",
      "- ğŸ‘¤ TÃªn khÃ¡ch: **Nguyá»…n VÄƒn A**\n",
      "- ğŸ“ LiÃªn há»‡: **0123456789**\n",
      "- ğŸ’° GiÃ¡ phÃ²ng/Ä‘Ãªm: **800,000.0 VNÄ**\n",
      "- ğŸ’µ **Tá»•ng tiá»n: 1,600,000.0 VNÄ**\n",
      "\n",
      "Cáº£m Æ¡n quÃ½ khÃ¡ch Ä‘Ã£ sá»­ dá»¥ng dá»‹ch vá»¥! ğŸ™\n",
      "\n",
      "_ÄÃ¢y lÃ  booking tá»« API thá»±c: http://103.38.236.148:8080/api/Room_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/3171132577.py:78: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  **request.dict(),\n"
     ]
    }
   ],
   "source": [
    "def find_available_room(booking: BookingRequest) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    TÃ¬m phÃ²ng trá»‘ng phÃ¹ há»£p tá»« API thá»±c\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Äang tÃ¬m phÃ²ng {booking.room_type} trá»‘ng...\")\n",
    "    \n",
    "    # Láº¥y danh sÃ¡ch phÃ²ng trá»‘ng theo loáº¡i\n",
    "    available_rooms = api_client.get_available_rooms(room_type_name=booking.room_type)\n",
    "    \n",
    "    if not available_rooms:\n",
    "        print(f\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y phÃ²ng {booking.room_type} trá»‘ng\")\n",
    "        return None\n",
    "    \n",
    "    # Chá»n phÃ²ng Ä‘áº§u tiÃªn phÃ¹ há»£p\n",
    "    selected_room = available_rooms[0]\n",
    "    \n",
    "    print(f\"âœ… TÃ¬m tháº¥y phÃ²ng: {selected_room['roomNumber']} - {selected_room['roomTypeName']}\")\n",
    "    \n",
    "    return selected_room\n",
    "\n",
    "def call_booking_api(request: BookingRequest) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Gá»i API Ä‘á»ƒ Ä‘áº·t phÃ²ng\n",
    "    Hiá»‡n táº¡i mock vÃ¬ chÆ°a cÃ³ endpoint POST /api/Booking\n",
    "    \"\"\"\n",
    "    # Simulate network delay\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # TÃ¬m phÃ²ng trá»‘ng phÃ¹ há»£p tá»« API thá»±c\n",
    "    available_room = find_available_room(request)\n",
    "    \n",
    "    if not available_room:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"KhÃ´ng cÃ³ phÃ²ng {request.room_type} trá»‘ng\",\n",
    "            \"booking_id\": None\n",
    "        }\n",
    "    \n",
    "    # Cáº­p nháº­t thÃ´ng tin phÃ²ng vÃ o booking request\n",
    "    request.room_id = available_room[\"roomId\"]\n",
    "    request.room_number = available_room[\"roomNumber\"]\n",
    "    request.price_per_night = available_room[\"basePriceNight\"]\n",
    "    \n",
    "    # Generate booking ID\n",
    "    booking_id = f\"BK{uuid.uuid4().hex[:8].upper()}\"\n",
    "    \n",
    "    # TODO: Khi cÃ³ API POST /api/Booking, uncomment code dÆ°á»›i:\n",
    "    # try:\n",
    "    #     response = requests.post(\n",
    "    #         f\"{API_BASE_URL}/Booking\",\n",
    "    #         json={\n",
    "    #             \"roomId\": request.room_id,\n",
    "    #             \"guestName\": request.guest_name,\n",
    "    #             \"contact\": request.contact,\n",
    "    #             \"checkIn\": request.checkin,\n",
    "    #             \"checkOut\": request.checkout,\n",
    "    #             # ... thÃªm cÃ¡c field khÃ¡c theo API\n",
    "    #         }\n",
    "    #     )\n",
    "    #     response.raise_for_status()\n",
    "    #     result = response.json()\n",
    "    #     \n",
    "    #     if result.get(\"isSuccess\"):\n",
    "    #         return {\n",
    "    #             \"success\": True,\n",
    "    #             \"booking_id\": result[\"data\"][\"bookingId\"],\n",
    "    #             \"details\": result[\"data\"]\n",
    "    #         }\n",
    "    # except Exception as e:\n",
    "    #     return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    # Mock response (cho Ä‘áº¿n khi cÃ³ API POST)\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"booking_id\": booking_id,\n",
    "        \"status\": \"confirmed\",\n",
    "        \"details\": {\n",
    "            **request.dict(),\n",
    "            \"roomInfo\": {\n",
    "                \"roomNumber\": available_room[\"roomNumber\"],\n",
    "                \"roomType\": available_room[\"roomTypeName\"],\n",
    "                \"pricePerNight\": available_room[\"basePriceNight\"],\n",
    "                \"images\": available_room.get(\"images\", [])\n",
    "            }\n",
    "        },\n",
    "        \"created_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "def format_booking_response(api_response: Dict[str, Any], booking: BookingRequest) -> str:\n",
    "    \"\"\"\n",
    "    Format response tá»« API thÃ nh message cho user\n",
    "    \"\"\"\n",
    "    if not api_response.get(\"success\"):\n",
    "        error_msg = api_response.get(\"error\", \"Äáº·t phÃ²ng tháº¥t báº¡i\")\n",
    "        return f\"âŒ **{error_msg}**\\n\\nVui lÃ²ng thá»­ láº¡i hoáº·c chá»n loáº¡i phÃ²ng khÃ¡c.\"\n",
    "    \n",
    "    room_info = api_response[\"details\"].get(\"roomInfo\", {})\n",
    "    price = room_info.get(\"pricePerNight\", 0)\n",
    "    \n",
    "    # TÃ­nh sá»‘ Ä‘Ãªm (Ä‘Æ¡n giáº£n hÃ³a)\n",
    "    try:\n",
    "        # Parse dates (giáº£ sá»­ format dd/mm)\n",
    "        checkin_parts = booking.checkin.split(\"/\")\n",
    "        checkout_parts = booking.checkout.split(\"/\")\n",
    "        nights = int(checkout_parts[0]) - int(checkin_parts[0])\n",
    "        if nights <= 0:\n",
    "            nights = 1\n",
    "    except:\n",
    "        nights = 1\n",
    "    \n",
    "    total_price = price * nights\n",
    "    \n",
    "    msg = f\"\"\"âœ… **Äáº·t phÃ²ng thÃ nh cÃ´ng!**\n",
    "\n",
    "ğŸ“‹ **ThÃ´ng tin Ä‘áº·t phÃ²ng:**\n",
    "- ğŸ†” MÃ£ Ä‘áº·t phÃ²ng: `{api_response['booking_id']}`\n",
    "- ğŸ¨ Sá»‘ phÃ²ng: **{booking.room_number}**\n",
    "- ğŸ·ï¸ Loáº¡i phÃ²ng: **{room_info.get('roomType', booking.room_type)}**\n",
    "- ğŸ“ Äá»‹a Ä‘iá»ƒm: **{booking.city or 'KhÃ¡ch sáº¡n'}**\n",
    "- ğŸ“… Check-in: **{booking.checkin}**\n",
    "- ğŸ“… Check-out: **{booking.checkout}**\n",
    "- ğŸŒ™ Sá»‘ Ä‘Ãªm: **{nights} Ä‘Ãªm**\n",
    "- ğŸ‘¤ TÃªn khÃ¡ch: **{booking.guest_name}**\n",
    "- ğŸ“ LiÃªn há»‡: **{booking.contact or 'ChÆ°a cung cáº¥p'}**\n",
    "- ğŸ’° GiÃ¡ phÃ²ng/Ä‘Ãªm: **{price:,} VNÄ**\n",
    "- ğŸ’µ **Tá»•ng tiá»n: {total_price:,} VNÄ**\n",
    "\n",
    "Cáº£m Æ¡n quÃ½ khÃ¡ch Ä‘Ã£ sá»­ dá»¥ng dá»‹ch vá»¥! ğŸ™\n",
    "\n",
    "_ÄÃ¢y lÃ  booking tá»« API thá»±c: http://103.38.236.148:8080/api/Room_\n",
    "\"\"\"\n",
    "    return msg\n",
    "\n",
    "# Test Real API Booking Flow\n",
    "print(\"ğŸ§ª Test Real API Booking Flow:\")\n",
    "test_request = BookingRequest(\n",
    "    city=\"KhÃ¡ch sáº¡n\",\n",
    "    checkin=\"18/10\",\n",
    "    checkout=\"20/10\",\n",
    "    room_type=\"Standard\",\n",
    "    guest_name=\"Nguyá»…n VÄƒn A\",\n",
    "    contact=\"0123456789\"\n",
    ")\n",
    "\n",
    "print(\"\\n1. TÃ¬m phÃ²ng trá»‘ng tá»« API...\")\n",
    "api_result = call_booking_api(test_request)\n",
    "\n",
    "if api_result[\"success\"]:\n",
    "    print(\"\\n2. Booking thÃ nh cÃ´ng!\")\n",
    "    print(format_booking_response(api_result, test_request))\n",
    "else:\n",
    "    print(f\"\\nâŒ Booking tháº¥t báº¡i: {api_result.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa88ec3",
   "metadata": {},
   "source": [
    "def user_submit(user_message: str, chat_history: List, state: Dict) -> tuple:\n",
    "    \"\"\"Xá»­ lÃ½ khi user gá»­i message\"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    # ThÃªm message cá»§a user vÃ o history\n",
    "    chat_history.append((\"user\", user_message))\n",
    "    \n",
    "    # Xá»­ lÃ½ message\n",
    "    chat_history, state = handle_user_message(user_message, chat_history, state)\n",
    "    \n",
    "    # Convert sang format Gradio Chatbot\n",
    "    pairs = []\n",
    "    user_msg = None\n",
    "    \n",
    "    for role, text in chat_history:\n",
    "        if role == \"user\":\n",
    "            user_msg = text\n",
    "        else:\n",
    "            if user_msg is None:\n",
    "                pairs.append((\"\", text))\n",
    "            else:\n",
    "                pairs.append((user_msg, text))\n",
    "                user_msg = None\n",
    "    \n",
    "    return pairs, state\n",
    "\n",
    "\n",
    "# Táº¡o Gradio Interface\n",
    "llm_status = \"ğŸ¤– **LLM: Enabled** (Gemini 1.5 Flash)\" if LLM_ENABLED else \"âš ï¸ **LLM: Disabled** (Rule-based fallback)\"\n",
    "api_status = \"ğŸ”Œ **API: Connected**\" if test_result.get(\"success\") else \"âŒ **API: Error**\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(f\"\"\"\n",
    "    # ğŸ¨ Booking Chatbot Demo - AI-Powered\n",
    "    \n",
    "    ### Tráº¡ng thÃ¡i há»‡ thá»‘ng:\n",
    "    {llm_status} | {api_status}\n",
    "    \n",
    "    ### Kiáº¿n trÃºc:\n",
    "    **User** â†’ **LLM Intent Detector** â†’ **LLM Slot Extractor** â†’ **Working Memory** â†’ **Real API** â†’ **Response**\n",
    "    \n",
    "    **TÃ­nh nÄƒng ná»•i báº­t:**\n",
    "    - ğŸ§  Hiá»ƒu ngá»¯ cáº£nh tá»± nhiÃªn (LLM-powered)\n",
    "    - \udde3ï¸ Xá»­ lÃ½ ngÃ´n ngá»¯ Ä‘Ã m thoáº¡i (\"2 Ä‘Ãªm\", \"tuáº§n sau\", \"std\")\n",
    "    - \udd04 KhÃ´ng bá»‹ vÃ²ng láº·p vÃ´ háº¡n\n",
    "    - ğŸ¨ TÃ¬m phÃ²ng trá»‘ng tá»« API thá»±c\n",
    "    - ğŸ’¬ TÆ° váº¥n thÃ´ng minh dá»±a trÃªn dá»¯ liá»‡u thá»±c\n",
    "    \n",
    "    **API Endpoint:** `http://103.38.236.148:8080/api/Room`\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Há»™i thoáº¡i\",\n",
    "        height=500,\n",
    "        show_label=True\n",
    "    )\n",
    "    \n",
    "    state = gr.State(init_memory())\n",
    "    \n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            placeholder=\"VD: MÃ¬nh muá»‘n Ä‘áº·t phÃ²ng 2 Ä‘Ãªm vÃ o cuá»‘i tuáº§n nÃ y\" if LLM_ENABLED else \"VD: TÃ´i muá»‘n Ä‘áº·t phÃ²ng Standard ngÃ y 18/10 Ä‘áº¿n 20/10\",\n",
    "            show_label=False,\n",
    "            scale=9\n",
    "        )\n",
    "        submit_btn = gr.Button(\"Gá»­i\", scale=1, variant=\"primary\")\n",
    "    \n",
    "    txt.submit(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)\n",
    "    \n",
    "    submit_btn.click(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    submit_btn.click(lambda: \"\", None, txt)\n",
    "    \n",
    "    if LLM_ENABLED:\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### ğŸ’¡ VÃ­ dá»¥ há»™i thoáº¡i tá»± nhiÃªn (vá»›i LLM):\n",
    "        \n",
    "        **User:** MÃ¬nh muá»‘n Ä‘áº·t phÃ²ng 2 Ä‘Ãªm  \n",
    "        **Bot:** Anh/chá»‹ muá»‘n Ä‘áº·t tá»« ngÃ y nÃ o áº¡?\n",
    "        \n",
    "        **User:** 18/10  \n",
    "        **Bot:** [LLM tá»± tÃ­nh] Váº­y lÃ  check-out 20/10 nhÃ©. Anh/chá»‹ muá»‘n loáº¡i phÃ²ng nÃ o?\n",
    "        \n",
    "        **User:** std  \n",
    "        **Bot:** [LLM hiá»ƒu \"std\" = \"Standard\"] Dáº¡, em cÃ³ phÃ²ng Standard tá»« 800k/Ä‘Ãªm...\n",
    "        \n",
    "        **User:** ok  \n",
    "        **Bot:** Cho em xin tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng áº¡?\n",
    "        \n",
    "        **User:** nguyá»…n vÄƒn a  \n",
    "        **Bot:** [LLM chuáº©n hÃ³a] Dáº¡, anh Nguyá»…n VÄƒn A. Cho em xin sá»‘ Ä‘iá»‡n thoáº¡i...\n",
    "        \n",
    "        **User:** 0912345678  \n",
    "        **Bot:** âœ… Äáº·t thÃ nh cÃ´ng phÃ²ng 101 - Standard...\n",
    "        \"\"\")\n",
    "    else:\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### ğŸ’¡ VÃ­ dá»¥ (Rule-based - cáº§n chÃ­nh xÃ¡c hÆ¡n):\n",
    "        \n",
    "        **User:** TÃ´i muá»‘n Ä‘áº·t phÃ²ng Standard  \n",
    "        **Bot:** Anh/chá»‹ muá»‘n Ä‘áº·t á»Ÿ thÃ nh phá»‘ nÃ o áº¡?\n",
    "        \n",
    "        **User:** KhÃ¡ch sáº¡n cá»§a báº¡n  \n",
    "        **Bot:** NgÃ y nháº­n phÃ²ng lÃ  ngÃ y nÃ o áº¡?\n",
    "        \n",
    "        **User:** 18/10  \n",
    "        **Bot:** NgÃ y tráº£ phÃ²ng lÃ  ngÃ y nÃ o áº¡?\n",
    "        \n",
    "        **User:** 20/10  \n",
    "        **Bot:** Cho em xin tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng áº¡?\n",
    "        \n",
    "        **User:** Nguyá»…n VÄƒn A  \n",
    "        **Bot:** Cho em xin sá»‘ Ä‘iá»‡n thoáº¡i...\n",
    "        \n",
    "        **User:** 0912345678  \n",
    "        **Bot:** âœ… Äáº·t thÃ nh cÃ´ng phÃ²ng 101...\n",
    "        \"\"\")\n",
    "    \n",
    "    gr.Markdown(f\"\"\"\n",
    "    ---\n",
    "    \n",
    "    ### ğŸ”§ Cáº¥u hÃ¬nh:\n",
    "    \n",
    "    **LLM Status:** {\"âœ… Enabled (Gemini 1.5 Flash)\" if LLM_ENABLED else \"âŒ Disabled (cáº§n GEMINI_API_KEY)\"}\n",
    "    \n",
    "    {\"\" if LLM_ENABLED else '''\n",
    "    **Muá»‘n báº­t LLM?**\n",
    "    1. Láº¥y API key: https://makersuite.google.com/app/apikey\n",
    "    2. Set environment: `export GEMINI_API_KEY=\"your-key\"`\n",
    "    3. Hoáº·c hardcode trong notebook cell\n",
    "    4. Restart kernel vÃ  cháº¡y láº¡i\n",
    "    '''}\n",
    "    \n",
    "    ### ğŸ“Š So sÃ¡nh LLM vs Rule-based:\n",
    "    \n",
    "    | TÃ­nh nÄƒng | LLM (Gemini) | Rule-based |\n",
    "    |-----------|--------------|------------|\n",
    "    | Hiá»ƒu \"2 Ä‘Ãªm\", \"tuáº§n sau\" | âœ… | âŒ |\n",
    "    | Context-aware | âœ… | âš ï¸ Limited |\n",
    "    | Xá»­ lÃ½ typo, viáº¿t táº¯t | âœ… | âŒ |\n",
    "    | Chuáº©n hÃ³a tÃªn | âœ… | âš ï¸ Basic |\n",
    "    | CÃ¢u há»i tá»± nhiÃªn | âœ… | âŒ Template |\n",
    "    | Tá»‘c Ä‘á»™ | ~1-2s | <0.1s |\n",
    "    | Chi phÃ­ | Free tier | Free |\n",
    "    | Äá»™ chÃ­nh xÃ¡c | ~95% | ~70% |\n",
    "    \n",
    "    ### ğŸš€ CÃ´ng nghá»‡:\n",
    "    - ğŸ¤– **LLM:** Google Gemini 1.5 Flash (1M context)\n",
    "    - ğŸ”Œ **Backend API:** {API_BASE_URL}\n",
    "    - ğŸ¨ **UI:** Gradio\n",
    "    - ğŸ“¦ **Schema:** Pydantic\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    **Made with â¤ï¸ by AI + Real API Integration**\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"âœ… Gradio UI sáºµn sÃ ng - LLM: {LLM_ENABLED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b474fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ§ª TEST 1: Regression - No infinite loop khi tráº£ lá»i checkout\n",
      "======================================================================\n",
      "\n",
      "--- Turn 1 ---\n",
      "User: MÃ¬nh muá»‘n Ä‘áº·t phÃ²ng Standard\n",
      "ğŸ¯ Intent detected: book_room\n",
      "ğŸ“Š Current slots: {\"city\": null, \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: city\n",
      "Bot: Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?...\n",
      "\n",
      "--- Turn 2 ---\n",
      "User: KhÃ¡ch sáº¡n cá»§a báº¡n\n",
      "ğŸ“Š Current slots: {\"city\": null, \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: city\n",
      "Bot: Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?...\n",
      "\n",
      "--- Turn 3 ---\n",
      "User: 18/10\n",
      "ğŸ“Š Current slots: {\"city\": null, \"checkin\": \"18/10\", \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: city\n",
      "Bot: Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?...\n",
      "\n",
      "--- Turn 4 ---\n",
      "User: 20/10\n",
      "ğŸ“Š Current slots: {\"city\": null, \"checkin\": \"18/10\", \"checkout\": \"20/10\", \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: city\n",
      "Bot: Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?...\n",
      "\n",
      "âœ… PASSED: Bot chuyá»ƒn sang há»i thÃ´ng tin khÃ¡c (khÃ´ng loop)\n",
      "\n",
      "======================================================================\n",
      "ğŸ§ª TEST 2: Natural language vá»›i LLM\n",
      "======================================================================\n",
      "âš ï¸ LLM not enabled, skipping natural language test\n",
      "\n",
      "======================================================================\n",
      "âœ… All tests completed!\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/618494449.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"slots\": BookingRequest().dict(),\n",
      "/tmp/ipykernel_1557/618494449.py:51: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  memory[\"slots\"] = updated_booking.dict()\n",
      "/tmp/ipykernel_1557/2048876677.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"ğŸ“Š Current slots: {json.dumps(booking.dict(), ensure_ascii=False)}\")\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ğŸ§ª TEST 1: Regression - No infinite loop khi tráº£ lá»i checkout\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_state = init_memory()\n",
    "test_history = []\n",
    "\n",
    "# Conversation flow\n",
    "messages = [\n",
    "    (\"User\", \"MÃ¬nh muá»‘n Ä‘áº·t phÃ²ng Standard\"),\n",
    "    (\"User\", \"KhÃ¡ch sáº¡n cá»§a báº¡n\"),\n",
    "    (\"User\", \"18/10\"),\n",
    "    (\"User\", \"20/10\"),  # â† Äiá»ƒm quan trá»ng: khÃ´ng bá»‹ loop á»Ÿ Ä‘Ã¢y\n",
    "]\n",
    "\n",
    "for i, (role, msg) in enumerate(messages, 1):\n",
    "    print(f\"\\n--- Turn {i} ---\")\n",
    "    print(f\"{role}: {msg}\")\n",
    "    \n",
    "    test_history.append((\"user\", msg))\n",
    "    test_history, test_state = handle_user_message(msg, test_history, test_state)\n",
    "    \n",
    "    bot_response = test_history[-1][1]\n",
    "    print(f\"Bot: {bot_response[:150]}...\")\n",
    "    \n",
    "    # Verify khÃ´ng há»i láº¡i checkout\n",
    "    if i == 4:  # Sau khi user tráº£ lá»i \"20/10\"\n",
    "        if \"tráº£ phÃ²ng\" in bot_response.lower() or \"checkout\" in bot_response.lower():\n",
    "            print(\"\\nâŒ FAILED: Bot váº«n há»i láº¡i checkout!\")\n",
    "        else:\n",
    "            print(\"\\nâœ… PASSED: Bot chuyá»ƒn sang há»i thÃ´ng tin khÃ¡c (khÃ´ng loop)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ§ª TEST 2: Natural language vá»›i LLM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if LLM_ENABLED:\n",
    "    test_state2 = init_memory()\n",
    "    test_history2 = []\n",
    "    \n",
    "    natural_messages = [\n",
    "        (\"User\", \"Äáº·t phÃ²ng 2 Ä‘Ãªm\"),\n",
    "        (\"User\", \"standard\"),\n",
    "        (\"User\", \"khÃ¡ch sáº¡n\"),\n",
    "        (\"User\", \"tá»« 18/10\"),\n",
    "        (\"User\", \"nguyá»…n vÄƒn a\"),\n",
    "        (\"User\", \"0912345678\"),\n",
    "    ]\n",
    "    \n",
    "    for i, (role, msg) in enumerate(natural_messages, 1):\n",
    "        print(f\"\\n--- Turn {i} ---\")\n",
    "        print(f\"{role}: {msg}\")\n",
    "        \n",
    "        test_history2.append((\"user\", msg))\n",
    "        test_history2, test_state2 = handle_user_message(msg, test_history2, test_state2)\n",
    "        \n",
    "        bot_response = test_history2[-1][1]\n",
    "        print(f\"Bot: {bot_response[:150]}...\")\n",
    "        \n",
    "        if i == len(natural_messages):\n",
    "            if \"âœ…\" in bot_response or \"thÃ nh cÃ´ng\" in bot_response.lower():\n",
    "                print(\"\\nâœ… PASSED: Booking hoÃ n táº¥t vá»›i LLM!\")\n",
    "else:\n",
    "    print(\"âš ï¸ LLM not enabled, skipping natural language test\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… All tests completed!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535a6f5",
   "metadata": {},
   "source": [
    "## ğŸ§ª Test Cases - Verify No Infinite Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82610a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dialog Manager Ä‘Ã£ sáºµn sÃ ng (vá»›i Real API integration)\n"
     ]
    }
   ],
   "source": [
    "def handle_user_message(message: str, history: List, state: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Xá»­ lÃ½ message tá»« user theo flow:\n",
    "    1. Detect intent (náº¿u chÆ°a cÃ³)\n",
    "    2. Extract slots tá»« message\n",
    "    3. Kiá»ƒm tra slot cÃ²n thiáº¿u\n",
    "    4. Náº¿u thiáº¿u â†’ há»i láº¡i\n",
    "    5. Náº¿u Ä‘á»§ â†’ call Real API â†’ format response\n",
    "    \"\"\"\n",
    "    if state is None:\n",
    "        state = init_memory()\n",
    "    \n",
    "    # 1. Detect intent náº¿u chÆ°a cÃ³\n",
    "    if not state[\"intent\"]:\n",
    "        state[\"intent\"] = detect_intent(message)\n",
    "        print(f\"ğŸ¯ Intent detected: {state['intent']}\")\n",
    "    \n",
    "    # 2. Xá»­ lÃ½ theo intent\n",
    "    if state[\"intent\"] == \"book_room\":\n",
    "        # Extract slots tá»« message\n",
    "        state = update_memory_with_extracted(state, message)\n",
    "        booking = build_booking_object(state)\n",
    "        \n",
    "        print(f\"ğŸ“Š Current slots: {json.dumps(booking.dict(), ensure_ascii=False)}\")\n",
    "        \n",
    "        # Kiá»ƒm tra slot cÃ²n thiáº¿u\n",
    "        missing = next_missing_slot(booking)\n",
    "        \n",
    "        if missing:\n",
    "            # Há»i láº¡i thÃ´ng tin cÃ²n thiáº¿u\n",
    "            question = SLOT_QUESTIONS.get(missing, \"Vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin.\")\n",
    "            history.append((\"bot\", question))\n",
    "            print(f\"â“ Asking for: {missing}\")\n",
    "            return history, state\n",
    "        \n",
    "        # ÄÃ£ Ä‘á»§ thÃ´ng tin â†’ gá»i Real API\n",
    "        print(\"ğŸ“ Calling Real Booking API...\")\n",
    "        api_response = call_booking_api(booking)\n",
    "        \n",
    "        # Format response\n",
    "        response_msg = format_booking_response(api_response, booking)\n",
    "        history.append((\"bot\", response_msg))\n",
    "        \n",
    "        # Reset memory cho láº§n booking tiáº¿p theo\n",
    "        state = init_memory()\n",
    "        print(\"âœ… Booking completed! Memory reset.\")\n",
    "        \n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"cancel\":\n",
    "        msg = \"Äá»ƒ há»§y Ä‘áº·t phÃ²ng, vui lÃ²ng cung cáº¥p mÃ£ Ä‘áº·t phÃ²ng cá»§a báº¡n (VD: BK12345678).\"\n",
    "        history.append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"check_booking\":\n",
    "        msg = \"Äá»ƒ kiá»ƒm tra Ä‘áº·t phÃ²ng, vui lÃ²ng cung cáº¥p mÃ£ Ä‘áº·t phÃ²ng hoáº·c sá»‘ Ä‘iá»‡n thoáº¡i Ä‘Ã£ Ä‘Äƒng kÃ½.\"\n",
    "        history.append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    else:\n",
    "        # Unknown intent\n",
    "        msg = \"\"\"Xin chÃ o! ğŸ‘‹ TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n",
    "- ğŸ¨ Äáº·t phÃ²ng khÃ¡ch sáº¡n\n",
    "- âŒ Há»§y Ä‘áº·t phÃ²ng\n",
    "- ğŸ” Kiá»ƒm tra thÃ´ng tin Ä‘áº·t phÃ²ng\n",
    "\n",
    "Báº¡n muá»‘n lÃ m gÃ¬ áº¡?\"\"\"\n",
    "        history.append((\"bot\", msg))\n",
    "        return history, state\n",
    "\n",
    "print(\"âœ… Dialog Manager Ä‘Ã£ sáºµn sÃ ng (vá»›i Real API integration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af114ee",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e85b60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gradio UI Ä‘Ã£ sáºµn sÃ ng vá»›i Real API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/703334404.py:46: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/tmp/ipykernel_1557/618494449.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"slots\": BookingRequest().dict(),\n"
     ]
    }
   ],
   "source": [
    "def user_submit(user_message: str, chat_history: List, state: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Xá»­ lÃ½ khi user gá»­i message\n",
    "    \"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    # ThÃªm message cá»§a user vÃ o history\n",
    "    chat_history.append((\"user\", user_message))\n",
    "    \n",
    "    # Xá»­ lÃ½ message\n",
    "    chat_history, state = handle_user_message(user_message, chat_history, state)\n",
    "    \n",
    "    # Convert sang format Gradio Chatbot (list of tuples)\n",
    "    pairs = []\n",
    "    user_msg = None\n",
    "    \n",
    "    for role, text in chat_history:\n",
    "        if role == \"user\":\n",
    "            user_msg = text\n",
    "        else:\n",
    "            if user_msg is None:\n",
    "                pairs.append((\"\", text))\n",
    "            else:\n",
    "                pairs.append((user_msg, text))\n",
    "                user_msg = None\n",
    "    \n",
    "    return pairs, state\n",
    "\n",
    "# Táº¡o Gradio Interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ğŸ¨ Booking Chatbot Demo - Real API Integration\n",
    "    \n",
    "    ### Kiáº¿n trÃºc: Intent Detector â†’ Slot Filler â†’ Working Memory â†’ **Real Booking API**\n",
    "    \n",
    "    **ğŸ”Œ Káº¿t ná»‘i vá»›i API:** `http://103.38.236.148:8080/api/Room`\n",
    "    \n",
    "    **HÆ°á»›ng dáº«n sá»­ dá»¥ng:**\n",
    "    - NÃ³i vá»›i bot báº¡n muá»‘n Ä‘áº·t phÃ²ng\n",
    "    - Bot sáº½ há»i cÃ¡c thÃ´ng tin cáº§n thiáº¿t (thÃ nh phá»‘, ngÃ y, loáº¡i phÃ²ng, tÃªn,...)\n",
    "    - Bot sáº½ **tá»± Ä‘á»™ng tÃ¬m phÃ²ng trá»‘ng** tá»« API thá»±c\n",
    "    - Khi Ä‘á»§ thÃ´ng tin, bot sáº½ Ä‘áº·t phÃ²ng vÃ  tráº£ vá» káº¿t quáº£\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"Há»™i thoáº¡i\",\n",
    "        height=500,\n",
    "        show_label=True\n",
    "    )\n",
    "    \n",
    "    state = gr.State(init_memory())\n",
    "    \n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            placeholder=\"VD: TÃ´i muá»‘n Ä‘áº·t phÃ²ng Standard ngÃ y 18/10 Ä‘áº¿n 20/10\",\n",
    "            show_label=False,\n",
    "            scale=9\n",
    "        )\n",
    "        submit_btn = gr.Button(\"Gá»­i\", scale=1, variant=\"primary\")\n",
    "    \n",
    "    # Event handlers\n",
    "    txt.submit(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)  # Clear textbox\n",
    "    \n",
    "    submit_btn.click(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    submit_btn.click(lambda: \"\", None, txt)  # Clear textbox\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ### ğŸ’¡ VÃ­ dá»¥ há»™i thoáº¡i:\n",
    "    \n",
    "    **User:** TÃ´i muá»‘n Ä‘áº·t phÃ²ng Standard  \n",
    "    **Bot:** Anh/chá»‹ muá»‘n Ä‘áº·t phÃ²ng á»Ÿ thÃ nh phá»‘ nÃ o áº¡?\n",
    "    \n",
    "    **User:** KhÃ¡ch sáº¡n cá»§a báº¡n, tá»« 18/10 Ä‘áº¿n 20/10  \n",
    "    **Bot:** Cho em xin tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng áº¡?\n",
    "    \n",
    "    **User:** Nguyá»…n VÄƒn A  \n",
    "    **Bot:** Cho em xin sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email...\n",
    "    \n",
    "    **User:** 0912345678  \n",
    "    **Bot:** âœ… Äáº·t thÃ nh cÃ´ng phÃ²ng 101 - PhÃ²ng tiÃªu chuáº©n tá»« 18/10 Ä‘áº¿n 20/10...\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ### **CÃ¡c tÃ­nh nÄƒng:**\n",
    "    - âœ… Intent Detection\n",
    "    - âœ… Slot Filling (Rule-based regex)\n",
    "    - âœ… Working Memory\n",
    "    - âœ… Multi-turn conversation\n",
    "    - âœ… **Real API Integration** (tÃ¬m phÃ²ng trá»‘ng tá»« API thá»±c)\n",
    "    - âœ… Response Formatting\n",
    "    \n",
    "    ### **Loáº¡i phÃ²ng cÃ³ sáºµn:**\n",
    "    - ğŸ¨ **Standard** (PhÃ²ng tiÃªu chuáº©n): ~800,000 VNÄ/Ä‘Ãªm\n",
    "    - ğŸ’ **VIP/Deluxe** (náº¿u cÃ³ trong há»‡ thá»‘ng)\n",
    "    \n",
    "    ### **API Endpoints:**\n",
    "    - `GET /api/Room` - Láº¥y danh sÃ¡ch phÃ²ng âœ…\n",
    "    - `POST /api/Booking` - Äáº·t phÃ²ng (Ä‘ang mock)\n",
    "    \"\"\")\n",
    "\n",
    "print(\"âœ… Gradio UI Ä‘Ã£ sáºµn sÃ ng vá»›i Real API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302618c1",
   "metadata": {},
   "source": [
    "# ============== Test Suite: LLM vs Rule-based ==============\n",
    "print(\"ğŸ§ª Test Full Dialog Flow (LLM-powered):\\n\")\n",
    "print(f\"Mode: {'LLM (Gemini)' if LLM_ENABLED else 'Rule-based'}\\n\")\n",
    "\n",
    "# Test Case 1: Natural language with context\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 1: Natural conversation with varied input\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_state = init_memory()\n",
    "test_history = []\n",
    "\n",
    "test_turns = [\n",
    "    \"MÃ¬nh muá»‘n Ä‘áº·t phÃ²ng Standard\",\n",
    "    \"á» khÃ¡ch sáº¡n cá»§a báº¡n\",\n",
    "    \"18 Ä‘áº¿n 20 thÃ¡ng 10\",  # Natural date range\n",
    "    \"nguyá»…n vÄƒn a\",        # Lowercase name\n",
    "    \"0912345678\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(test_turns, 1):\n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"User: {msg}\")\n",
    "    test_history, test_state = handle_user_message(msg, test_history, test_state)\n",
    "    bot_msg = test_history[-1][1]\n",
    "    # Truncate long responses\n",
    "    display_msg = (bot_msg[:150] + '...') if len(bot_msg) > 150 else bot_msg\n",
    "    print(f\"Bot: {display_msg}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… Test 1 Complete\\n\")\n",
    "\n",
    "# Test Case 2: Single date reply (regression test for infinite loop)\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 2: Regression - Single date reply for checkout\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "state2 = init_memory()\n",
    "history2 = []\n",
    "\n",
    "steps = [\n",
    "    (\"Äáº·t phÃ²ng Standard\", \"Initial booking\"),\n",
    "    (\"KhÃ¡ch sáº¡n\", \"City\"),\n",
    "    (\"18/10\", \"Check-in\"),\n",
    "    (\"20/10\", \"Check-out - should NOT loop\"),\n",
    "]\n",
    "\n",
    "for msg, note in steps:\n",
    "    history2, state2 = handle_user_message(msg, history2, state2)\n",
    "    last = history2[-1][1][:100]\n",
    "    print(f\"â†’ User: {msg} ({note})\")\n",
    "    print(f\"  Bot: {last}...\")\n",
    "\n",
    "# Verify no loop\n",
    "final_slots = state2.get(\"slots\", {})\n",
    "print(f\"\\nFinal state:\")\n",
    "print(f\"  checkin: {final_slots.get('checkin')}\")\n",
    "print(f\"  checkout: {final_slots.get('checkout')}\")\n",
    "\n",
    "if final_slots.get('checkout') == '20/10':\n",
    "    print(\"âœ… No infinite loop - checkout filled correctly\")\n",
    "else:\n",
    "    print(\"âŒ Issue: checkout not filled\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… All tests complete!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df9a7577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Regression Test: Single checkout reply no loop\n",
      "\n",
      "ğŸ¯ Intent detected: book_room\n",
      "ğŸ“Š Current slots: {\"city\": null, \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: city\n",
      "ğŸ“Š Current slots: {\"city\": \"khÃ¡ch\", \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: checkin\n",
      "ğŸ“Š Current slots: {\"city\": \"khÃ¡ch\", \"checkin\": \"18/10\", \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: checkout\n",
      "ğŸ“Š Current slots: {\"city\": \"khÃ¡ch\", \"checkin\": \"18/10\", \"checkout\": \"20/10\", \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "â“ Asking for: guest_name\n",
      "Last bot message:\n",
      " Cho em xin tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng áº¡?\n",
      "\n",
      "State slots:\n",
      " {\"city\": \"khÃ¡ch\", \"checkin\": \"18/10\", \"checkout\": \"20/10\", \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/618494449.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"slots\": BookingRequest().dict(),\n",
      "/tmp/ipykernel_1557/618494449.py:51: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  memory[\"slots\"] = updated_booking.dict()\n",
      "/tmp/ipykernel_1557/2048876677.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"ğŸ“Š Current slots: {json.dumps(booking.dict(), ensure_ascii=False)}\")\n"
     ]
    }
   ],
   "source": [
    "# Quick regression test: avoid infinite loop when answering only checkout date\n",
    "print(\"ğŸ§ª Regression Test: Single checkout reply no loop\\n\")\n",
    "state = init_memory()\n",
    "history = []\n",
    "\n",
    "# User intent to book\n",
    "history, state = handle_user_message(\"MÃ¬nh muá»‘n Ä‘áº·t phÃ²ng Standard\", history, state)\n",
    "# Provide city quickly\n",
    "history, state = handle_user_message(\"á» khÃ¡ch sáº¡n\", history, state)\n",
    "# Provide checkin\n",
    "history, state = handle_user_message(\"18/10\", history, state)\n",
    "# Now bot should ask checkout; user replies with only one date\n",
    "history, state = handle_user_message(\"20/10\", history, state)\n",
    "\n",
    "# Expect next question is guest_name (not ask checkout again)\n",
    "last_bot = history[-1][1]\n",
    "print(\"Last bot message:\\n\", (last_bot[:200] + '...') if len(last_bot) > 200 else last_bot)\n",
    "\n",
    "# Ensure state shows checkout filled\n",
    "print(\"\\nState slots:\\n\", json.dumps(state[\"slots\"], ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d07af774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760934216.124038    1557 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Google Gemini AI káº¿t ná»‘i thÃ nh cÃ´ng!\n",
      "ğŸ¤– Model: gemini-2.0-flash (latest)\n",
      "ğŸ§ª Test response: ChÃ o báº¡n! CÃ³, tÃ´i hiá»ƒu tiáº¿ng Viá»‡t. Báº¡n cáº§n tÃ´i giÃºp gÃ¬ khÃ´ng?\n",
      "...\n",
      "\n",
      "ğŸ¯ LLM_ENABLED: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GOOGLE GEMINI AI CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Láº¥y API key tá»«: https://makersuite.google.com/app/apikey\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "\n",
    "# Hoáº·c hardcode (CHá»ˆ dÃ¹ng cho development - KHÃ”NG commit vÃ o git)\n",
    "if not GEMINI_API_KEY:\n",
    "    GEMINI_API_KEY = \"AIzaSyBLzuTObWlZHqZMXcfEAfNb8qLwnfNk0zU\"\n",
    "\n",
    "LLM_ENABLED = False\n",
    "llm_model = None\n",
    "\n",
    "if GEMINI_API_KEY and GENAI_AVAILABLE:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        \n",
    "        # Sá»­ dá»¥ng Gemini 2.0 Flash (free, nhanh nháº¥t, má»›i nháº¥t)\n",
    "        llm_model = genai.GenerativeModel(\n",
    "            model_name='gemini-2.0-flash',\n",
    "            generation_config={\n",
    "                \"temperature\": 0.3,  # Low temperature cho output nháº¥t quÃ¡n\n",
    "                \"top_p\": 0.95,\n",
    "                \"top_k\": 40,\n",
    "                \"max_output_tokens\": 2048,\n",
    "            },\n",
    "            safety_settings=[\n",
    "                {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Test connection\n",
    "        test_response = llm_model.generate_content(\"Xin chÃ o, báº¡n hiá»ƒu tiáº¿ng Viá»‡t khÃ´ng?\")\n",
    "        LLM_ENABLED = True\n",
    "        print(\"âœ… Google Gemini AI káº¿t ná»‘i thÃ nh cÃ´ng!\")\n",
    "        print(f\"ğŸ¤– Model: gemini-2.0-flash (latest)\")\n",
    "        print(f\"ğŸ§ª Test response: {test_response.text[:150]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i Gemini AI: {e}\")\n",
    "        print(\"âš ï¸ Fallback sang rule-based parsing\")\n",
    "        LLM_ENABLED = False\n",
    "else:\n",
    "    if not GEMINI_API_KEY:\n",
    "        print(\"âš ï¸ ChÆ°a cáº¥u hÃ¬nh GEMINI_API_KEY\")\n",
    "        print(\"\\nğŸ“ HÆ°á»›ng dáº«n láº¥y API key:\")\n",
    "        print(\"   1. Truy cáº­p: https://makersuite.google.com/app/apikey\")\n",
    "        print(\"   2. ÄÄƒng nháº­p Google account\")\n",
    "        print(\"   3. Click 'Create API Key'\")\n",
    "        print(\"   4. Copy key\")\n",
    "    print(\"\\nâš ï¸ Há»‡ thá»‘ng sáº½ sá»­ dá»¥ng rule-based parsing\")\n",
    "\n",
    "print(f\"\\nğŸ¯ LLM_ENABLED: {LLM_ENABLED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "429dbb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM-powered Intent Detector & Slot Extractor sáºµn sÃ ng (Gemini AI)\n",
      "   Status: ğŸŸ¢ ENABLED\n"
     ]
    }
   ],
   "source": [
    "def llm_detect_intent(text: str, conversation_history: List = None) -> str:\n",
    "    \"\"\"\n",
    "    Sá»­ dá»¥ng Gemini AI Ä‘á»ƒ phÃ¡t hiá»‡n intent vá»›i ngá»¯ cáº£nh há»™i thoáº¡i\n",
    "    Returns: 'book_room', 'cancel', 'check_booking', 'unknown'\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        print(\"âš ï¸ LLM not enabled, using rule-based fallback\")\n",
    "        text_lower = text.lower()\n",
    "        if any(k in text_lower for k in [\"Ä‘áº·t\", \"book\", \"reserve\"]):\n",
    "            return \"book_room\"\n",
    "        elif any(k in text_lower for k in [\"há»§y\", \"cancel\"]):\n",
    "            return \"cancel\"\n",
    "        elif any(k in text_lower for k in [\"kiá»ƒm tra\", \"check\"]):\n",
    "            return \"check_booking\"\n",
    "        return \"unknown\"\n",
    "    \n",
    "    try:\n",
    "        # Build context\n",
    "        history_str = \"\"\n",
    "        if conversation_history and len(conversation_history) > 0:\n",
    "            history_str = \"Lá»‹ch sá»­ há»™i thoáº¡i:\\n\"\n",
    "            for role, msg in conversation_history[-5:]:  # Last 5 turns\n",
    "                history_str += f\"{'USER' if role == 'user' else 'BOT'}: {msg}\\n\"\n",
    "        else:\n",
    "            history_str = \"ÄÃ¢y lÃ  tin nháº¯n Ä‘áº§u tiÃªn trong cuá»™c trÃ² chuyá»‡n.\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"Báº¡n lÃ  trá»£ lÃ½ AI phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh khÃ¡ch hÃ ng trong há»‡ thá»‘ng Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n.\n",
    "\n",
    "{history_str}\n",
    "\n",
    "Tin nháº¯n Má»šI NHáº¤T tá»« khÃ¡ch hÃ ng:\n",
    "\"{text}\"\n",
    "\n",
    "PHÃ‚N TÃCH: XÃ¡c Ä‘á»‹nh Ã½ Ä‘á»‹nh chÃ­nh cá»§a tin nháº¯n nÃ y.\n",
    "\n",
    "QUY Táº®C Æ¯U TIÃŠN (quan trá»ng):\n",
    "1. Náº¿u tin nháº¯n chá»©a Báº¤T Ká»² thÃ´ng tin Ä‘áº·t phÃ²ng nÃ o (ngÃ y thÃ¡ng, loáº¡i phÃ²ng, Ä‘á»‹a Ä‘iá»ƒm, sá»‘ Ä‘Ãªm) â†’ \"book_room\"\n",
    "   - VÃ­ dá»¥: \"KhÃ¡ch sáº¡n cá»§a báº¡n, tá»« 18/10 Ä‘áº¿n 20/10\" â†’ book_room\n",
    "   - VÃ­ dá»¥: \"2 Ä‘Ãªm á»Ÿ ÄÃ  Láº¡t\" â†’ book_room\n",
    "   - VÃ­ dá»¥: \"Standard room\" â†’ book_room\n",
    "\n",
    "2. Náº¿u Ä‘ang trong cuá»™c trÃ² chuyá»‡n Ä‘áº·t phÃ²ng vÃ  khÃ¡ch Ä‘Æ°a thÃªm thÃ´ng tin (tráº£ lá»i cÃ¢u há»i) â†’ \"book_room\"\n",
    "   - Bot há»i vá» ngÃ y, khÃ¡ch tráº£ \"20/10\" â†’ book_room\n",
    "   - Bot há»i vá» tÃªn, khÃ¡ch tráº£ \"Nguyá»…n VÄƒn A\" â†’ book_room\n",
    "\n",
    "3. Chá»‰ tráº£ \"unknown\" khi:\n",
    "   - Lá»i chÃ o khÃ´ng liÃªn quan booking: \"Xin chÃ o\", \"Hello\"\n",
    "   - CÃ¢u há»i chung: \"GiÃ¡ phÃ²ng bao nhiÃªu?\", \"CÃ³ wifi khÃ´ng?\"\n",
    "   \n",
    "4. \"cancel\" khi khÃ¡ch muá»‘n há»§y Ä‘áº·t phÃ²ng\n",
    "5. \"check_booking\" khi khÃ¡ch muá»‘n kiá»ƒm tra booking Ä‘Ã£ Ä‘áº·t\n",
    "\n",
    "CHá»ˆ TRáº¢ Lá»œI Má»˜T Tá»ª (khÃ´ng giáº£i thÃ­ch):\n",
    "book_room\"\"\"\n",
    "\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        result = response.text.strip().lower()\n",
    "        \n",
    "        print(f\"ğŸ¤– Gemini Intent: '{text[:40]}...' â†’ {result}\")\n",
    "        \n",
    "        # Clean up response - tÃ¬m keyword\n",
    "        if \"book\" in result or \"book_room\" in result:\n",
    "            return \"book_room\"\n",
    "        elif \"cancel\" in result:\n",
    "            return \"cancel\"\n",
    "        elif \"check\" in result or \"check_booking\" in result:\n",
    "            return \"check_booking\"\n",
    "        elif \"unknown\" in result:\n",
    "            return \"unknown\"\n",
    "        else:\n",
    "            # Default to book_room náº¿u khÃ´ng cháº¯c (vÃ¬ Ä‘Ã¢y lÃ  app Ä‘áº·t phÃ²ng)\n",
    "            print(f\"âš ï¸ Unclear LLM response: '{result}', defaulting to book_room\")\n",
    "            return \"book_room\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ LLM intent detection error: {e}\")\n",
    "        # Smart fallback: náº¿u cÃ³ ngÃ y thÃ¡ng hoáº·c Ä‘á»‹a Ä‘iá»ƒm â†’ book_room\n",
    "        text_lower = text.lower()\n",
    "        if any(k in text_lower for k in [\"Ä‘áº·t\", \"book\", \"reserve\"]):\n",
    "            return \"book_room\"\n",
    "        # Check cÃ³ thÃ´ng tin ngÃ y thÃ¡ng khÃ´ng\n",
    "        if re.search(r'\\d{1,2}[/\\-]\\d{1,2}', text):\n",
    "            return \"book_room\"\n",
    "        # Check cÃ³ tá»« khÃ³a Ä‘á»‹a Ä‘iá»ƒm\n",
    "        if any(k in text_lower for k in [\"khÃ¡ch sáº¡n\", \"hotel\", \"Ä‘Ã  láº¡t\", \"hÃ  ná»™i\", \"sÃ i gÃ²n\"]):\n",
    "            return \"book_room\"\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def llm_extract_slots(text: str, current_booking: BookingRequest, expected_slot: Optional[str] = None, conversation_history: List = None) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    Sá»­ dá»¥ng Gemini AI Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin tá»« cÃ¢u nÃ³i tá»± nhiÃªn\n",
    "    Hiá»ƒu Ä‘Æ°á»£c ngá»¯ cáº£nh: \"2 Ä‘Ãªm\", \"tuáº§n sau\", \"nguyá»…n vÄƒn a\"...\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        # Fallback to rule-based\n",
    "        return extract_slots_from_text(text, current_booking)\n",
    "    \n",
    "    try:\n",
    "        # Build context\n",
    "        current_data = current_booking.dict()\n",
    "        filled_slots = {k: v for k, v in current_data.items() if v is not None}\n",
    "        \n",
    "        history_str = \"\"\n",
    "        if conversation_history:\n",
    "            history_str = \"Lá»‹ch sá»­ há»™i thoáº¡i gáº§n Ä‘Ã¢y:\\n\"\n",
    "            for role, msg in conversation_history[-4:]:\n",
    "                history_str += f\"{'USER' if role == 'user' else 'BOT'}: {msg}\\n\"\n",
    "        \n",
    "        expected_info = f\"\\nâš ï¸ QUAN TRá»ŒNG: Bot vá»«a há»i vá» slot '{expected_slot}'. Náº¿u user tráº£ lá»i ngáº¯n, Æ°u tiÃªn gÃ¡n vÃ o slot nÃ y!\" if expected_slot else \"\"\n",
    "        \n",
    "        prompt = f\"\"\"Báº¡n lÃ  trá»£ lÃ½ AI trÃ­ch xuáº¥t thÃ´ng tin Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n.\n",
    "\n",
    "{history_str}\n",
    "\n",
    "ThÃ´ng tin ÄÃƒ CÃ“:\n",
    "{json.dumps(filled_slots, ensure_ascii=False, indent=2)}\n",
    "{expected_info}\n",
    "\n",
    "Tin nháº¯n Má»šI tá»« khÃ¡ch hÃ ng:\n",
    "\"{text}\"\n",
    "\n",
    "NHIá»†M Vá»¤: TrÃ­ch xuáº¥t cÃ¡c thÃ´ng tin Ä‘áº·t phÃ²ng (náº¿u cÃ³):\n",
    "- city: thÃ nh phá»‘/Ä‘á»‹a Ä‘iá»ƒm (vÃ­ dá»¥: \"ÄÃ  Láº¡t\", \"HÃ  Ná»™i\", \"KhÃ¡ch sáº¡n cá»§a báº¡n\", \"á»Ÿ Ä‘Ã¢y\")\n",
    "- checkin: ngÃ y nháº­n phÃ²ng (format dd/mm, tÃ­nh tá»« hÃ´m nay 20/10/2025)\n",
    "- checkout: ngÃ y tráº£ phÃ²ng  \n",
    "- room_type: loáº¡i phÃ²ng (VIP, Deluxe, Standard)\n",
    "- guest_name: tÃªn ngÆ°á»i Ä‘áº·t (chuáº©n hÃ³a chá»¯ hoa: \"nguyá»…n vÄƒn a\" â†’ \"Nguyá»…n VÄƒn A\")\n",
    "- contact: sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email\n",
    "\n",
    "LÆ¯U Ã Äáº¶C BIá»†T:\n",
    "- \"tá»« 18/10 Ä‘áº¿n 20/10\" â†’ checkin=\"18/10\", checkout=\"20/10\"\n",
    "- \"18-20/10\" â†’ checkin=\"18/10\", checkout=\"20/10\"\n",
    "- \"2 Ä‘Ãªm\" tá»« ngÃ y X â†’ checkout = X + 2 ngÃ y\n",
    "- \"KhÃ¡ch sáº¡n cá»§a báº¡n\", \"á»Ÿ Ä‘Ã¢y\", \"hotel\" â†’ city=\"KhÃ¡ch sáº¡n\"\n",
    "- \"std\", \"standard\", \"thÆ°á»ng\" â†’ room_type=\"Standard\"\n",
    "- \"vip\", \"luxury\" â†’ room_type=\"VIP\"\n",
    "- Náº¿u bot há»i \"{expected_slot}\" vÃ  user tráº£ lá»i ngáº¯n â†’ Æ°u tiÃªn gÃ¡n vÃ o slot Ä‘Ã³\n",
    "\n",
    "TRáº¢ Lá»œI ÄÃšNG FORMAT JSON (khÃ´ng markdown, khÃ´ng giáº£i thÃ­ch):\n",
    "{{\n",
    "  \"city\": \"giÃ¡ trá»‹ hoáº·c null\",\n",
    "  \"checkin\": \"giÃ¡ trá»‹ hoáº·c null\",\n",
    "  \"checkout\": \"giÃ¡ trá»‹ hoáº·c null\",\n",
    "  \"room_type\": \"giÃ¡ trá»‹ hoáº·c null\",\n",
    "  \"guest_name\": \"giÃ¡ trá»‹ hoáº·c null\",\n",
    "  \"contact\": \"giÃ¡ trá»‹ hoáº·c null\"\n",
    "}}\"\"\"\n",
    "\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        result_text = response.text.strip()\n",
    "        \n",
    "        print(f\"ğŸ¤– Gemini Slots: {result_text[:100]}...\")\n",
    "        \n",
    "        # Extract JSON from response\n",
    "        if \"```json\" in result_text:\n",
    "            json_str = result_text.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in result_text:\n",
    "            json_str = result_text.split(\"```\")[1].split(\"```\")[0]\n",
    "        else:\n",
    "            json_str = result_text\n",
    "        \n",
    "        extracted = json.loads(json_str)\n",
    "        \n",
    "        # Update booking with extracted data\n",
    "        for key, value in extracted.items():\n",
    "            if value and value != \"null\" and hasattr(current_booking, key):\n",
    "                current_value = getattr(current_booking, key)\n",
    "                if not current_value:  # Only update if not already filled\n",
    "                    setattr(current_booking, key, value)\n",
    "        \n",
    "        print(f\"âœ… Extracted: {json.dumps({k:v for k,v in extracted.items() if v and v != 'null'}, ensure_ascii=False)}\")\n",
    "        \n",
    "        return current_booking\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ LLM slot extraction error: {e}\")\n",
    "        if 'result_text' in locals():\n",
    "            print(f\"   Response: {result_text[:200]}\")\n",
    "        # Fallback to rule-based\n",
    "        return extract_slots_from_text(text, current_booking)\n",
    "\n",
    "\n",
    "print(\"âœ… LLM-powered Intent Detector & Slot Extractor sáºµn sÃ ng (Gemini AI)\")\n",
    "print(f\"   Status: {'ğŸŸ¢ ENABLED' if LLM_ENABLED else 'ğŸ”´ DISABLED (fallback to rules)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1635bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Question Generator sáºµn sÃ ng (LLM + API tÆ° váº¥n)\n"
     ]
    }
   ],
   "source": [
    "def generate_question(missing_slot: str, current_data: Dict, conversation_history: List, asked_slots: set) -> str:\n",
    "    \"\"\"\n",
    "    Sinh cÃ¢u há»i tá»± nhiÃªn Ä‘á»ƒ há»i slot cÃ²n thiáº¿u\n",
    "    Vá»›i LLM: cÃ¢u há»i sáº½ contextual vÃ  tá»± nhiÃªn hÆ¡n\n",
    "    KhÃ´ng LLM: dÃ¹ng template cÃ³ sáºµn\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        # Fallback: template questions\n",
    "        if missing_slot == \"room_type\":\n",
    "            return consultant_room_type_prompt()  # Gá»i hÃ m tÆ° váº¥n tá»« API\n",
    "        return SLOT_QUESTIONS.get(missing_slot, \"Vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin.\")\n",
    "    \n",
    "    try:\n",
    "        # Náº¿u lÃ  room_type, luÃ´n dÃ¹ng tÆ° váº¥n tá»« API\n",
    "        if missing_slot == \"room_type\":\n",
    "            return consultant_room_type_prompt()\n",
    "        \n",
    "        # Build context\n",
    "        filled = {k: v for k, v in current_data.items() if v}\n",
    "        history_str = \"\\n\".join([\n",
    "            f\"{'USER' if role == 'user' else 'BOT'}: {msg}\" \n",
    "            for role, msg in conversation_history[-3:]\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"Báº¡n lÃ  chatbot Ä‘áº·t phÃ²ng khÃ¡ch sáº¡n thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p.\n",
    "\n",
    "Lá»‹ch sá»­ há»™i thoáº¡i:\n",
    "{history_str}\n",
    "\n",
    "ThÃ´ng tin Ä‘Ã£ cÃ³:\n",
    "{json.dumps(filled, ensure_ascii=False, indent=2)}\n",
    "\n",
    "Báº¡n cáº§n há»i thÃªm: {missing_slot}\n",
    "\n",
    "Slot meanings:\n",
    "- city: thÃ nh phá»‘/Ä‘á»‹a Ä‘iá»ƒm khÃ¡ch sáº¡n\n",
    "- checkin: ngÃ y nháº­n phÃ²ng\n",
    "- checkout: ngÃ y tráº£ phÃ²ng\n",
    "- guest_name: tÃªn ngÆ°á»i Ä‘áº·t phÃ²ng\n",
    "- contact: sá»‘ Ä‘iá»‡n thoáº¡i hoáº·c email\n",
    "\n",
    "HÃ£y táº¡o Má»˜T cÃ¢u há»i ngáº¯n gá»n, tá»± nhiÃªn báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ há»i thÃ´ng tin \"{missing_slot}\".\n",
    "DÃ¹ng xÆ°ng hÃ´ \"em\" cho bot, \"anh/chá»‹\" cho khÃ¡ch.\n",
    "KhÃ´ng láº·p láº¡i thÃ´ng tin Ä‘Ã£ biáº¿t.\n",
    "\n",
    "Chá»‰ tráº£ lá»i cÃ¢u há»i, KHÃ”NG giáº£i thÃ­ch thÃªm.\"\"\"\n",
    "\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        question = response.text.strip()\n",
    "        \n",
    "        # Clean up\n",
    "        if question.startswith('\"') and question.endswith('\"'):\n",
    "            question = question[1:-1]\n",
    "        \n",
    "        return question\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ LLM question generation error: {e}\")\n",
    "        if missing_slot == \"room_type\":\n",
    "            return consultant_room_type_prompt()\n",
    "        return SLOT_QUESTIONS.get(missing_slot, \"Vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin.\")\n",
    "\n",
    "\n",
    "def consultant_room_type_prompt() -> str:\n",
    "    \"\"\"\n",
    "    Sinh cÃ¢u há»i tÆ° váº¥n loáº¡i phÃ²ng dá»±a trÃªn dá»¯ liá»‡u API thá»±c\n",
    "    Gá»i API Ä‘á»ƒ láº¥y danh sÃ¡ch phÃ²ng, giÃ¡, vÃ  táº¡o gá»£i Ã½\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = api_client.get_rooms(page_size=100)\n",
    "        if not result[\"success\"]:\n",
    "            raise RuntimeError(result.get(\"error\", \"API error\"))\n",
    "        \n",
    "        items = result[\"data\"].get(\"items\", [])\n",
    "        if not items:\n",
    "            return \"Anh/chá»‹ muá»‘n Ä‘áº·t loáº¡i phÃ²ng nÃ o? (VIP/Deluxe/Standard)\"\n",
    "        \n",
    "        # TÃ­nh giÃ¡ min theo loáº¡i phÃ²ng\n",
    "        prices = {}\n",
    "        for r in items:\n",
    "            name = (r.get(\"roomTypeName\") or \"\").strip()\n",
    "            price = r.get(\"basePriceNight\") or 0\n",
    "            if name and price:\n",
    "                prices[name] = min(prices.get(name, 10**12), price)\n",
    "        \n",
    "        # Táº¡o gá»£i Ã½ tÆ° váº¥n\n",
    "        lines = [\"Em cÃ³ cÃ¡c lá»±a chá»n sau Ä‘Ã¢y, anh/chá»‹ thÃ­ch phong cÃ¡ch nÃ o áº¡?\"]\n",
    "        for name, p in sorted(prices.items(), key=lambda x: x[1]):\n",
    "            bullet = \"- ğŸ’\" if any(k in name.lower() for k in [\"vip\", \"deluxe\", \"cao cáº¥p\"]) else \"- ğŸ¨\"\n",
    "            lines.append(f\"{bullet} {name}: tá»« {p:,} VNÄ/Ä‘Ãªm\")\n",
    "        \n",
    "        lines.append(\"\\n(Anh/chá»‹ cÃ³ thá»ƒ tráº£ lá»i: 'Standard' hoáº·c 'VIP' hoáº·c 'Deluxe')\")\n",
    "        return \"\\n\".join(lines)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ API consultant error: {e}\")\n",
    "        return \"Anh/chá»‹ muá»‘n Ä‘áº·t loáº¡i phÃ²ng nÃ o? (VIP/Deluxe/Standard)\"\n",
    "\n",
    "\n",
    "print(\"âœ… Question Generator sáºµn sÃ ng (LLM + API tÆ° váº¥n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284acc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ§ª TEST: Gemini Intent Detection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_cases = [\n",
    "    (\"KhÃ¡ch sáº¡n cá»§a báº¡n, tá»« 18/10 Ä‘áº¿n 20/10\", None, \"book_room\"),\n",
    "    (\"TÃ´i muá»‘n Ä‘áº·t phÃ²ng VIP\", None, \"book_room\"),\n",
    "    (\"20/10\", [(\"bot\", \"NgÃ y tráº£ phÃ²ng lÃ  ngÃ y nÃ o áº¡?\")], \"book_room\"),\n",
    "    (\"Xin chÃ o\", None, \"unknown\"),\n",
    "]\n",
    "\n",
    "for text, history, expected in test_cases:\n",
    "    result = llm_detect_intent(text, history)\n",
    "    status = \"âœ…\" if result == expected else \"âŒ\"\n",
    "    print(f\"{status} '{text[:40]}...' â†’ {result} (expected: {expected})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§ª TEST: Gemini Slot Extraction\")  \n",
    "print(\"=\"*70)\n",
    "\n",
    "test_booking = BookingRequest()\n",
    "text = \"KhÃ¡ch sáº¡n cá»§a báº¡n, tá»« 18/10 Ä‘áº¿n 20/10\"\n",
    "result = llm_extract_slots(text, test_booking, None, None)\n",
    "\n",
    "print(f\"Input: '{text}'\")\n",
    "print(f\"Extracted slots:\")\n",
    "for key, value in result.dict().items():\n",
    "    if value:\n",
    "        print(f\"  - {key}: {value}\")\n",
    "\n",
    "print(\"\\nâœ… All Gemini tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b339bfd",
   "metadata": {},
   "source": [
    "## âœ… Test Gemini Intent & Slot Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333a1ca",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ LLM-Powered Intent Detector & Slot Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e319f",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Cáº¥u hÃ¬nh Google Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93f814d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://ac849b4d27679614de.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "* Running on public URL: https://ac849b4d27679614de.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ac849b4d27679614de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://ac849b4d27679614de.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch Gradio app\n",
    "demo.launch(\n",
    "    share=True,  # Táº¡o public link náº¿u cháº¡y trÃªn Colab\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== LLM Configuration ==============\n",
    "# Sá»­ dá»¥ng Gemini (Google) - miá»…n phÃ­ vá»›i API key\n",
    "# Láº¥y API key táº¡i: https://makersuite.google.com/app/apikey\n",
    "\n",
    "# Option 1: Set environment variable (khuyáº¿n nghá»‹ cho production)\n",
    "# export GEMINI_API_KEY=\"your-api-key-here\"\n",
    "\n",
    "# Option 2: Hardcode (chá»‰ dÃ¹ng Ä‘á»ƒ test, khÃ´ng commit lÃªn Git)\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")  # Thay báº±ng key cá»§a báº¡n náº¿u cáº§n\n",
    "\n",
    "# Initialize LLM\n",
    "LLM_ENABLED = False\n",
    "llm_model = None\n",
    "\n",
    "if HAS_GEMINI and GEMINI_API_KEY:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        llm_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        # Test connection\n",
    "        response = llm_model.generate_content(\"Hello\")\n",
    "        LLM_ENABLED = True\n",
    "        print(\"âœ… LLM (Gemini) Ä‘Ã£ sáºµn sÃ ng!\")\n",
    "        print(f\"   Model: gemini-1.5-flash\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Gemini: {e}\")\n",
    "        print(\"   Há»‡ thá»‘ng sáº½ dÃ¹ng rule-based fallback\")\n",
    "else:\n",
    "    if not GEMINI_API_KEY:\n",
    "        print(\"ğŸ’¡ Äá»ƒ báº­t LLM:\")\n",
    "        print(\"   1. Láº¥y API key: https://makersuite.google.com/app/apikey\")\n",
    "        print(\"   2. Set: GEMINI_API_KEY = 'your-key-here'\")\n",
    "        print(\"   3. Cháº¡y láº¡i cell nÃ y\")\n",
    "    print(\"âš ï¸ LLM disabled - sá»­ dá»¥ng rule-based processing\")\n",
    "\n",
    "# Helper function cho LLM calls\n",
    "def call_llm(prompt: str, temperature: float = 0.3, max_tokens: int = 500) -> Optional[str]:\n",
    "    \"\"\"Gá»i LLM vá»›i prompt, tráº£ vá» text response\"\"\"\n",
    "    if not LLM_ENABLED or not llm_model:\n",
    "        return None\n",
    "    try:\n",
    "        response = llm_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=temperature,\n",
    "                max_output_tokens=max_tokens\n",
    "            )\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM error: {e}\")\n",
    "        return None\n",
    "\n",
    "def call_llm_json(prompt: str, temperature: float = 0.1) -> Optional[Dict]:\n",
    "    \"\"\"Gá»i LLM vÃ  parse káº¿t quáº£ JSON\"\"\"\n",
    "    result = call_llm(prompt, temperature=temperature)\n",
    "    if not result:\n",
    "        return None\n",
    "    try:\n",
    "        # Extract JSON tá»« markdown code block náº¿u cÃ³\n",
    "        if \"```json\" in result:\n",
    "            json_str = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result:\n",
    "            json_str = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = result.strip()\n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ JSON parse error: {e}\")\n",
    "        print(f\"   Raw response: {result[:200]}\")\n",
    "        return None\n",
    "\n",
    "print(f\"ğŸ¤– LLM Status: {'ENABLED' if LLM_ENABLED else 'DISABLED (using fallback)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b19689",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Cáº¥u hÃ¬nh LLM (Gemini/OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa604a",
   "metadata": {},
   "source": [
    "### ğŸ“Š So sÃ¡nh cáº£i tiáº¿n\n",
    "\n",
    "| TÃ­nh nÄƒng | TrÆ°á»›c (Rule-based) | Sau (LLM-powered) |\n",
    "|-----------|-------------------|-------------------|\n",
    "| **Intent Detection** | Keyword matching | Context-aware LLM |\n",
    "| **\"20/10\" sau há»i checkout** | âŒ Nháº§m thÃ nh Ã½ Ä‘á»‹nh má»›i | âœ… Hiá»ƒu lÃ  tráº£ lá»i |\n",
    "| **Slot Extraction** | Chá»‰ xem cÃ¢u hiá»‡n táº¡i | âœ… Xem toÃ n bá»™ context |\n",
    "| **\"2 Ä‘Ãªm\", \"tuáº§n sau\"** | âŒ KhÃ´ng hiá»ƒu | âœ… Parse tá»± nhiÃªn |\n",
    "| **Lowercase name** | âš ï¸ CÃ³ thá»ƒ bá» qua | âœ… Chuáº©n hÃ³a Title Case |\n",
    "| **CÃ¢u há»i** | Fixed templates | âœ… Sinh tá»± nhiÃªn theo context |\n",
    "| **TÆ° váº¥n room type** | Text Ä‘Æ¡n giáº£n | âœ… Láº¥y giÃ¡ tá»« API + gá»£i Ã½ |\n",
    "| **VÃ²ng láº·p vÃ´ háº¡n** | âš ï¸ CÃ³ thá»ƒ xáº£y ra | âœ… TrÃ¡nh vá»›i expected_slot |\n",
    "| **Hiá»ƒu typo, viáº¿t táº¯t** | âŒ | âœ… (VD: \"std\" â†’ Standard) |\n",
    "| **Chi phÃ­** | Free | Free (Gemini free tier) |\n",
    "| **Tá»‘c Ä‘á»™** | <100ms | ~1-2s |\n",
    "\n",
    "### ğŸ”§ Giáº£i phÃ¡p ká»¹ thuáº­t cho váº¥n Ä‘á» báº¡n gáº·p:\n",
    "\n",
    "**Váº¥n Ä‘á»:** VÃ²ng láº·p vÃ´ háº¡n khi tráº£ lá»i \"20/10\" cho cÃ¢u há»i checkout\n",
    "\n",
    "**NguyÃªn nhÃ¢n cÅ©:**\n",
    "- Rule-based parser chá»‰ nhÃ¬n message hiá»‡n táº¡i\n",
    "- KhÃ´ng biáº¿t bot vá»«a há»i gÃ¬\n",
    "- \"20/10\" â†’ tá»± Ä‘á»™ng gÃ¡n vÃ o `checkin` náº¿u chÆ°a cÃ³\n",
    "\n",
    "**Giáº£i phÃ¡p má»›i:**\n",
    "1. **Expected Slot Tracking:** Memory lÆ°u slot Ä‘ang há»i\n",
    "2. **LLM Context-aware:** Xem toÃ n bá»™ há»™i thoáº¡i Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh\n",
    "3. **Priority Fill:** Æ¯u tiÃªn fill expected_slot trÆ°á»›c\n",
    "4. **Asked Slots Set:** TrÃ¡nh há»i láº¡i slot Ä‘Ã£ há»i\n",
    "\n",
    "**Káº¿t quáº£:**\n",
    "```\n",
    "Bot: NgÃ y tráº£ phÃ²ng lÃ  ngÃ y nÃ o áº¡?\n",
    "User: 20/10\n",
    "â†’ LLM hiá»ƒu: Ä‘Ã¢y lÃ  tráº£ lá»i cho checkout (khÃ´ng pháº£i intent má»›i)\n",
    "â†’ Fill checkout = 20/10\n",
    "â†’ Chuyá»ƒn há»i guest_name (KHÃ”NG há»i láº¡i checkout)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd634c8",
   "metadata": {},
   "source": [
    "## ğŸ”§ Test Cases (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff178b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test toÃ n bá»™ flow vá»›i Real API\n",
    "print(\"ğŸ§ª Test Full Dialog Flow vá»›i Real API:\\n\")\n",
    "\n",
    "test_conversation = [\n",
    "    \"TÃ´i muá»‘n Ä‘áº·t phÃ²ng Standard\",\n",
    "    \"á» khÃ¡ch sáº¡n, tá»« 18/10 Ä‘áº¿n 20/10\",\n",
    "    \"Nguyá»…n VÄƒn A\",\n",
    "    \"0912345678\"\n",
    "]\n",
    "\n",
    "test_state = init_memory()\n",
    "test_history = []\n",
    "\n",
    "for i, msg in enumerate(test_conversation, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Turn {i} - User: {msg}\")\n",
    "    test_history.append((\"user\", msg))\n",
    "    test_history, test_state = handle_user_message(msg, test_history, test_state)\n",
    "    bot_response = test_history[-1][1]\n",
    "    print(f\"\\nBot: {bot_response[:200]}...\")  # Hiá»ƒn thá»‹ 200 kÃ½ tá»± Ä‘áº§u\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\\nâœ… Test completed with Real API integration!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
