{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12460780",
   "metadata": {},
   "source": [
    "# üè® Booking Chatbot Demo - AI-Powered NLU\n",
    "\n",
    "## üöÄ N√¢ng c·∫•p m·ªõi: LLM-Powered Natural Language Understanding\n",
    "\n",
    "### Ki·∫øn tr√∫c AI m·ªõi:\n",
    "```\n",
    "User ‚îÄ‚îÄ‚îÄ‚ñ∂ LLM Intent Detector ‚îÄ‚îÄ‚îÄ‚ñ∂ LLM Slot Extractor ‚îÄ‚îÄ‚îÄ‚ñ∂ Working Memory\n",
    "               ‚îÇ                          ‚îÇ                        ‚îÇ\n",
    "               ‚îÇ                          ‚îÇ                        ‚ñº\n",
    "               ‚îÇ                          ‚îÇ                  Ask Missing Info\n",
    "               ‚îÇ                          ‚ñº                        ‚îÇ\n",
    "               ‚îÇ                   (Context-aware:                 ‚îÇ\n",
    "               ‚îÇ                    xem to√†n b·ªô h·ªôi tho·∫°i)         ‚îÇ\n",
    "               ‚ñº                                                   ‚ñº\n",
    "        When all slots filled                            LLM Question Generator\n",
    "               ‚îÇ                                          (t∆∞ v·∫•n t·ª± nhi√™n)\n",
    "               ‚ñº\n",
    "          Call Real API ‚îÄ‚îÄ‚îÄ‚ñ∂ Format response ‚îÄ‚îÄ‚îÄ‚ñ∂ User\n",
    "```\n",
    "\n",
    "## ‚ú® T√≠nh nƒÉng AI n√¢ng cao:\n",
    "\n",
    "### üß† **Intent Detection (LLM-powered)**\n",
    "- Hi·ªÉu ng·ªØ c·∫£nh h·ªôi tho·∫°i (kh√¥ng ch·ªâ c√¢u hi·ªán t·∫°i)\n",
    "- Ph√¢n bi·ªát c√¢u tr·∫£ l·ªùi vs √Ω ƒë·ªãnh m·ªõi\n",
    "- VD: \"20/10\" sau c√¢u h·ªèi \"Ng√†y tr·∫£ ph√≤ng?\" ‚Üí hi·ªÉu l√† tr·∫£ l·ªùi, kh√¥ng ph·∫£i intent m·ªõi\n",
    "\n",
    "### üí¨ **Slot Extraction (Context-aware)**\n",
    "- Tr√≠ch xu·∫•t t·ª´ **to√†n b·ªô context** h·ªôi tho·∫°i\n",
    "- X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n:\n",
    "  - \"2 ƒë√™m\" ‚Üí t√≠nh checkout t·ª´ checkin\n",
    "  - \"tu·∫ßn sau\", \"cu·ªëi tu·∫ßn n√†y\" ‚Üí parse ng√†y\n",
    "  - \"18-20/10\" ‚Üí checkin=18/10, checkout=20/10\n",
    "  - \"nguy·ªÖn vƒÉn a\" (lowercase) ‚Üí chu·∫©n h√≥a \"Nguy·ªÖn VƒÉn A\"\n",
    "\n",
    "### üéØ **Conversational Question Generation**\n",
    "- Sinh c√¢u h·ªèi t·ª± nhi√™n theo context\n",
    "- T∆∞ v·∫•n th√¥ng minh:\n",
    "  - Khi h·ªèi lo·∫°i ph√≤ng ‚Üí g·ªçi API l·∫•y gi√° th·ª±c v√† g·ª£i √Ω\n",
    "  - VD: \"Em c√≥ Standard (800k/ƒë√™m), Deluxe (1.2tr/ƒë√™m), anh ch·ªçn lo·∫°i n√†o ·∫°?\"\n",
    "- Kh√¥ng h·ªèi l·∫°i th√¥ng tin ƒë√£ c√≥\n",
    "\n",
    "### üõ°Ô∏è **Fallback Rule-based**\n",
    "- T·ª± ƒë·ªông fallback n·∫øu kh√¥ng c√≥ API key\n",
    "- V·∫´n ho·∫°t ƒë·ªông t·ªët v·ªõi regex matching\n",
    "\n",
    "## üìã H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:\n",
    "\n",
    "### **Option 1: Ch·∫°y v·ªõi LLM (Khuy·∫øn ngh·ªã)**\n",
    "1. L·∫•y API key mi·ªÖn ph√≠: [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
    "2. V√†o cell **\"C·∫•u h√¨nh LLM\"**, th√™m:\n",
    "   ```python\n",
    "   GEMINI_API_KEY = \"your-api-key-here\"\n",
    "   ```\n",
    "3. Ch·∫°y l·∫°i notebook t·ª´ ƒë·∫ßu (Run All)\n",
    "4. Th∆∞·ªüng th·ª©c AI th√¥ng minh! üéâ\n",
    "\n",
    "### **Option 2: Ch·∫°y Rule-based (Kh√¥ng c·∫ßn API key)**\n",
    "- Ch·ªâ c·∫ßn ch·∫°y notebook b√¨nh th∆∞·ªùng\n",
    "- H·ªá th·ªëng t·ª± ƒë·ªông d√πng regex fallback\n",
    "\n",
    "## üé® Demo Gradio:\n",
    "- ‚úÖ Intent Detection (context-aware)\n",
    "- ‚úÖ Slot Filling (hi·ªÉu ng√¥n ng·ªØ t·ª± nhi√™n)\n",
    "- ‚úÖ Working Memory (l∆∞u tr·∫°ng th√°i)\n",
    "- ‚úÖ T∆∞ v·∫•n th√¥ng minh (d·ª±a tr√™n API th·ª±c)\n",
    "- ‚úÖ Real API Integration (`http://103.38.236.148:8080/api/Room`)\n",
    "- ‚úÖ Kh√¥ng b·ªã v√≤ng l·∫∑p v√¥ h·∫°n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471c9e5",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ C√†i ƒë·∫∑t th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c72912cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio pydantic requests google-generativeai python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e7985",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Import th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abf951b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ google-generativeai imported successfully\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "# Import Google Generative AI\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    GENAI_AVAILABLE = True\n",
    "    print(\"‚úÖ google-generativeai imported successfully\")\n",
    "except ImportError:\n",
    "    GENAI_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è google-generativeai not installed. Run: pip install google-generativeai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5819a4",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ ƒê·ªãnh nghƒ©a Schema API (Booking Request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005b4f2",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ ƒê·ªãnh nghƒ©a Schema API (Booking Request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58573956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå ƒêang k·∫øt n·ªëi v·ªõi Room API...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ K·∫øt n·ªëi API th√†nh c√¥ng!\n",
      "üìä T·ªïng s·ªë ph√≤ng trong h·ªá th·ªëng: 33\n",
      "\n",
      "üè® Ph√≤ng m·∫´u:\n",
      "  - 101: Ph√≤ng ti√™u chu·∫©n - Tr·ªëng - 800,000.0 VNƒê/ƒë√™m\n",
      "  - 1010: Ph√≤ng ti√™u chu·∫©n - B·∫£o tr√¨ - 800,000.0 VNƒê/ƒë√™m\n",
      "  - 102: Ph√≤ng ti√™u chu·∫©n - Tr·ªëng - 800,000.0 VNƒê/ƒë√™m\n"
     ]
    }
   ],
   "source": [
    "# C·∫•u h√¨nh API\n",
    "API_BASE_URL = \"http://103.38.236.148:8080/api\"\n",
    "\n",
    "class RoomAPIClient:\n",
    "    \"\"\"Client ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi Room API\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url: str = API_BASE_URL):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def get_rooms(self, room_type_id: Optional[int] = None, \n",
    "                  status_id: Optional[int] = None,\n",
    "                  min_price: Optional[float] = None,\n",
    "                  max_price: Optional[float] = None,\n",
    "                  page_index: int = 1,\n",
    "                  page_size: int = 100) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        L·∫•y danh s√°ch ph√≤ng t·ª´ API\n",
    "        \n",
    "        Parameters:\n",
    "        - room_type_id: 1 = Ph√≤ng ti√™u chu·∫©n, 2 = VIP, 3 = Deluxe, etc.\n",
    "        - status_id: 41 = Tr·ªëng, 42 = ƒê√£ ƒë·∫∑t, 43 = ƒêang s·ª≠ d·ª•ng, 45 = B·∫£o tr√¨\n",
    "        \"\"\"\n",
    "        try:\n",
    "            params = {\n",
    "                \"PageIndex\": page_index,\n",
    "                \"PageSize\": page_size\n",
    "            }\n",
    "            \n",
    "            if room_type_id:\n",
    "                params[\"RoomTypeId\"] = room_type_id\n",
    "            if status_id:\n",
    "                params[\"StatusId\"] = status_id\n",
    "            if min_price:\n",
    "                params[\"MinPrice\"] = min_price\n",
    "            if max_price:\n",
    "                params[\"MaxPrice\"] = max_price\n",
    "            \n",
    "            response = self.session.get(\n",
    "                f\"{self.base_url}/Room\",\n",
    "                params=params,\n",
    "                timeout=10\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if data.get(\"isSuccess\"):\n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"data\": data.get(\"data\", {}),\n",
    "                    \"message\": data.get(\"message\", \"\")\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"error\": data.get(\"message\", \"Unknown error\"),\n",
    "                    \"data\": None\n",
    "                }\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå API Error: {str(e)}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"data\": None\n",
    "            }\n",
    "    \n",
    "    def get_available_rooms(self, room_type_name: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"L·∫•y danh s√°ch ph√≤ng tr·ªëng\"\"\"\n",
    "        result = self.get_rooms(status_id=41)  # 41 = Tr·ªëng\n",
    "        \n",
    "        if not result[\"success\"]:\n",
    "            return []\n",
    "        \n",
    "        rooms = result[\"data\"].get(\"items\", [])\n",
    "        \n",
    "        # L·ªçc theo lo·∫°i ph√≤ng n·∫øu c√≥\n",
    "        if room_type_name:\n",
    "            room_type_map = {\n",
    "                \"VIP\": [\"vip\", \"lux\", \"luxury\", \"suite\"],\n",
    "                \"Deluxe\": [\"deluxe\", \"cao c·∫•p\"],\n",
    "                \"Standard\": [\"standard\", \"ti√™u chu·∫©n\", \"th∆∞·ªùng\"]\n",
    "            }\n",
    "            \n",
    "            keywords = room_type_map.get(room_type_name, [room_type_name.lower()])\n",
    "            rooms = [\n",
    "                r for r in rooms \n",
    "                if any(kw in r.get(\"roomTypeName\", \"\").lower() for kw in keywords)\n",
    "            ]\n",
    "        \n",
    "        return rooms\n",
    "    \n",
    "    def get_room_types_mapping(self) -> Dict[str, int]:\n",
    "        \"\"\"L·∫•y mapping gi·ªØa t√™n lo·∫°i ph√≤ng v√† RoomTypeId\"\"\"\n",
    "        result = self.get_rooms()\n",
    "        \n",
    "        if not result[\"success\"]:\n",
    "            return {}\n",
    "        \n",
    "        rooms = result[\"data\"].get(\"items\", [])\n",
    "        mapping = {}\n",
    "        \n",
    "        for room in rooms:\n",
    "            type_name = room.get(\"roomTypeName\", \"\")\n",
    "            type_id = room.get(\"roomTypeId\")\n",
    "            \n",
    "            if type_name and type_id and type_name not in mapping:\n",
    "                mapping[type_name] = type_id\n",
    "        \n",
    "        return mapping\n",
    "\n",
    "# Kh·ªüi t·∫°o API Client\n",
    "api_client = RoomAPIClient()\n",
    "\n",
    "# Test API connection\n",
    "print(\"üîå ƒêang k·∫øt n·ªëi v·ªõi Room API...\")\n",
    "test_result = api_client.get_rooms(page_size=5)\n",
    "\n",
    "if test_result[\"success\"]:\n",
    "    total_rooms = test_result[\"data\"].get(\"totalRecords\", 0)\n",
    "    print(f\"‚úÖ K·∫øt n·ªëi API th√†nh c√¥ng!\")\n",
    "    print(f\"üìä T·ªïng s·ªë ph√≤ng trong h·ªá th·ªëng: {total_rooms}\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã m·ªôt v√†i ph√≤ng m·∫´u\n",
    "    sample_rooms = test_result[\"data\"].get(\"items\", [])[:3]\n",
    "    print(f\"\\nüè® Ph√≤ng m·∫´u:\")\n",
    "    for room in sample_rooms:\n",
    "        print(f\"  - {room['roomNumber']}: {room['roomTypeName']} - {room['statusName']} - {room['basePriceNight']:,} VNƒê/ƒë√™m\")\n",
    "else:\n",
    "    print(f\"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi API: {test_result['error']}\")\n",
    "    print(\"‚ö†Ô∏è H·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng d·ªØ li·ªáu mock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adaf9ec",
   "metadata": {},
   "source": [
    "# ============== Intent Detection (LLM-powered + fallback) ==============\n",
    "\n",
    "def detect_intent_llm(text: str, conversation_history: List = None) -> str:\n",
    "    \"\"\"\n",
    "    S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√°t hi·ªán √Ω ƒë·ªãnh d·ª±a tr√™n ng·ªØ c·∫£nh h·ªôi tho·∫°i\n",
    "    Returns: 'book_room', 'cancel', 'check_booking', 'unknown'\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        return None\n",
    "    \n",
    "    # T·∫°o context t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i\n",
    "    context = \"\"\n",
    "    if conversation_history:\n",
    "        recent = conversation_history[-3:]  # 3 turns g·∫ßn nh·∫•t\n",
    "        for role, msg in recent:\n",
    "            context += f\"{role.upper()}: {msg}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"B·∫°n l√† tr·ª£ l√Ω ph√¢n lo·∫°i √Ω ƒë·ªãnh (intent) trong h·ªá th·ªëng ƒë·∫∑t ph√≤ng kh√°ch s·∫°n.\n",
    "\n",
    "L·ªãch s·ª≠ h·ªôi tho·∫°i:\n",
    "{context}\n",
    "\n",
    "C√¢u m·ªõi nh·∫•t t·ª´ kh√°ch h√†ng: \"{text}\"\n",
    "\n",
    "Ph√¢n lo·∫°i √Ω ƒë·ªãnh th√†nh M·ªòT trong c√°c lo·∫°i sau:\n",
    "- book_room: Kh√°ch mu·ªën ƒë·∫∑t ph√≤ng, book ph√≤ng, reserve ph√≤ng\n",
    "- cancel: Kh√°ch mu·ªën h·ªßy ƒë·∫∑t ph√≤ng\n",
    "- check_booking: Kh√°ch mu·ªën ki·ªÉm tra, xem th√¥ng tin ƒë·∫∑t ph√≤ng\n",
    "- unknown: Kh√¥ng r√µ √Ω ƒë·ªãnh ho·∫∑c ch·ªâ l√† c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi tr∆∞·ªõc\n",
    "\n",
    "Tr·∫£ l·ªùi ch·ªâ M·ªòT t·ª´: book_room / cancel / check_booking / unknown\"\"\"\n",
    "\n",
    "    result = call_llm(prompt, temperature=0.1, max_tokens=50)\n",
    "    if result:\n",
    "        result = result.lower().strip()\n",
    "        for intent in [\"book_room\", \"cancel\", \"check_booking\", \"unknown\"]:\n",
    "            if intent in result:\n",
    "                return intent\n",
    "    return None\n",
    "\n",
    "def detect_intent_rule_based(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Fallback: ph√°t hi·ªán √Ω ƒë·ªãnh b·∫±ng keyword matching\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Intent: ƒê·∫∑t ph√≤ng\n",
    "    booking_keywords = [\"ƒë·∫∑t\", \"book\", \"reserve\", \"mu·ªën ƒë·∫∑t\", \"ƒë·∫∑t ph√≤ng\", \"booking\"]\n",
    "    if any(keyword in text_lower for keyword in booking_keywords):\n",
    "        return \"book_room\"\n",
    "    \n",
    "    # Intent: H·ªßy ƒë·∫∑t ph√≤ng\n",
    "    cancel_keywords = [\"h·ªßy\", \"hu·ª∑\", \"cancel\"]\n",
    "    if any(keyword in text_lower for keyword in cancel_keywords):\n",
    "        return \"cancel\"\n",
    "    \n",
    "    # Intent: Ki·ªÉm tra booking\n",
    "    check_keywords = [\"ki·ªÉm tra\", \"check\", \"xem ƒë·∫∑t ph√≤ng\"]\n",
    "    if any(keyword in text_lower for keyword in check_keywords):\n",
    "        return \"check_booking\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "def detect_intent(text: str, conversation_history: List = None) -> str:\n",
    "    \"\"\"\n",
    "    Ph√°t hi·ªán √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng (LLM-first v·ªõi fallback)\n",
    "    \"\"\"\n",
    "    # Try LLM first\n",
    "    intent = detect_intent_llm(text, conversation_history)\n",
    "    \n",
    "    # Fallback to rule-based\n",
    "    if not intent:\n",
    "        intent = detect_intent_rule_based(text)\n",
    "    \n",
    "    return intent\n",
    "\n",
    "# Test Intent Detector\n",
    "print(\"üß™ Test Intent Detector (LLM-powered):\")\n",
    "test_cases = [\n",
    "    (\"T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP\", None),\n",
    "    (\"H·ªßy ƒë·∫∑t ph√≤ng gi√∫p t√¥i\", None),\n",
    "    (\"Ki·ªÉm tra booking c·ªßa t√¥i\", None),\n",
    "    (\"20/10\", [(\"bot\", \"Ng√†y tr·∫£ ph√≤ng l√† ng√†y n√†o ·∫°?\")]),  # Context-aware\n",
    "]\n",
    "for text, history in test_cases:\n",
    "    intent = detect_intent(text, history)\n",
    "    mode = \"LLM\" if LLM_ENABLED else \"Rule\"\n",
    "    print(f\"  [{mode}] '{text}' ‚Üí {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de09761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a\n",
      "C√°c slot b·∫Øt bu·ªôc: ['city', 'checkin', 'checkout', 'room_type', 'guest_name']\n"
     ]
    }
   ],
   "source": [
    "class BookingRequest(BaseModel):\n",
    "    \"\"\"Schema cho y√™u c·∫ßu ƒë·∫∑t ph√≤ng\"\"\"\n",
    "    city: Optional[str] = Field(None, description=\"Th√†nh ph·ªë\")\n",
    "    checkin: Optional[str] = Field(None, description=\"Ng√†y nh·∫≠n ph√≤ng\")\n",
    "    checkout: Optional[str] = Field(None, description=\"Ng√†y tr·∫£ ph√≤ng\")\n",
    "    room_type: Optional[str] = Field(None, description=\"Lo·∫°i ph√≤ng (VIP/Standard/Deluxe)\")\n",
    "    guest_name: Optional[str] = Field(None, description=\"T√™n ng∆∞·ªùi ƒë·∫∑t\")\n",
    "    contact: Optional[str] = Field(None, description=\"S·ªë ƒëi·ªán tho·∫°i ho·∫∑c email\")\n",
    "    \n",
    "    # Th√¥ng tin b·ªï sung t·ª´ API\n",
    "    room_id: Optional[int] = Field(None, description=\"ID ph√≤ng ƒë∆∞·ª£c ch·ªçn\")\n",
    "    room_number: Optional[str] = Field(None, description=\"S·ªë ph√≤ng\")\n",
    "    price_per_night: Optional[float] = Field(None, description=\"Gi√° ph√≤ng/ƒë√™m\")\n",
    "\n",
    "# C√°c slot b·∫Øt bu·ªôc ph·∫£i c√≥\n",
    "REQUIRED_SLOTS = [\"city\", \"checkin\", \"checkout\", \"room_type\", \"guest_name\"]\n",
    "\n",
    "print(\"‚úÖ Schema ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a\")\n",
    "print(f\"C√°c slot b·∫Øt bu·ªôc: {REQUIRED_SLOTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009cc65",
   "metadata": {},
   "source": [
    "# ============== Slot Extraction (LLM-powered + fallback) ==============\n",
    "\n",
    "def extract_slots_llm(text: str, current_slots: Dict, conversation_history: List = None, expected_slot: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    S·ª≠ d·ª•ng LLM ƒë·ªÉ tr√≠ch xu·∫•t slots t·ª´ ng·ªØ c·∫£nh t·ª± nhi√™n\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        return None\n",
    "    \n",
    "    # Context t·ª´ l·ªãch s·ª≠\n",
    "    context = \"\"\n",
    "    if conversation_history:\n",
    "        recent = conversation_history[-5:]\n",
    "        for role, msg in recent:\n",
    "            context += f\"{role.upper()}: {msg}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"B·∫°n l√† tr·ª£ l√Ω tr√≠ch xu·∫•t th√¥ng tin ƒë·∫∑t ph√≤ng kh√°ch s·∫°n t·ª´ h·ªôi tho·∫°i ti·∫øng Vi·ªát.\n",
    "\n",
    "L·ªãch s·ª≠ h·ªôi tho·∫°i:\n",
    "{context}\n",
    "\n",
    "C√¢u m·ªõi nh·∫•t: \"{text}\"\n",
    "\n",
    "Th√¥ng tin hi·ªán c√≥:\n",
    "{json.dumps(current_slots, ensure_ascii=False, indent=2)}\n",
    "\n",
    "{\"Bot v·ª´a h·ªèi v·ªÅ: \" + expected_slot if expected_slot else \"\"}\n",
    "\n",
    "Tr√≠ch xu·∫•t c√°c th√¥ng tin sau (gi·ªØ nguy√™n gi√° tr·ªã c≈© n·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin m·ªõi):\n",
    "- city: Th√†nh ph·ªë (v√≠ d·ª•: \"ƒê√† L·∫°t\", \"H√† N·ªôi\", \"TP HCM\")\n",
    "- checkin: Ng√†y nh·∫≠n ph√≤ng (format: dd/mm ho·∫∑c dd/mm/yyyy)\n",
    "- checkout: Ng√†y tr·∫£ ph√≤ng (format: dd/mm ho·∫∑c dd/mm/yyyy)\n",
    "- room_type: Lo·∫°i ph√≤ng (\"Standard\", \"VIP\", \"Deluxe\")\n",
    "- guest_name: T√™n kh√°ch h√†ng (h·ªç t√™n ƒë·∫ßy ƒë·ªß)\n",
    "- contact: S·ªë ƒëi·ªán tho·∫°i ho·∫∑c email\n",
    "\n",
    "L∆∞u √Ω ƒë·∫∑c bi·ªát:\n",
    "- N·∫øu ch·ªâ c√≥ 1 ng√†y v√† checkin ƒë√£ c√≥ ‚Üí g√°n v√†o checkout\n",
    "- N·∫øu c√≥ c·ª•m \"18-20/10\" ho·∫∑c \"t·ª´ 18 ƒë·∫øn 20/10\" ‚Üí checkin=18/10, checkout=20/10\n",
    "- N·∫øu n√≥i \"2 ƒë√™m\" ho·∫∑c \"3 ng√†y\" ‚Üí t√≠nh checkout t·ª´ checkin\n",
    "- Ch·∫•p nh·∫≠n t√™n vi·∫øt th∆∞·ªùng ho·∫∑c hoa (chu·∫©n h√≥a v·ªÅ Title Case)\n",
    "- Room type: map \"ti√™u chu·∫©n\"‚Üí\"Standard\", \"cao c·∫•p\"‚Üí\"Deluxe\", \"vip/suite\"‚Üí\"VIP\"\n",
    "\n",
    "Tr·∫£ v·ªÅ JSON v·ªõi c√°c key tr√™n (null n·∫øu kh√¥ng c√≥):\n",
    "```json\n",
    "{{\n",
    "  \"city\": \"...\",\n",
    "  \"checkin\": \"...\",\n",
    "  \"checkout\": \"...\",\n",
    "  \"room_type\": \"...\",\n",
    "  \"guest_name\": \"...\",\n",
    "  \"contact\": \"...\"\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "    result = call_llm_json(prompt)\n",
    "    if result:\n",
    "        # Merge v·ªõi current_slots (gi·ªØ gi√° tr·ªã c≈© n·∫øu LLM tr·∫£ v·ªÅ null)\n",
    "        for key in [\"city\", \"checkin\", \"checkout\", \"room_type\", \"guest_name\", \"contact\"]:\n",
    "            if result.get(key):\n",
    "                current_slots[key] = result[key]\n",
    "        return current_slots\n",
    "    return None\n",
    "\n",
    "def extract_slots_from_text(text: str, current: BookingRequest) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    Fallback: Tr√≠ch xu·∫•t th√¥ng tin b·∫±ng regex (rule-based)\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 1. Tr√≠ch xu·∫•t Th√†nh ph·ªë\n",
    "    if not current.city:\n",
    "        city_patterns = [\n",
    "            r\"·ªü\\s+([A-Za-z√Ä-·ªπ\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"t·∫°i\\s+([A-Za-z√Ä-·ªπ\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"(H√† N·ªôi|ƒê√† L·∫°t|S√†i G√≤n|TP HCM|ƒê√† N·∫µng|Nha Trang|Ph√∫ Qu·ªëc|V≈©ng T√†u|H·ªôi An)\"\n",
    "        ]\n",
    "        for pattern in city_patterns:\n",
    "            match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                city = match.group(1).strip()\n",
    "                if len(city) <= 40:\n",
    "                    current.city = city\n",
    "                    break\n",
    "    \n",
    "    # 2. Tr√≠ch xu·∫•t Ng√†y\n",
    "    range_match = re.search(r\"(\\d{1,2})\\s*[‚Äì‚Äî-]\\s*(\\d{1,2})[/\\-](\\d{1,2})\", text)\n",
    "    if range_match and not current.checkin:\n",
    "        day1, day2, month = range_match.groups()\n",
    "        current.checkin = f\"{day1}/{month}\"\n",
    "        current.checkout = f\"{day2}/{month}\"\n",
    "    else:\n",
    "        dates = re.findall(r\"(\\d{1,2}[/\\-]\\d{1,2}(?:[/\\-]\\d{2,4})?)\", text)\n",
    "        if dates:\n",
    "            if len(dates) == 1:\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                elif not current.checkout:\n",
    "                    # N·∫øu ƒë√£ c√≥ checkin, g√°n v√†o checkout\n",
    "                    current.checkout = dates[0]\n",
    "            else:\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                if not current.checkout:\n",
    "                    current.checkout = dates[1]\n",
    "    \n",
    "    # 3. Lo·∫°i ph√≤ng\n",
    "    if not current.room_type:\n",
    "        room_patterns = {\n",
    "            \"VIP\": r\"\\b(vip|lux|luxury|suite)\\b\",\n",
    "            \"Deluxe\": r\"\\b(deluxe|cao c·∫•p)\\b\",\n",
    "            \"Standard\": r\"\\b(standard|normal|th∆∞·ªùng|ti√™u chu·∫©n)\\b\"\n",
    "        }\n",
    "        for room_type, pattern in room_patterns.items():\n",
    "            if re.search(pattern, text, flags=re.IGNORECASE):\n",
    "                current.room_type = room_type\n",
    "                break\n",
    "    \n",
    "    # 4. T√™n kh√°ch\n",
    "    if not current.guest_name:\n",
    "        name_patterns = [\n",
    "            r\"t√™n l√†\\s+([A-Z√Ä-·ª∏][A-Za-z√Ä-·ªπ\\s]{1,40})\",\n",
    "            r\"t√™n\\s+([A-Z√Ä-·ª∏][A-Za-z√Ä-·ªπ\\s]{1,40})\",\n",
    "            r\"l√†\\s+([A-Z√Ä-·ª∏][A-Za-z√Ä-·ªπ\\s]{2,40})$\",\n",
    "            r\"^([A-Z√Ä-·ª∏][a-z√†-·ªπ]+(?:\\s+[A-Z√Ä-·ª∏][a-z√†-·ªπ]+)+)$\"\n",
    "        ]\n",
    "        for pattern in name_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                name = match.group(1).strip()\n",
    "                if len(name.split()) >= 2 and not any(char.isdigit() for char in name):\n",
    "                    current.guest_name = name\n",
    "                    break\n",
    "    \n",
    "    # 5. Contact\n",
    "    if not current.contact:\n",
    "        email_match = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\", text)\n",
    "        if email_match:\n",
    "            current.contact = email_match.group(0)\n",
    "        else:\n",
    "            phone_match = re.search(r\"(\\+?84|0)\\s*[\\d\\-\\s]{8,12}\", text)\n",
    "            if phone_match:\n",
    "                current.contact = phone_match.group(0)\n",
    "    \n",
    "    return current\n",
    "\n",
    "def extract_slots(text: str, current: BookingRequest, conversation_history: List = None, expected_slot: str = None) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t slots (LLM-first v·ªõi fallback)\n",
    "    \"\"\"\n",
    "    current_dict = current.dict()\n",
    "    \n",
    "    # Try LLM first\n",
    "    llm_result = extract_slots_llm(text, current_dict, conversation_history, expected_slot)\n",
    "    \n",
    "    if llm_result:\n",
    "        # Update BookingRequest v·ªõi k·∫øt qu·∫£ t·ª´ LLM\n",
    "        for key, value in llm_result.items():\n",
    "            if value and hasattr(current, key):\n",
    "                setattr(current, key, value)\n",
    "        return current\n",
    "    \n",
    "    # Fallback to rule-based\n",
    "    return extract_slots_from_text(text, current)\n",
    "\n",
    "# Test Slot Filler\n",
    "print(\"üß™ Test Slot Filler (LLM-powered):\")\n",
    "test_booking = BookingRequest()\n",
    "test_text = \"T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP ·ªü ƒê√† L·∫°t ng√†y 18‚Äì20/10 cho Nguy·ªÖn VƒÉn A\"\n",
    "result = extract_slots(test_text, test_booking)\n",
    "mode = \"LLM\" if LLM_ENABLED else \"Rule\"\n",
    "print(f\"  [{mode}] Input: '{test_text}'\")\n",
    "print(f\"  Extracted: {json.dumps(result.dict(), indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1e4c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test Intent Detector:\n",
      "  'T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP' ‚Üí Intent: book_room\n",
      "  'H·ªßy ƒë·∫∑t ph√≤ng gi√∫p t√¥i' ‚Üí Intent: book_room\n",
      "  'Ki·ªÉm tra booking c·ªßa t√¥i' ‚Üí Intent: book_room\n",
      "  'Xin ch√†o' ‚Üí Intent: unknown\n"
     ]
    }
   ],
   "source": [
    "def detect_intent(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Ph√°t hi·ªán √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng\n",
    "    Returns: 'book_room', 'cancel', 'check_booking', 'unknown'\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Intent: ƒê·∫∑t ph√≤ng\n",
    "    booking_keywords = [\"ƒë·∫∑t\", \"book\", \"reserve\", \"mu·ªën ƒë·∫∑t\", \"ƒë·∫∑t ph√≤ng\", \"booking\"]\n",
    "    if any(keyword in text_lower for keyword in booking_keywords):\n",
    "        return \"book_room\"\n",
    "    \n",
    "    # Intent: H·ªßy ƒë·∫∑t ph√≤ng\n",
    "    cancel_keywords = [\"h·ªßy\", \"hu·ª∑\", \"cancel\"]\n",
    "    if any(keyword in text_lower for keyword in cancel_keywords):\n",
    "        return \"cancel\"\n",
    "    \n",
    "    # Intent: Ki·ªÉm tra booking\n",
    "    check_keywords = [\"ki·ªÉm tra\", \"check\", \"xem ƒë·∫∑t ph√≤ng\"]\n",
    "    if any(keyword in text_lower for keyword in check_keywords):\n",
    "        return \"check_booking\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "# Test Intent Detector\n",
    "print(\"üß™ Test Intent Detector:\")\n",
    "test_cases = [\n",
    "    \"T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP\",\n",
    "    \"H·ªßy ƒë·∫∑t ph√≤ng gi√∫p t√¥i\",\n",
    "    \"Ki·ªÉm tra booking c·ªßa t√¥i\",\n",
    "    \"Xin ch√†o\"\n",
    "]\n",
    "for text in test_cases:\n",
    "    intent = detect_intent(text)\n",
    "    print(f\"  '{text}' ‚Üí Intent: {intent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba69490",
   "metadata": {},
   "source": [
    "# ============== Working Memory & Question Generation ==============\n",
    "\n",
    "# C√¢u h·ªèi fallback cho t·ª´ng slot\n",
    "SLOT_QUESTIONS = {\n",
    "    \"city\": \"Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?\",\n",
    "    \"checkin\": \"Ng√†y nh·∫≠n ph√≤ng l√† ng√†y n√†o ·∫°? (VD: 18/10 ho·∫∑c 18-10-2025)\",\n",
    "    \"checkout\": \"Ng√†y tr·∫£ ph√≤ng l√† ng√†y n√†o ·∫°?\",\n",
    "    \"room_type\": \"Anh/ch·ªã mu·ªën ƒë·∫∑t lo·∫°i ph√≤ng n√†o? (VIP/Deluxe/Standard)\",\n",
    "    \"guest_name\": \"Cho em xin t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng ·∫°?\",\n",
    "    \"contact\": \"Cho em xin s·ªë ƒëi·ªán tho·∫°i ho·∫∑c email ƒë·ªÉ li√™n h·ªá ƒë∆∞·ª£c kh√¥ng ·∫°?\"\n",
    "}\n",
    "\n",
    "def init_memory() -> Dict[str, Any]:\n",
    "    \"\"\"Kh·ªüi t·∫°o Working Memory\"\"\"\n",
    "    return {\n",
    "        \"intent\": None,\n",
    "        \"slots\": BookingRequest().dict(),\n",
    "        \"conversation_history\": [],\n",
    "        \"expected_slot\": None,\n",
    "        \"asked_slots\": set(),\n",
    "        \"last_bot_question\": None\n",
    "    }\n",
    "\n",
    "def next_missing_slot(booking: BookingRequest) -> Optional[str]:\n",
    "    \"\"\"T√¨m slot ti·∫øp theo c√≤n thi·∫øu\"\"\"\n",
    "    for slot in REQUIRED_SLOTS:\n",
    "        value = getattr(booking, slot)\n",
    "        if value is None or value == \"\":\n",
    "            return slot\n",
    "    if not booking.contact:\n",
    "        return \"contact\"\n",
    "    return None\n",
    "\n",
    "def build_booking_object(memory: Dict) -> BookingRequest:\n",
    "    \"\"\"X√¢y d·ª±ng BookingRequest t·ª´ memory\"\"\"\n",
    "    return BookingRequest(**memory[\"slots\"])\n",
    "\n",
    "def update_memory_with_extracted(memory: Dict, text: str) -> Dict:\n",
    "    \"\"\"C·∫≠p nh·∫≠t memory v·ªõi th√¥ng tin m·ªõi (LLM-powered)\"\"\"\n",
    "    current_booking = BookingRequest(**memory[\"slots\"])\n",
    "    updated_booking = extract_slots(\n",
    "        text, \n",
    "        current_booking,\n",
    "        conversation_history=memory.get(\"conversation_history\"),\n",
    "        expected_slot=memory.get(\"expected_slot\")\n",
    "    )\n",
    "    memory[\"slots\"] = updated_booking.dict()\n",
    "    return memory\n",
    "\n",
    "def generate_question_llm(missing_slot: str, current_slots: Dict, conversation_history: List) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Sinh c√¢u h·ªèi t·ª± nhi√™n b·∫±ng LLM d·ª±a tr√™n ng·ªØ c·∫£nh\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        return None\n",
    "    \n",
    "    # L·∫•y th√¥ng tin ph√≤ng t·ª´ API n·∫øu ƒëang h·ªèi room_type\n",
    "    room_info = \"\"\n",
    "    if missing_slot == \"room_type\":\n",
    "        try:\n",
    "            result = api_client.get_rooms(page_size=50)\n",
    "            if result[\"success\"]:\n",
    "                items = result[\"data\"].get(\"items\", [])\n",
    "                prices = {}\n",
    "                for r in items:\n",
    "                    name = (r.get(\"roomTypeName\") or \"\").strip()\n",
    "                    price = r.get(\"basePriceNight\") or 0\n",
    "                    if name:\n",
    "                        prices[name] = min(prices.get(name, 10**12), price)\n",
    "                if prices:\n",
    "                    room_info = \"\\\\n\".join([f\"- {n}: {p:,} VNƒê/ƒë√™m\" for n, p in sorted(prices.items(), key=lambda x: x[1])])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    context = \"\"\n",
    "    if conversation_history:\n",
    "        recent = conversation_history[-3:]\n",
    "        for role, msg in recent:\n",
    "            context += f\"{role.upper()}: {msg}\\\\n\"\n",
    "    \n",
    "    slot_desc = {\n",
    "        \"city\": \"th√†nh ph·ªë ƒë·∫∑t ph√≤ng\",\n",
    "        \"checkin\": \"ng√†y nh·∫≠n ph√≤ng (check-in)\",\n",
    "        \"checkout\": \"ng√†y tr·∫£ ph√≤ng (check-out)\",\n",
    "        \"room_type\": \"lo·∫°i ph√≤ng (Standard/VIP/Deluxe)\",\n",
    "        \"guest_name\": \"t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng\",\n",
    "        \"contact\": \"s·ªë ƒëi·ªán tho·∫°i ho·∫∑c email li√™n h·ªá\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"B·∫°n l√† receptionist chuy√™n nghi·ªáp t·∫°i kh√°ch s·∫°n, ƒëang t∆∞ v·∫•n ƒë·∫∑t ph√≤ng.\n",
    "\n",
    "L·ªãch s·ª≠ h·ªôi tho·∫°i:\n",
    "{context}\n",
    "\n",
    "Th√¥ng tin ƒë√£ c√≥:\n",
    "{json.dumps({k: v for k, v in current_slots.items() if v}, ensure_ascii=False)}\n",
    "\n",
    "B·∫°n c·∫ßn h·ªèi kh√°ch v·ªÅ: {slot_desc.get(missing_slot, missing_slot)}\n",
    "\n",
    "{f\"Th√¥ng tin c√°c lo·∫°i ph√≤ng hi·ªán c√≥:\\\\n{room_info}\" if room_info else \"\"}\n",
    "\n",
    "H√£y t·∫°o M·ªòT c√¢u h·ªèi t·ª± nhi√™n, th√¢n thi·ªán, ng·∫Øn g·ªçn (1-2 c√¢u) ƒë·ªÉ h·ªèi th√¥ng tin c√≤n thi·∫øu.\n",
    "- N·∫øu h·ªèi lo·∫°i ph√≤ng v√† c√≥ th√¥ng tin gi√°: ƒë∆∞a ra 2-3 l·ª±a ch·ªçn v·ªõi gi√° ƒë·ªÉ kh√°ch d·ªÖ ch·ªçn\n",
    "- Tone: l·ªãch s·ª±, chuy√™n nghi·ªáp, t·ª± nhi√™n nh∆∞ ng∆∞·ªùi th·∫≠t\n",
    "- KH√îNG h·ªèi l·∫°i th√¥ng tin ƒë√£ c√≥\n",
    "\n",
    "Tr·∫£ l·ªùi ch·ªâ c√¢u h·ªèi (kh√¥ng gi·∫£i th√≠ch):\"\"\"\n",
    "\n",
    "    return call_llm(prompt, temperature=0.7, max_tokens=200)\n",
    "\n",
    "def generate_question(missing_slot: str, current_slots: Dict, conversation_history: List, asked_slots: set) -> str:\n",
    "    \"\"\"\n",
    "    Sinh c√¢u h·ªèi cho slot c√≤n thi·∫øu (LLM-first v·ªõi fallback)\n",
    "    \"\"\"\n",
    "    # Tr√°nh h·ªèi l·∫°i n·∫øu v·ª´a h·ªèi\n",
    "    if missing_slot in asked_slots:\n",
    "        # ƒê√£ h·ªèi r·ªìi nh∆∞ng ch∆∞a ƒëi·ªÅn ƒë∆∞·ª£c ‚Üí h·ªèi l·∫°i v·ªõi c√°ch kh√°c\n",
    "        if LLM_ENABLED:\n",
    "            q = generate_question_llm(missing_slot, current_slots, conversation_history)\n",
    "            if q:\n",
    "                return q\n",
    "    \n",
    "    # Try LLM\n",
    "    if LLM_ENABLED and missing_slot == \"room_type\":\n",
    "        # Lu√¥n d√πng LLM cho room_type ƒë·ªÉ t∆∞ v·∫•n t·ªët h∆°n\n",
    "        q = generate_question_llm(missing_slot, current_slots, conversation_history)\n",
    "        if q:\n",
    "            return q\n",
    "    \n",
    "    # Fallback\n",
    "    return SLOT_QUESTIONS.get(missing_slot, \"Vui l√≤ng cung c·∫•p th√™m th√¥ng tin.\")\n",
    "\n",
    "print(\"‚úÖ Working Memory & Question Generator (LLM-powered)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "813b7862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test Slot Filler:\n",
      "  Input: 'T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP ·ªü ƒê√† L·∫°t ng√†y 18‚Äì20/10'\n",
      "  Extracted: {\n",
      "  \"city\": \"ƒê√†\",\n",
      "  \"checkin\": \"18/10\",\n",
      "  \"checkout\": \"20/10\",\n",
      "  \"room_type\": \"VIP\",\n",
      "  \"guest_name\": null,\n",
      "  \"contact\": null,\n",
      "  \"room_id\": null,\n",
      "  \"room_number\": null,\n",
      "  \"price_per_night\": null\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/4041408505.py:98: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"  Extracted: {json.dumps(result.dict(), indent=2, ensure_ascii=False)}\")\n"
     ]
    }
   ],
   "source": [
    "def extract_slots_from_text(text: str, current: BookingRequest) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t th√¥ng tin t·ª´ text ng∆∞·ªùi d√πng v√† c·∫≠p nh·∫≠t v√†o BookingRequest\n",
    "    S·ª≠ d·ª•ng regex v√† rule-based matching\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # 1. Tr√≠ch xu·∫•t Th√†nh ph·ªë\n",
    "    if not current.city:\n",
    "        # Pattern: \"·ªü <City>\" ho·∫∑c \"t·∫°i <City>\"\n",
    "        city_patterns = [\n",
    "            r\"·ªü\\s+([A-Za-z√Ä-·ªπ\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"t·∫°i\\s+([A-Za-z√Ä-·ªπ\\s]+?)(?:\\s|,|\\.|$)\",\n",
    "            r\"(H√† N·ªôi|ƒê√† L·∫°t|S√†i G√≤n|TP HCM|ƒê√† N·∫µng|Nha Trang|Ph√∫ Qu·ªëc|V≈©ng T√†u|H·ªôi An)\"\n",
    "        ]\n",
    "        for pattern in city_patterns:\n",
    "            match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                city = match.group(1).strip()\n",
    "                if len(city) <= 40:\n",
    "                    current.city = city\n",
    "                    break\n",
    "    \n",
    "    # 2. Tr√≠ch xu·∫•t Ng√†y (checkin/checkout)\n",
    "    # Pattern: dd/mm, dd-mm, yyyy-mm-dd, \"18‚Äì20/10\", \"t·ª´ 18 ƒë·∫øn 20\"\n",
    "    \n",
    "    # T√¨m pattern \"18‚Äì20/10\" ho·∫∑c \"t·ª´ 18 ƒë·∫øn 20/10\"\n",
    "    range_match = re.search(r\"(\\d{1,2})\\s*[‚Äì‚Äî-]\\s*(\\d{1,2})[/\\-](\\d{1,2})\", text)\n",
    "    if range_match and not current.checkin:\n",
    "        day1, day2, month = range_match.groups()\n",
    "        current.checkin = f\"{day1}/{month}\"\n",
    "        current.checkout = f\"{day2}/{month}\"\n",
    "    else:\n",
    "        # T√¨m t·∫•t c·∫£ ng√†y d·∫°ng dd/mm\n",
    "        dates = re.findall(r\"(\\d{1,2}[/\\-]\\d{1,2}(?:[/\\-]\\d{2,4})?)\", text)\n",
    "        if dates:\n",
    "            if len(dates) == 1:\n",
    "                # QUAN TR·ªåNG: N·∫øu ƒë√£ c√≥ checkin r·ªìi, g√°n v√†o checkout\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                elif not current.checkout:\n",
    "                    current.checkout = dates[0]\n",
    "            elif len(dates) >= 2:\n",
    "                if not current.checkin:\n",
    "                    current.checkin = dates[0]\n",
    "                if not current.checkout:\n",
    "                    current.checkout = dates[1]\n",
    "    \n",
    "    # 3. Tr√≠ch xu·∫•t Lo·∫°i ph√≤ng\n",
    "    if not current.room_type:\n",
    "        room_patterns = {\n",
    "            \"VIP\": r\"\\b(vip|lux|luxury|suite)\\b\",\n",
    "            \"Deluxe\": r\"\\b(deluxe|cao c·∫•p)\\b\",\n",
    "            \"Standard\": r\"\\b(standard|normal|th∆∞·ªùng|ti√™u chu·∫©n)\\b\"\n",
    "        }\n",
    "        for room_type, pattern in room_patterns.items():\n",
    "            if re.search(pattern, text, flags=re.IGNORECASE):\n",
    "                current.room_type = room_type\n",
    "                break\n",
    "    \n",
    "    # 4. Tr√≠ch xu·∫•t T√™n ng∆∞·ªùi ƒë·∫∑t\n",
    "    if not current.guest_name:\n",
    "        name_patterns = [\n",
    "            r\"t√™n l√†\\s+([A-Z√Ä-·ª∏][A-Za-z√Ä-·ªπ\\s]{1,40})\",\n",
    "            r\"t√™n\\s+([A-Z√Ä-·ª∏][A-Za-z√Ä-·ªπ\\s]{1,40})\",\n",
    "            r\"l√†\\s+([A-Z√Ä-·ª∏][A-Za-z√Ä-·ªπ\\s]{2,40})$\",\n",
    "            r\"^([A-Z√Ä-·ª∏][a-z√†-·ªπ]+(?:\\s+[A-Z√Ä-·ª∏][a-z√†-·ªπ]+)+)$\"\n",
    "        ]\n",
    "        for pattern in name_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                name = match.group(1).strip()\n",
    "                # Validate name (kh√¥ng ch·ª©a s·ªë, √≠t nh·∫•t 2 t·ª´)\n",
    "                if len(name.split()) >= 2 and not any(char.isdigit() for char in name):\n",
    "                    current.guest_name = name\n",
    "                    break\n",
    "    \n",
    "    # 5. Tr√≠ch xu·∫•t Contact (Email ho·∫∑c Phone)\n",
    "    if not current.contact:\n",
    "        # Email\n",
    "        email_match = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\", text)\n",
    "        if email_match:\n",
    "            current.contact = email_match.group(0)\n",
    "        else:\n",
    "            # Phone number\n",
    "            phone_match = re.search(r\"(\\+?84|0)\\s*[\\d\\-\\s]{8,12}\", text)\n",
    "            if phone_match:\n",
    "                current.contact = phone_match.group(0)\n",
    "    \n",
    "    return current\n",
    "\n",
    "# Test Slot Filler\n",
    "print(\"üß™ Test Slot Filler:\")\n",
    "test_booking = BookingRequest()\n",
    "test_text = \"T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP ·ªü ƒê√† L·∫°t ng√†y 18‚Äì20/10\"\n",
    "result = extract_slots_from_text(test_text, test_booking)\n",
    "print(f\"  Input: '{test_text}'\")\n",
    "print(f\"  Extracted: {json.dumps(result.dict(), indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d16877",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Working Memory & Slot Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "837798be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Working Memory ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh (v·ªõi LLM integration)\n"
     ]
    }
   ],
   "source": [
    "# C√¢u h·ªèi cho t·ª´ng slot c√≤n thi·∫øu\n",
    "SLOT_QUESTIONS = {\n",
    "    \"city\": \"Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?\",\n",
    "    \"checkin\": \"Ng√†y nh·∫≠n ph√≤ng l√† ng√†y n√†o ·∫°? (VD: 18/10 ho·∫∑c 18-10-2025)\",\n",
    "    \"checkout\": \"Ng√†y tr·∫£ ph√≤ng l√† ng√†y n√†o ·∫°?\",\n",
    "    \"room_type\": \"Anh/ch·ªã mu·ªën ƒë·∫∑t lo·∫°i ph√≤ng n√†o? (VIP/Deluxe/Standard)\",\n",
    "    \"guest_name\": \"Cho em xin t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng ·∫°?\",\n",
    "    \"contact\": \"Cho em xin s·ªë ƒëi·ªán tho·∫°i ho·∫∑c email ƒë·ªÉ li√™n h·ªá ƒë∆∞·ª£c kh√¥ng ·∫°?\"\n",
    "}\n",
    "\n",
    "def init_memory() -> Dict[str, Any]:\n",
    "    \"\"\"Kh·ªüi t·∫°o Working Memory\"\"\"\n",
    "    return {\n",
    "        \"intent\": None,\n",
    "        \"slots\": BookingRequest().dict(),\n",
    "        \"conversation_history\": [],\n",
    "        \"expected_slot\": None,  # Slot ƒëang ch·ªù user tr·∫£ l·ªùi\n",
    "    }\n",
    "\n",
    "def next_missing_slot(booking: BookingRequest) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    T√¨m slot ti·∫øp theo c√≤n thi·∫øu\n",
    "    Returns: t√™n slot ho·∫∑c None n·∫øu ƒë√£ ƒë·ªß\n",
    "    \"\"\"\n",
    "    for slot in REQUIRED_SLOTS:\n",
    "        value = getattr(booking, slot)\n",
    "        if value is None or value == \"\":\n",
    "            return slot\n",
    "    \n",
    "    # Contact l√† optional nh∆∞ng n√™n h·ªèi\n",
    "    if not booking.contact:\n",
    "        return \"contact\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "def build_booking_object(memory: Dict) -> BookingRequest:\n",
    "    \"\"\"X√¢y d·ª±ng BookingRequest t·ª´ memory\"\"\"\n",
    "    return BookingRequest(**memory[\"slots\"])\n",
    "\n",
    "def update_memory_with_extracted(memory: Dict, text: str) -> Dict:\n",
    "    \"\"\"C·∫≠p nh·∫≠t memory v·ªõi th√¥ng tin m·ªõi tr√≠ch xu·∫•t ƒë∆∞·ª£c - LLM-powered\"\"\"\n",
    "    current_booking = BookingRequest(**memory[\"slots\"])\n",
    "    expected_slot = memory.get(\"expected_slot\")\n",
    "    conversation_history = memory.get(\"conversation_history\", [])\n",
    "    \n",
    "    if LLM_ENABLED:\n",
    "        updated_booking = llm_extract_slots(text, current_booking, expected_slot, conversation_history)\n",
    "    else:\n",
    "        updated_booking = extract_slots_from_text(text, current_booking)\n",
    "    \n",
    "    memory[\"slots\"] = updated_booking.dict()\n",
    "    return memory\n",
    "\n",
    "print(\"‚úÖ Working Memory ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh (v·ªõi LLM integration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd7b55",
   "metadata": {},
   "source": [
    "def handle_user_message(message: str, history: List, state: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    X·ª≠ l√Ω message v·ªõi LLM-powered NLU:\n",
    "    1. Detect intent (context-aware v·ªõi LLM)\n",
    "    2. Extract slots (t·ª´ to√†n b·ªô context, kh√¥ng ch·ªâ message hi·ªán t·∫°i)\n",
    "    3. Generate natural follow-up questions (LLM)\n",
    "    4. Call Real API khi ƒë·ªß th√¥ng tin\n",
    "    \"\"\"\n",
    "    if state is None:\n",
    "        state = init_memory()\n",
    "    \n",
    "    # Update conversation history\n",
    "    state[\"conversation_history\"].append((\"user\", message))\n",
    "    \n",
    "    # 1. Detect intent (LLM context-aware)\n",
    "    if not state[\"intent\"]:\n",
    "        if LLM_ENABLED:\n",
    "            state[\"intent\"] = llm_detect_intent(message, state[\"conversation_history\"])\n",
    "        else:\n",
    "            state[\"intent\"] = detect_intent(message)\n",
    "        print(f\"üéØ Intent: {state['intent']} {'[LLM]' if LLM_ENABLED else '[Rule]'}\")\n",
    "    \n",
    "    # Handle non-booking intents\n",
    "    if state[\"intent\"] == \"cancel\":\n",
    "        msg = \"ƒê·ªÉ h·ªßy ƒë·∫∑t ph√≤ng, vui l√≤ng cung c·∫•p m√£ ƒë·∫∑t ph√≤ng c·ªßa b·∫°n (VD: BK12345678).\"\n",
    "        history.append((\"bot\", msg))\n",
    "        state[\"conversation_history\"].append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"check_booking\":\n",
    "        msg = \"ƒê·ªÉ ki·ªÉm tra ƒë·∫∑t ph√≤ng, vui l√≤ng cung c·∫•p m√£ ƒë·∫∑t ph√≤ng ho·∫∑c s·ªë ƒëi·ªán tho·∫°i ƒë√£ ƒëƒÉng k√Ω.\"\n",
    "        history.append((\"bot\", msg))\n",
    "        state[\"conversation_history\"].append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"unknown\":\n",
    "        msg = \"\"\"Xin ch√†o! üëã T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n",
    "- üè® ƒê·∫∑t ph√≤ng kh√°ch s·∫°n\n",
    "- ‚ùå H·ªßy ƒë·∫∑t ph√≤ng\n",
    "- üîç Ki·ªÉm tra th√¥ng tin ƒë·∫∑t ph√≤ng\n",
    "\n",
    "B·∫°n mu·ªën l√†m g√¨ ·∫°?\"\"\"\n",
    "        history.append((\"bot\", msg))\n",
    "        state[\"conversation_history\"].append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    # 2. Extract slots (LLM s·∫Ω xem to√†n b·ªô context)\n",
    "    state = update_memory_with_extracted(state, message)\n",
    "    booking = build_booking_object(state)\n",
    "    \n",
    "    print(f\"üìä Slots: {json.dumps({k:v for k,v in booking.dict().items() if v}, ensure_ascii=False)}\")\n",
    "    \n",
    "    # 3. Ki·ªÉm tra slot c√≤n thi·∫øu\n",
    "    missing = next_missing_slot(booking)\n",
    "    \n",
    "    if missing:\n",
    "        # Generate natural question (LLM-powered or API-based for room_type)\n",
    "        question = generate_question(\n",
    "            missing, \n",
    "            booking.dict(),\n",
    "            state[\"conversation_history\"],\n",
    "            state.get(\"asked_slots\", set())\n",
    "        )\n",
    "        \n",
    "        history.append((\"bot\", question))\n",
    "        state[\"conversation_history\"].append((\"bot\", question))\n",
    "        state[\"expected_slot\"] = missing\n",
    "        state.setdefault(\"asked_slots\", set()).add(missing)\n",
    "        state[\"last_bot_question\"] = question\n",
    "        \n",
    "        print(f\"‚ùì Asking: {missing} {'[LLM]' if LLM_ENABLED else '[Template]'}\")\n",
    "        return history, state\n",
    "    \n",
    "    # 4. ƒê·ªß th√¥ng tin ‚Üí Call Real API\n",
    "    print(\"üìû Calling Real Booking API...\")\n",
    "    api_response = call_booking_api(booking)\n",
    "    response_msg = format_booking_response(api_response, booking)\n",
    "    \n",
    "    history.append((\"bot\", response_msg))\n",
    "    state[\"conversation_history\"].append((\"bot\", response_msg))\n",
    "    \n",
    "    # Reset\n",
    "    state = init_memory()\n",
    "    print(\"‚úÖ Booking completed!\")\n",
    "    \n",
    "    return history, state\n",
    "\n",
    "print(\"‚úÖ Dialog Manager s·∫µn s√†ng (LLM-powered NLU + Real API)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8e82bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test Real API Booking Flow:\n",
      "\n",
      "1. T√¨m ph√≤ng tr·ªëng t·ª´ API...\n",
      "üîç ƒêang t√¨m ph√≤ng Standard tr·ªëng...\n",
      "üîç ƒêang t√¨m ph√≤ng Standard tr·ªëng...\n",
      "‚úÖ T√¨m th·∫•y ph√≤ng: 101 - Ph√≤ng ti√™u chu·∫©n\n",
      "\n",
      "2. Booking th√†nh c√¥ng!\n",
      "‚úÖ **ƒê·∫∑t ph√≤ng th√†nh c√¥ng!**\n",
      "\n",
      "üìã **Th√¥ng tin ƒë·∫∑t ph√≤ng:**\n",
      "- üÜî M√£ ƒë·∫∑t ph√≤ng: `BKDC6908F1`\n",
      "- üè® S·ªë ph√≤ng: **101**\n",
      "- üè∑Ô∏è Lo·∫°i ph√≤ng: **Ph√≤ng ti√™u chu·∫©n**\n",
      "- üìç ƒê·ªãa ƒëi·ªÉm: **Kh√°ch s·∫°n**\n",
      "- üìÖ Check-in: **18/10**\n",
      "- üìÖ Check-out: **20/10**\n",
      "- üåô S·ªë ƒë√™m: **2 ƒë√™m**\n",
      "- üë§ T√™n kh√°ch: **Nguy·ªÖn VƒÉn A**\n",
      "- üìû Li√™n h·ªá: **0123456789**\n",
      "- üí∞ Gi√° ph√≤ng/ƒë√™m: **800,000.0 VNƒê**\n",
      "- üíµ **T·ªïng ti·ªÅn: 1,600,000.0 VNƒê**\n",
      "\n",
      "C·∫£m ∆°n qu√Ω kh√°ch ƒë√£ s·ª≠ d·ª•ng d·ªãch v·ª•! üôè\n",
      "\n",
      "_ƒê√¢y l√† booking t·ª´ API th·ª±c: http://103.38.236.148:8080/api/Room_\n",
      "\n",
      "‚úÖ T√¨m th·∫•y ph√≤ng: 101 - Ph√≤ng ti√™u chu·∫©n\n",
      "\n",
      "2. Booking th√†nh c√¥ng!\n",
      "‚úÖ **ƒê·∫∑t ph√≤ng th√†nh c√¥ng!**\n",
      "\n",
      "üìã **Th√¥ng tin ƒë·∫∑t ph√≤ng:**\n",
      "- üÜî M√£ ƒë·∫∑t ph√≤ng: `BKDC6908F1`\n",
      "- üè® S·ªë ph√≤ng: **101**\n",
      "- üè∑Ô∏è Lo·∫°i ph√≤ng: **Ph√≤ng ti√™u chu·∫©n**\n",
      "- üìç ƒê·ªãa ƒëi·ªÉm: **Kh√°ch s·∫°n**\n",
      "- üìÖ Check-in: **18/10**\n",
      "- üìÖ Check-out: **20/10**\n",
      "- üåô S·ªë ƒë√™m: **2 ƒë√™m**\n",
      "- üë§ T√™n kh√°ch: **Nguy·ªÖn VƒÉn A**\n",
      "- üìû Li√™n h·ªá: **0123456789**\n",
      "- üí∞ Gi√° ph√≤ng/ƒë√™m: **800,000.0 VNƒê**\n",
      "- üíµ **T·ªïng ti·ªÅn: 1,600,000.0 VNƒê**\n",
      "\n",
      "C·∫£m ∆°n qu√Ω kh√°ch ƒë√£ s·ª≠ d·ª•ng d·ªãch v·ª•! üôè\n",
      "\n",
      "_ƒê√¢y l√† booking t·ª´ API th·ª±c: http://103.38.236.148:8080/api/Room_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/3171132577.py:78: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  **request.dict(),\n"
     ]
    }
   ],
   "source": [
    "def find_available_room(booking: BookingRequest) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    T√¨m ph√≤ng tr·ªëng ph√π h·ª£p t·ª´ API th·ª±c\n",
    "    \"\"\"\n",
    "    print(f\"üîç ƒêang t√¨m ph√≤ng {booking.room_type} tr·ªëng...\")\n",
    "    \n",
    "    # L·∫•y danh s√°ch ph√≤ng tr·ªëng theo lo·∫°i\n",
    "    available_rooms = api_client.get_available_rooms(room_type_name=booking.room_type)\n",
    "    \n",
    "    if not available_rooms:\n",
    "        print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ph√≤ng {booking.room_type} tr·ªëng\")\n",
    "        return None\n",
    "    \n",
    "    # Ch·ªçn ph√≤ng ƒë·∫ßu ti√™n ph√π h·ª£p\n",
    "    selected_room = available_rooms[0]\n",
    "    \n",
    "    print(f\"‚úÖ T√¨m th·∫•y ph√≤ng: {selected_room['roomNumber']} - {selected_room['roomTypeName']}\")\n",
    "    \n",
    "    return selected_room\n",
    "\n",
    "def call_booking_api(request: BookingRequest) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    G·ªçi API ƒë·ªÉ ƒë·∫∑t ph√≤ng\n",
    "    Hi·ªán t·∫°i mock v√¨ ch∆∞a c√≥ endpoint POST /api/Booking\n",
    "    \"\"\"\n",
    "    # Simulate network delay\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # T√¨m ph√≤ng tr·ªëng ph√π h·ª£p t·ª´ API th·ª±c\n",
    "    available_room = find_available_room(request)\n",
    "    \n",
    "    if not available_room:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Kh√¥ng c√≥ ph√≤ng {request.room_type} tr·ªëng\",\n",
    "            \"booking_id\": None\n",
    "        }\n",
    "    \n",
    "    # C·∫≠p nh·∫≠t th√¥ng tin ph√≤ng v√†o booking request\n",
    "    request.room_id = available_room[\"roomId\"]\n",
    "    request.room_number = available_room[\"roomNumber\"]\n",
    "    request.price_per_night = available_room[\"basePriceNight\"]\n",
    "    \n",
    "    # Generate booking ID\n",
    "    booking_id = f\"BK{uuid.uuid4().hex[:8].upper()}\"\n",
    "    \n",
    "    # TODO: Khi c√≥ API POST /api/Booking, uncomment code d∆∞·ªõi:\n",
    "    # try:\n",
    "    #     response = requests.post(\n",
    "    #         f\"{API_BASE_URL}/Booking\",\n",
    "    #         json={\n",
    "    #             \"roomId\": request.room_id,\n",
    "    #             \"guestName\": request.guest_name,\n",
    "    #             \"contact\": request.contact,\n",
    "    #             \"checkIn\": request.checkin,\n",
    "    #             \"checkOut\": request.checkout,\n",
    "    #             # ... th√™m c√°c field kh√°c theo API\n",
    "    #         }\n",
    "    #     )\n",
    "    #     response.raise_for_status()\n",
    "    #     result = response.json()\n",
    "    #     \n",
    "    #     if result.get(\"isSuccess\"):\n",
    "    #         return {\n",
    "    #             \"success\": True,\n",
    "    #             \"booking_id\": result[\"data\"][\"bookingId\"],\n",
    "    #             \"details\": result[\"data\"]\n",
    "    #         }\n",
    "    # except Exception as e:\n",
    "    #     return {\"success\": False, \"error\": str(e)}\n",
    "    \n",
    "    # Mock response (cho ƒë·∫øn khi c√≥ API POST)\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"booking_id\": booking_id,\n",
    "        \"status\": \"confirmed\",\n",
    "        \"details\": {\n",
    "            **request.dict(),\n",
    "            \"roomInfo\": {\n",
    "                \"roomNumber\": available_room[\"roomNumber\"],\n",
    "                \"roomType\": available_room[\"roomTypeName\"],\n",
    "                \"pricePerNight\": available_room[\"basePriceNight\"],\n",
    "                \"images\": available_room.get(\"images\", [])\n",
    "            }\n",
    "        },\n",
    "        \"created_at\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "def format_booking_response(api_response: Dict[str, Any], booking: BookingRequest) -> str:\n",
    "    \"\"\"\n",
    "    Format response t·ª´ API th√†nh message cho user\n",
    "    \"\"\"\n",
    "    if not api_response.get(\"success\"):\n",
    "        error_msg = api_response.get(\"error\", \"ƒê·∫∑t ph√≤ng th·∫•t b·∫°i\")\n",
    "        return f\"‚ùå **{error_msg}**\\n\\nVui l√≤ng th·ª≠ l·∫°i ho·∫∑c ch·ªçn lo·∫°i ph√≤ng kh√°c.\"\n",
    "    \n",
    "    room_info = api_response[\"details\"].get(\"roomInfo\", {})\n",
    "    price = room_info.get(\"pricePerNight\", 0)\n",
    "    \n",
    "    # T√≠nh s·ªë ƒë√™m (ƒë∆°n gi·∫£n h√≥a)\n",
    "    try:\n",
    "        # Parse dates (gi·∫£ s·ª≠ format dd/mm)\n",
    "        checkin_parts = booking.checkin.split(\"/\")\n",
    "        checkout_parts = booking.checkout.split(\"/\")\n",
    "        nights = int(checkout_parts[0]) - int(checkin_parts[0])\n",
    "        if nights <= 0:\n",
    "            nights = 1\n",
    "    except:\n",
    "        nights = 1\n",
    "    \n",
    "    total_price = price * nights\n",
    "    \n",
    "    msg = f\"\"\"‚úÖ **ƒê·∫∑t ph√≤ng th√†nh c√¥ng!**\n",
    "\n",
    "üìã **Th√¥ng tin ƒë·∫∑t ph√≤ng:**\n",
    "- üÜî M√£ ƒë·∫∑t ph√≤ng: `{api_response['booking_id']}`\n",
    "- üè® S·ªë ph√≤ng: **{booking.room_number}**\n",
    "- üè∑Ô∏è Lo·∫°i ph√≤ng: **{room_info.get('roomType', booking.room_type)}**\n",
    "- üìç ƒê·ªãa ƒëi·ªÉm: **{booking.city or 'Kh√°ch s·∫°n'}**\n",
    "- üìÖ Check-in: **{booking.checkin}**\n",
    "- üìÖ Check-out: **{booking.checkout}**\n",
    "- üåô S·ªë ƒë√™m: **{nights} ƒë√™m**\n",
    "- üë§ T√™n kh√°ch: **{booking.guest_name}**\n",
    "- üìû Li√™n h·ªá: **{booking.contact or 'Ch∆∞a cung c·∫•p'}**\n",
    "- üí∞ Gi√° ph√≤ng/ƒë√™m: **{price:,} VNƒê**\n",
    "- üíµ **T·ªïng ti·ªÅn: {total_price:,} VNƒê**\n",
    "\n",
    "C·∫£m ∆°n qu√Ω kh√°ch ƒë√£ s·ª≠ d·ª•ng d·ªãch v·ª•! üôè\n",
    "\n",
    "_ƒê√¢y l√† booking t·ª´ API th·ª±c: http://103.38.236.148:8080/api/Room_\n",
    "\"\"\"\n",
    "    return msg\n",
    "\n",
    "# Test Real API Booking Flow\n",
    "print(\"üß™ Test Real API Booking Flow:\")\n",
    "test_request = BookingRequest(\n",
    "    city=\"Kh√°ch s·∫°n\",\n",
    "    checkin=\"18/10\",\n",
    "    checkout=\"20/10\",\n",
    "    room_type=\"Standard\",\n",
    "    guest_name=\"Nguy·ªÖn VƒÉn A\",\n",
    "    contact=\"0123456789\"\n",
    ")\n",
    "\n",
    "print(\"\\n1. T√¨m ph√≤ng tr·ªëng t·ª´ API...\")\n",
    "api_result = call_booking_api(test_request)\n",
    "\n",
    "if api_result[\"success\"]:\n",
    "    print(\"\\n2. Booking th√†nh c√¥ng!\")\n",
    "    print(format_booking_response(api_result, test_request))\n",
    "else:\n",
    "    print(f\"\\n‚ùå Booking th·∫•t b·∫°i: {api_result.get('error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa88ec3",
   "metadata": {},
   "source": [
    "def user_submit(user_message: str, chat_history: List, state: Dict) -> tuple:\n",
    "    \"\"\"X·ª≠ l√Ω khi user g·ª≠i message\"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    # Th√™m message c·ªßa user v√†o history\n",
    "    chat_history.append((\"user\", user_message))\n",
    "    \n",
    "    # X·ª≠ l√Ω message\n",
    "    chat_history, state = handle_user_message(user_message, chat_history, state)\n",
    "    \n",
    "    # Convert sang format Gradio Chatbot\n",
    "    pairs = []\n",
    "    user_msg = None\n",
    "    \n",
    "    for role, text in chat_history:\n",
    "        if role == \"user\":\n",
    "            user_msg = text\n",
    "        else:\n",
    "            if user_msg is None:\n",
    "                pairs.append((\"\", text))\n",
    "            else:\n",
    "                pairs.append((user_msg, text))\n",
    "                user_msg = None\n",
    "    \n",
    "    return pairs, state\n",
    "\n",
    "\n",
    "# T·∫°o Gradio Interface\n",
    "llm_status = \"ü§ñ **LLM: Enabled** (Gemini 1.5 Flash)\" if LLM_ENABLED else \"‚ö†Ô∏è **LLM: Disabled** (Rule-based fallback)\"\n",
    "api_status = \"üîå **API: Connected**\" if test_result.get(\"success\") else \"‚ùå **API: Error**\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(f\"\"\"\n",
    "    # üè® Booking Chatbot Demo - AI-Powered\n",
    "    \n",
    "    ### Tr·∫°ng th√°i h·ªá th·ªëng:\n",
    "    {llm_status} | {api_status}\n",
    "    \n",
    "    ### Ki·∫øn tr√∫c:\n",
    "    **User** ‚Üí **LLM Intent Detector** ‚Üí **LLM Slot Extractor** ‚Üí **Working Memory** ‚Üí **Real API** ‚Üí **Response**\n",
    "    \n",
    "    **T√≠nh nƒÉng n·ªïi b·∫≠t:**\n",
    "    - üß† Hi·ªÉu ng·ªØ c·∫£nh t·ª± nhi√™n (LLM-powered)\n",
    "    - \udde3Ô∏è X·ª≠ l√Ω ng√¥n ng·ªØ ƒë√†m tho·∫°i (\"2 ƒë√™m\", \"tu·∫ßn sau\", \"std\")\n",
    "    - \udd04 Kh√¥ng b·ªã v√≤ng l·∫∑p v√¥ h·∫°n\n",
    "    - üè® T√¨m ph√≤ng tr·ªëng t·ª´ API th·ª±c\n",
    "    - üí¨ T∆∞ v·∫•n th√¥ng minh d·ª±a tr√™n d·ªØ li·ªáu th·ª±c\n",
    "    \n",
    "    **API Endpoint:** `http://103.38.236.148:8080/api/Room`\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"H·ªôi tho·∫°i\",\n",
    "        height=500,\n",
    "        show_label=True\n",
    "    )\n",
    "    \n",
    "    state = gr.State(init_memory())\n",
    "    \n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            placeholder=\"VD: M√¨nh mu·ªën ƒë·∫∑t ph√≤ng 2 ƒë√™m v√†o cu·ªëi tu·∫ßn n√†y\" if LLM_ENABLED else \"VD: T√¥i mu·ªën ƒë·∫∑t ph√≤ng Standard ng√†y 18/10 ƒë·∫øn 20/10\",\n",
    "            show_label=False,\n",
    "            scale=9\n",
    "        )\n",
    "        submit_btn = gr.Button(\"G·ª≠i\", scale=1, variant=\"primary\")\n",
    "    \n",
    "    txt.submit(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)\n",
    "    \n",
    "    submit_btn.click(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    submit_btn.click(lambda: \"\", None, txt)\n",
    "    \n",
    "    if LLM_ENABLED:\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### üí° V√≠ d·ª• h·ªôi tho·∫°i t·ª± nhi√™n (v·ªõi LLM):\n",
    "        \n",
    "        **User:** M√¨nh mu·ªën ƒë·∫∑t ph√≤ng 2 ƒë√™m  \n",
    "        **Bot:** Anh/ch·ªã mu·ªën ƒë·∫∑t t·ª´ ng√†y n√†o ·∫°?\n",
    "        \n",
    "        **User:** 18/10  \n",
    "        **Bot:** [LLM t·ª± t√≠nh] V·∫≠y l√† check-out 20/10 nh√©. Anh/ch·ªã mu·ªën lo·∫°i ph√≤ng n√†o?\n",
    "        \n",
    "        **User:** std  \n",
    "        **Bot:** [LLM hi·ªÉu \"std\" = \"Standard\"] D·∫°, em c√≥ ph√≤ng Standard t·ª´ 800k/ƒë√™m...\n",
    "        \n",
    "        **User:** ok  \n",
    "        **Bot:** Cho em xin t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng ·∫°?\n",
    "        \n",
    "        **User:** nguy·ªÖn vƒÉn a  \n",
    "        **Bot:** [LLM chu·∫©n h√≥a] D·∫°, anh Nguy·ªÖn VƒÉn A. Cho em xin s·ªë ƒëi·ªán tho·∫°i...\n",
    "        \n",
    "        **User:** 0912345678  \n",
    "        **Bot:** ‚úÖ ƒê·∫∑t th√†nh c√¥ng ph√≤ng 101 - Standard...\n",
    "        \"\"\")\n",
    "    else:\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### üí° V√≠ d·ª• (Rule-based - c·∫ßn ch√≠nh x√°c h∆°n):\n",
    "        \n",
    "        **User:** T√¥i mu·ªën ƒë·∫∑t ph√≤ng Standard  \n",
    "        **Bot:** Anh/ch·ªã mu·ªën ƒë·∫∑t ·ªü th√†nh ph·ªë n√†o ·∫°?\n",
    "        \n",
    "        **User:** Kh√°ch s·∫°n c·ªßa b·∫°n  \n",
    "        **Bot:** Ng√†y nh·∫≠n ph√≤ng l√† ng√†y n√†o ·∫°?\n",
    "        \n",
    "        **User:** 18/10  \n",
    "        **Bot:** Ng√†y tr·∫£ ph√≤ng l√† ng√†y n√†o ·∫°?\n",
    "        \n",
    "        **User:** 20/10  \n",
    "        **Bot:** Cho em xin t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng ·∫°?\n",
    "        \n",
    "        **User:** Nguy·ªÖn VƒÉn A  \n",
    "        **Bot:** Cho em xin s·ªë ƒëi·ªán tho·∫°i...\n",
    "        \n",
    "        **User:** 0912345678  \n",
    "        **Bot:** ‚úÖ ƒê·∫∑t th√†nh c√¥ng ph√≤ng 101...\n",
    "        \"\"\")\n",
    "    \n",
    "    gr.Markdown(f\"\"\"\n",
    "    ---\n",
    "    \n",
    "    ### üîß C·∫•u h√¨nh:\n",
    "    \n",
    "    **LLM Status:** {\"‚úÖ Enabled (Gemini 1.5 Flash)\" if LLM_ENABLED else \"‚ùå Disabled (c·∫ßn GEMINI_API_KEY)\"}\n",
    "    \n",
    "    {\"\" if LLM_ENABLED else '''\n",
    "    **Mu·ªën b·∫≠t LLM?**\n",
    "    1. L·∫•y API key: https://makersuite.google.com/app/apikey\n",
    "    2. Set environment: `export GEMINI_API_KEY=\"your-key\"`\n",
    "    3. Ho·∫∑c hardcode trong notebook cell\n",
    "    4. Restart kernel v√† ch·∫°y l·∫°i\n",
    "    '''}\n",
    "    \n",
    "    ### üìä So s√°nh LLM vs Rule-based:\n",
    "    \n",
    "    | T√≠nh nƒÉng | LLM (Gemini) | Rule-based |\n",
    "    |-----------|--------------|------------|\n",
    "    | Hi·ªÉu \"2 ƒë√™m\", \"tu·∫ßn sau\" | ‚úÖ | ‚ùå |\n",
    "    | Context-aware | ‚úÖ | ‚ö†Ô∏è Limited |\n",
    "    | X·ª≠ l√Ω typo, vi·∫øt t·∫Øt | ‚úÖ | ‚ùå |\n",
    "    | Chu·∫©n h√≥a t√™n | ‚úÖ | ‚ö†Ô∏è Basic |\n",
    "    | C√¢u h·ªèi t·ª± nhi√™n | ‚úÖ | ‚ùå Template |\n",
    "    | T·ªëc ƒë·ªô | ~1-2s | <0.1s |\n",
    "    | Chi ph√≠ | Free tier | Free |\n",
    "    | ƒê·ªô ch√≠nh x√°c | ~95% | ~70% |\n",
    "    \n",
    "    ### üöÄ C√¥ng ngh·ªá:\n",
    "    - ü§ñ **LLM:** Google Gemini 1.5 Flash (1M context)\n",
    "    - üîå **Backend API:** {API_BASE_URL}\n",
    "    - üé® **UI:** Gradio\n",
    "    - üì¶ **Schema:** Pydantic\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    **Made with ‚ù§Ô∏è by AI + Real API Integration**\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"‚úÖ Gradio UI s·∫µn s√†ng - LLM: {LLM_ENABLED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b474fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üß™ TEST 1: Regression - No infinite loop khi tr·∫£ l·ªùi checkout\n",
      "======================================================================\n",
      "\n",
      "--- Turn 1 ---\n",
      "User: M√¨nh mu·ªën ƒë·∫∑t ph√≤ng Standard\n",
      "üéØ Intent detected: book_room\n",
      "üìä Current slots: {\"city\": null, \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: city\n",
      "Bot: Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?...\n",
      "\n",
      "--- Turn 2 ---\n",
      "User: Kh√°ch s·∫°n c·ªßa b·∫°n\n",
      "üìä Current slots: {\"city\": null, \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: city\n",
      "Bot: Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?...\n",
      "\n",
      "--- Turn 3 ---\n",
      "User: 18/10\n",
      "üìä Current slots: {\"city\": null, \"checkin\": \"18/10\", \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: city\n",
      "Bot: Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?...\n",
      "\n",
      "--- Turn 4 ---\n",
      "User: 20/10\n",
      "üìä Current slots: {\"city\": null, \"checkin\": \"18/10\", \"checkout\": \"20/10\", \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: city\n",
      "Bot: Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?...\n",
      "\n",
      "‚úÖ PASSED: Bot chuy·ªÉn sang h·ªèi th√¥ng tin kh√°c (kh√¥ng loop)\n",
      "\n",
      "======================================================================\n",
      "üß™ TEST 2: Natural language v·ªõi LLM\n",
      "======================================================================\n",
      "‚ö†Ô∏è LLM not enabled, skipping natural language test\n",
      "\n",
      "======================================================================\n",
      "‚úÖ All tests completed!\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/618494449.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"slots\": BookingRequest().dict(),\n",
      "/tmp/ipykernel_1557/618494449.py:51: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  memory[\"slots\"] = updated_booking.dict()\n",
      "/tmp/ipykernel_1557/2048876677.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"üìä Current slots: {json.dumps(booking.dict(), ensure_ascii=False)}\")\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üß™ TEST 1: Regression - No infinite loop khi tr·∫£ l·ªùi checkout\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_state = init_memory()\n",
    "test_history = []\n",
    "\n",
    "# Conversation flow\n",
    "messages = [\n",
    "    (\"User\", \"M√¨nh mu·ªën ƒë·∫∑t ph√≤ng Standard\"),\n",
    "    (\"User\", \"Kh√°ch s·∫°n c·ªßa b·∫°n\"),\n",
    "    (\"User\", \"18/10\"),\n",
    "    (\"User\", \"20/10\"),  # ‚Üê ƒêi·ªÉm quan tr·ªçng: kh√¥ng b·ªã loop ·ªü ƒë√¢y\n",
    "]\n",
    "\n",
    "for i, (role, msg) in enumerate(messages, 1):\n",
    "    print(f\"\\n--- Turn {i} ---\")\n",
    "    print(f\"{role}: {msg}\")\n",
    "    \n",
    "    test_history.append((\"user\", msg))\n",
    "    test_history, test_state = handle_user_message(msg, test_history, test_state)\n",
    "    \n",
    "    bot_response = test_history[-1][1]\n",
    "    print(f\"Bot: {bot_response[:150]}...\")\n",
    "    \n",
    "    # Verify kh√¥ng h·ªèi l·∫°i checkout\n",
    "    if i == 4:  # Sau khi user tr·∫£ l·ªùi \"20/10\"\n",
    "        if \"tr·∫£ ph√≤ng\" in bot_response.lower() or \"checkout\" in bot_response.lower():\n",
    "            print(\"\\n‚ùå FAILED: Bot v·∫´n h·ªèi l·∫°i checkout!\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ PASSED: Bot chuy·ªÉn sang h·ªèi th√¥ng tin kh√°c (kh√¥ng loop)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ TEST 2: Natural language v·ªõi LLM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if LLM_ENABLED:\n",
    "    test_state2 = init_memory()\n",
    "    test_history2 = []\n",
    "    \n",
    "    natural_messages = [\n",
    "        (\"User\", \"ƒê·∫∑t ph√≤ng 2 ƒë√™m\"),\n",
    "        (\"User\", \"standard\"),\n",
    "        (\"User\", \"kh√°ch s·∫°n\"),\n",
    "        (\"User\", \"t·ª´ 18/10\"),\n",
    "        (\"User\", \"nguy·ªÖn vƒÉn a\"),\n",
    "        (\"User\", \"0912345678\"),\n",
    "    ]\n",
    "    \n",
    "    for i, (role, msg) in enumerate(natural_messages, 1):\n",
    "        print(f\"\\n--- Turn {i} ---\")\n",
    "        print(f\"{role}: {msg}\")\n",
    "        \n",
    "        test_history2.append((\"user\", msg))\n",
    "        test_history2, test_state2 = handle_user_message(msg, test_history2, test_state2)\n",
    "        \n",
    "        bot_response = test_history2[-1][1]\n",
    "        print(f\"Bot: {bot_response[:150]}...\")\n",
    "        \n",
    "        if i == len(natural_messages):\n",
    "            if \"‚úÖ\" in bot_response or \"th√†nh c√¥ng\" in bot_response.lower():\n",
    "                print(\"\\n‚úÖ PASSED: Booking ho√†n t·∫•t v·ªõi LLM!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è LLM not enabled, skipping natural language test\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ All tests completed!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535a6f5",
   "metadata": {},
   "source": [
    "## üß™ Test Cases - Verify No Infinite Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82610a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dialog Manager ƒë√£ s·∫µn s√†ng (v·ªõi Real API integration)\n"
     ]
    }
   ],
   "source": [
    "def handle_user_message(message: str, history: List, state: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    X·ª≠ l√Ω message t·ª´ user theo flow:\n",
    "    1. Detect intent (n·∫øu ch∆∞a c√≥)\n",
    "    2. Extract slots t·ª´ message\n",
    "    3. Ki·ªÉm tra slot c√≤n thi·∫øu\n",
    "    4. N·∫øu thi·∫øu ‚Üí h·ªèi l·∫°i\n",
    "    5. N·∫øu ƒë·ªß ‚Üí call Real API ‚Üí format response\n",
    "    \"\"\"\n",
    "    if state is None:\n",
    "        state = init_memory()\n",
    "    \n",
    "    # 1. Detect intent n·∫øu ch∆∞a c√≥\n",
    "    if not state[\"intent\"]:\n",
    "        state[\"intent\"] = detect_intent(message)\n",
    "        print(f\"üéØ Intent detected: {state['intent']}\")\n",
    "    \n",
    "    # 2. X·ª≠ l√Ω theo intent\n",
    "    if state[\"intent\"] == \"book_room\":\n",
    "        # Extract slots t·ª´ message\n",
    "        state = update_memory_with_extracted(state, message)\n",
    "        booking = build_booking_object(state)\n",
    "        \n",
    "        print(f\"üìä Current slots: {json.dumps(booking.dict(), ensure_ascii=False)}\")\n",
    "        \n",
    "        # Ki·ªÉm tra slot c√≤n thi·∫øu\n",
    "        missing = next_missing_slot(booking)\n",
    "        \n",
    "        if missing:\n",
    "            # H·ªèi l·∫°i th√¥ng tin c√≤n thi·∫øu\n",
    "            question = SLOT_QUESTIONS.get(missing, \"Vui l√≤ng cung c·∫•p th√™m th√¥ng tin.\")\n",
    "            history.append((\"bot\", question))\n",
    "            print(f\"‚ùì Asking for: {missing}\")\n",
    "            return history, state\n",
    "        \n",
    "        # ƒê√£ ƒë·ªß th√¥ng tin ‚Üí g·ªçi Real API\n",
    "        print(\"üìû Calling Real Booking API...\")\n",
    "        api_response = call_booking_api(booking)\n",
    "        \n",
    "        # Format response\n",
    "        response_msg = format_booking_response(api_response, booking)\n",
    "        history.append((\"bot\", response_msg))\n",
    "        \n",
    "        # Reset memory cho l·∫ßn booking ti·∫øp theo\n",
    "        state = init_memory()\n",
    "        print(\"‚úÖ Booking completed! Memory reset.\")\n",
    "        \n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"cancel\":\n",
    "        msg = \"ƒê·ªÉ h·ªßy ƒë·∫∑t ph√≤ng, vui l√≤ng cung c·∫•p m√£ ƒë·∫∑t ph√≤ng c·ªßa b·∫°n (VD: BK12345678).\"\n",
    "        history.append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    elif state[\"intent\"] == \"check_booking\":\n",
    "        msg = \"ƒê·ªÉ ki·ªÉm tra ƒë·∫∑t ph√≤ng, vui l√≤ng cung c·∫•p m√£ ƒë·∫∑t ph√≤ng ho·∫∑c s·ªë ƒëi·ªán tho·∫°i ƒë√£ ƒëƒÉng k√Ω.\"\n",
    "        history.append((\"bot\", msg))\n",
    "        return history, state\n",
    "    \n",
    "    else:\n",
    "        # Unknown intent\n",
    "        msg = \"\"\"Xin ch√†o! üëã T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n",
    "- üè® ƒê·∫∑t ph√≤ng kh√°ch s·∫°n\n",
    "- ‚ùå H·ªßy ƒë·∫∑t ph√≤ng\n",
    "- üîç Ki·ªÉm tra th√¥ng tin ƒë·∫∑t ph√≤ng\n",
    "\n",
    "B·∫°n mu·ªën l√†m g√¨ ·∫°?\"\"\"\n",
    "        history.append((\"bot\", msg))\n",
    "        return history, state\n",
    "\n",
    "print(\"‚úÖ Dialog Manager ƒë√£ s·∫µn s√†ng (v·ªõi Real API integration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af114ee",
   "metadata": {},
   "source": [
    "## üîü Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e85b60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gradio UI ƒë√£ s·∫µn s√†ng v·ªõi Real API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/703334404.py:46: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/tmp/ipykernel_1557/618494449.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"slots\": BookingRequest().dict(),\n"
     ]
    }
   ],
   "source": [
    "def user_submit(user_message: str, chat_history: List, state: Dict) -> tuple:\n",
    "    \"\"\"\n",
    "    X·ª≠ l√Ω khi user g·ª≠i message\n",
    "    \"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "    \n",
    "    # Th√™m message c·ªßa user v√†o history\n",
    "    chat_history.append((\"user\", user_message))\n",
    "    \n",
    "    # X·ª≠ l√Ω message\n",
    "    chat_history, state = handle_user_message(user_message, chat_history, state)\n",
    "    \n",
    "    # Convert sang format Gradio Chatbot (list of tuples)\n",
    "    pairs = []\n",
    "    user_msg = None\n",
    "    \n",
    "    for role, text in chat_history:\n",
    "        if role == \"user\":\n",
    "            user_msg = text\n",
    "        else:\n",
    "            if user_msg is None:\n",
    "                pairs.append((\"\", text))\n",
    "            else:\n",
    "                pairs.append((user_msg, text))\n",
    "                user_msg = None\n",
    "    \n",
    "    return pairs, state\n",
    "\n",
    "# T·∫°o Gradio Interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üè® Booking Chatbot Demo - Real API Integration\n",
    "    \n",
    "    ### Ki·∫øn tr√∫c: Intent Detector ‚Üí Slot Filler ‚Üí Working Memory ‚Üí **Real Booking API**\n",
    "    \n",
    "    **üîå K·∫øt n·ªëi v·ªõi API:** `http://103.38.236.148:8080/api/Room`\n",
    "    \n",
    "    **H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:**\n",
    "    - N√≥i v·ªõi bot b·∫°n mu·ªën ƒë·∫∑t ph√≤ng\n",
    "    - Bot s·∫Ω h·ªèi c√°c th√¥ng tin c·∫ßn thi·∫øt (th√†nh ph·ªë, ng√†y, lo·∫°i ph√≤ng, t√™n,...)\n",
    "    - Bot s·∫Ω **t·ª± ƒë·ªông t√¨m ph√≤ng tr·ªëng** t·ª´ API th·ª±c\n",
    "    - Khi ƒë·ªß th√¥ng tin, bot s·∫Ω ƒë·∫∑t ph√≤ng v√† tr·∫£ v·ªÅ k·∫øt qu·∫£\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"H·ªôi tho·∫°i\",\n",
    "        height=500,\n",
    "        show_label=True\n",
    "    )\n",
    "    \n",
    "    state = gr.State(init_memory())\n",
    "    \n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(\n",
    "            placeholder=\"VD: T√¥i mu·ªën ƒë·∫∑t ph√≤ng Standard ng√†y 18/10 ƒë·∫øn 20/10\",\n",
    "            show_label=False,\n",
    "            scale=9\n",
    "        )\n",
    "        submit_btn = gr.Button(\"G·ª≠i\", scale=1, variant=\"primary\")\n",
    "    \n",
    "    # Event handlers\n",
    "    txt.submit(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    txt.submit(lambda: \"\", None, txt)  # Clear textbox\n",
    "    \n",
    "    submit_btn.click(user_submit, [txt, chatbot, state], [chatbot, state])\n",
    "    submit_btn.click(lambda: \"\", None, txt)  # Clear textbox\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ### üí° V√≠ d·ª• h·ªôi tho·∫°i:\n",
    "    \n",
    "    **User:** T√¥i mu·ªën ƒë·∫∑t ph√≤ng Standard  \n",
    "    **Bot:** Anh/ch·ªã mu·ªën ƒë·∫∑t ph√≤ng ·ªü th√†nh ph·ªë n√†o ·∫°?\n",
    "    \n",
    "    **User:** Kh√°ch s·∫°n c·ªßa b·∫°n, t·ª´ 18/10 ƒë·∫øn 20/10  \n",
    "    **Bot:** Cho em xin t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng ·∫°?\n",
    "    \n",
    "    **User:** Nguy·ªÖn VƒÉn A  \n",
    "    **Bot:** Cho em xin s·ªë ƒëi·ªán tho·∫°i ho·∫∑c email...\n",
    "    \n",
    "    **User:** 0912345678  \n",
    "    **Bot:** ‚úÖ ƒê·∫∑t th√†nh c√¥ng ph√≤ng 101 - Ph√≤ng ti√™u chu·∫©n t·ª´ 18/10 ƒë·∫øn 20/10...\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ### **C√°c t√≠nh nƒÉng:**\n",
    "    - ‚úÖ Intent Detection\n",
    "    - ‚úÖ Slot Filling (Rule-based regex)\n",
    "    - ‚úÖ Working Memory\n",
    "    - ‚úÖ Multi-turn conversation\n",
    "    - ‚úÖ **Real API Integration** (t√¨m ph√≤ng tr·ªëng t·ª´ API th·ª±c)\n",
    "    - ‚úÖ Response Formatting\n",
    "    \n",
    "    ### **Lo·∫°i ph√≤ng c√≥ s·∫µn:**\n",
    "    - üè® **Standard** (Ph√≤ng ti√™u chu·∫©n): ~800,000 VNƒê/ƒë√™m\n",
    "    - üíé **VIP/Deluxe** (n·∫øu c√≥ trong h·ªá th·ªëng)\n",
    "    \n",
    "    ### **API Endpoints:**\n",
    "    - `GET /api/Room` - L·∫•y danh s√°ch ph√≤ng ‚úÖ\n",
    "    - `POST /api/Booking` - ƒê·∫∑t ph√≤ng (ƒëang mock)\n",
    "    \"\"\")\n",
    "\n",
    "print(\"‚úÖ Gradio UI ƒë√£ s·∫µn s√†ng v·ªõi Real API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302618c1",
   "metadata": {},
   "source": [
    "# ============== Test Suite: LLM vs Rule-based ==============\n",
    "print(\"üß™ Test Full Dialog Flow (LLM-powered):\\n\")\n",
    "print(f\"Mode: {'LLM (Gemini)' if LLM_ENABLED else 'Rule-based'}\\n\")\n",
    "\n",
    "# Test Case 1: Natural language with context\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 1: Natural conversation with varied input\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_state = init_memory()\n",
    "test_history = []\n",
    "\n",
    "test_turns = [\n",
    "    \"M√¨nh mu·ªën ƒë·∫∑t ph√≤ng Standard\",\n",
    "    \"·ªû kh√°ch s·∫°n c·ªßa b·∫°n\",\n",
    "    \"18 ƒë·∫øn 20 th√°ng 10\",  # Natural date range\n",
    "    \"nguy·ªÖn vƒÉn a\",        # Lowercase name\n",
    "    \"0912345678\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(test_turns, 1):\n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"User: {msg}\")\n",
    "    test_history, test_state = handle_user_message(msg, test_history, test_state)\n",
    "    bot_msg = test_history[-1][1]\n",
    "    # Truncate long responses\n",
    "    display_msg = (bot_msg[:150] + '...') if len(bot_msg) > 150 else bot_msg\n",
    "    print(f\"Bot: {display_msg}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Test 1 Complete\\n\")\n",
    "\n",
    "# Test Case 2: Single date reply (regression test for infinite loop)\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 2: Regression - Single date reply for checkout\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "state2 = init_memory()\n",
    "history2 = []\n",
    "\n",
    "steps = [\n",
    "    (\"ƒê·∫∑t ph√≤ng Standard\", \"Initial booking\"),\n",
    "    (\"Kh√°ch s·∫°n\", \"City\"),\n",
    "    (\"18/10\", \"Check-in\"),\n",
    "    (\"20/10\", \"Check-out - should NOT loop\"),\n",
    "]\n",
    "\n",
    "for msg, note in steps:\n",
    "    history2, state2 = handle_user_message(msg, history2, state2)\n",
    "    last = history2[-1][1][:100]\n",
    "    print(f\"‚Üí User: {msg} ({note})\")\n",
    "    print(f\"  Bot: {last}...\")\n",
    "\n",
    "# Verify no loop\n",
    "final_slots = state2.get(\"slots\", {})\n",
    "print(f\"\\nFinal state:\")\n",
    "print(f\"  checkin: {final_slots.get('checkin')}\")\n",
    "print(f\"  checkout: {final_slots.get('checkout')}\")\n",
    "\n",
    "if final_slots.get('checkout') == '20/10':\n",
    "    print(\"‚úÖ No infinite loop - checkout filled correctly\")\n",
    "else:\n",
    "    print(\"‚ùå Issue: checkout not filled\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ All tests complete!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df9a7577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Regression Test: Single checkout reply no loop\n",
      "\n",
      "üéØ Intent detected: book_room\n",
      "üìä Current slots: {\"city\": null, \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: city\n",
      "üìä Current slots: {\"city\": \"kh√°ch\", \"checkin\": null, \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: checkin\n",
      "üìä Current slots: {\"city\": \"kh√°ch\", \"checkin\": \"18/10\", \"checkout\": null, \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: checkout\n",
      "üìä Current slots: {\"city\": \"kh√°ch\", \"checkin\": \"18/10\", \"checkout\": \"20/10\", \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n",
      "‚ùì Asking for: guest_name\n",
      "Last bot message:\n",
      " Cho em xin t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng ·∫°?\n",
      "\n",
      "State slots:\n",
      " {\"city\": \"kh√°ch\", \"checkin\": \"18/10\", \"checkout\": \"20/10\", \"room_type\": \"Standard\", \"guest_name\": null, \"contact\": null, \"room_id\": null, \"room_number\": null, \"price_per_night\": null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1557/618494449.py:15: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"slots\": BookingRequest().dict(),\n",
      "/tmp/ipykernel_1557/618494449.py:51: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  memory[\"slots\"] = updated_booking.dict()\n",
      "/tmp/ipykernel_1557/2048876677.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"üìä Current slots: {json.dumps(booking.dict(), ensure_ascii=False)}\")\n"
     ]
    }
   ],
   "source": [
    "# Quick regression test: avoid infinite loop when answering only checkout date\n",
    "print(\"üß™ Regression Test: Single checkout reply no loop\\n\")\n",
    "state = init_memory()\n",
    "history = []\n",
    "\n",
    "# User intent to book\n",
    "history, state = handle_user_message(\"M√¨nh mu·ªën ƒë·∫∑t ph√≤ng Standard\", history, state)\n",
    "# Provide city quickly\n",
    "history, state = handle_user_message(\"·ªû kh√°ch s·∫°n\", history, state)\n",
    "# Provide checkin\n",
    "history, state = handle_user_message(\"18/10\", history, state)\n",
    "# Now bot should ask checkout; user replies with only one date\n",
    "history, state = handle_user_message(\"20/10\", history, state)\n",
    "\n",
    "# Expect next question is guest_name (not ask checkout again)\n",
    "last_bot = history[-1][1]\n",
    "print(\"Last bot message:\\n\", (last_bot[:200] + '...') if len(last_bot) > 200 else last_bot)\n",
    "\n",
    "# Ensure state shows checkout filled\n",
    "print(\"\\nState slots:\\n\", json.dumps(state[\"slots\"], ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d07af774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1760934216.124038    1557 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Google Gemini AI k·∫øt n·ªëi th√†nh c√¥ng!\n",
      "ü§ñ Model: gemini-2.0-flash (latest)\n",
      "üß™ Test response: Ch√†o b·∫°n! C√≥, t√¥i hi·ªÉu ti·∫øng Vi·ªát. B·∫°n c·∫ßn t√¥i gi√∫p g√¨ kh√¥ng?\n",
      "...\n",
      "\n",
      "üéØ LLM_ENABLED: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GOOGLE GEMINI AI CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# L·∫•y API key t·ª´: https://makersuite.google.com/app/apikey\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "\n",
    "# Ho·∫∑c hardcode (CH·ªà d√πng cho development - KH√îNG commit v√†o git)\n",
    "if not GEMINI_API_KEY:\n",
    "    GEMINI_API_KEY = \"AIzaSyBLzuTObWlZHqZMXcfEAfNb8qLwnfNk0zU\"\n",
    "\n",
    "LLM_ENABLED = False\n",
    "llm_model = None\n",
    "\n",
    "if GEMINI_API_KEY and GENAI_AVAILABLE:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        \n",
    "        # S·ª≠ d·ª•ng Gemini 2.0 Flash (free, nhanh nh·∫•t, m·ªõi nh·∫•t)\n",
    "        llm_model = genai.GenerativeModel(\n",
    "            model_name='gemini-2.0-flash',\n",
    "            generation_config={\n",
    "                \"temperature\": 0.3,  # Low temperature cho output nh·∫•t qu√°n\n",
    "                \"top_p\": 0.95,\n",
    "                \"top_k\": 40,\n",
    "                \"max_output_tokens\": 2048,\n",
    "            },\n",
    "            safety_settings=[\n",
    "                {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "                {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Test connection\n",
    "        test_response = llm_model.generate_content(\"Xin ch√†o, b·∫°n hi·ªÉu ti·∫øng Vi·ªát kh√¥ng?\")\n",
    "        LLM_ENABLED = True\n",
    "        print(\"‚úÖ Google Gemini AI k·∫øt n·ªëi th√†nh c√¥ng!\")\n",
    "        print(f\"ü§ñ Model: gemini-2.0-flash (latest)\")\n",
    "        print(f\"üß™ Test response: {test_response.text[:150]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi Gemini AI: {e}\")\n",
    "        print(\"‚ö†Ô∏è Fallback sang rule-based parsing\")\n",
    "        LLM_ENABLED = False\n",
    "else:\n",
    "    if not GEMINI_API_KEY:\n",
    "        print(\"‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh GEMINI_API_KEY\")\n",
    "        print(\"\\nüìù H∆∞·ªõng d·∫´n l·∫•y API key:\")\n",
    "        print(\"   1. Truy c·∫≠p: https://makersuite.google.com/app/apikey\")\n",
    "        print(\"   2. ƒêƒÉng nh·∫≠p Google account\")\n",
    "        print(\"   3. Click 'Create API Key'\")\n",
    "        print(\"   4. Copy key\")\n",
    "    print(\"\\n‚ö†Ô∏è H·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng rule-based parsing\")\n",
    "\n",
    "print(f\"\\nüéØ LLM_ENABLED: {LLM_ENABLED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "429dbb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM-powered Intent Detector & Slot Extractor s·∫µn s√†ng (Gemini AI)\n",
      "   Status: üü¢ ENABLED\n"
     ]
    }
   ],
   "source": [
    "def llm_detect_intent(text: str, conversation_history: List = None) -> str:\n",
    "    \"\"\"\n",
    "    S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ ph√°t hi·ªán intent v·ªõi ng·ªØ c·∫£nh h·ªôi tho·∫°i\n",
    "    Returns: 'book_room', 'cancel', 'check_booking', 'unknown'\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        print(\"‚ö†Ô∏è LLM not enabled, using rule-based fallback\")\n",
    "        text_lower = text.lower()\n",
    "        if any(k in text_lower for k in [\"ƒë·∫∑t\", \"book\", \"reserve\"]):\n",
    "            return \"book_room\"\n",
    "        elif any(k in text_lower for k in [\"h·ªßy\", \"cancel\"]):\n",
    "            return \"cancel\"\n",
    "        elif any(k in text_lower for k in [\"ki·ªÉm tra\", \"check\"]):\n",
    "            return \"check_booking\"\n",
    "        return \"unknown\"\n",
    "    \n",
    "    try:\n",
    "        # Build context\n",
    "        history_str = \"\"\n",
    "        if conversation_history and len(conversation_history) > 0:\n",
    "            history_str = \"L·ªãch s·ª≠ h·ªôi tho·∫°i:\\n\"\n",
    "            for role, msg in conversation_history[-5:]:  # Last 5 turns\n",
    "                history_str += f\"{'USER' if role == 'user' else 'BOT'}: {msg}\\n\"\n",
    "        else:\n",
    "            history_str = \"ƒê√¢y l√† tin nh·∫Øn ƒë·∫ßu ti√™n trong cu·ªôc tr√≤ chuy·ªán.\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"B·∫°n l√† tr·ª£ l√Ω AI ph√¢n t√≠ch √Ω ƒë·ªãnh kh√°ch h√†ng trong h·ªá th·ªëng ƒë·∫∑t ph√≤ng kh√°ch s·∫°n.\n",
    "\n",
    "{history_str}\n",
    "\n",
    "Tin nh·∫Øn M·ªöI NH·∫§T t·ª´ kh√°ch h√†ng:\n",
    "\"{text}\"\n",
    "\n",
    "PH√ÇN T√çCH: X√°c ƒë·ªãnh √Ω ƒë·ªãnh ch√≠nh c·ªßa tin nh·∫Øn n√†y.\n",
    "\n",
    "QUY T·∫ÆC ∆ØU TI√äN (quan tr·ªçng):\n",
    "1. N·∫øu tin nh·∫Øn ch·ª©a B·∫§T K·ª≤ th√¥ng tin ƒë·∫∑t ph√≤ng n√†o (ng√†y th√°ng, lo·∫°i ph√≤ng, ƒë·ªãa ƒëi·ªÉm, s·ªë ƒë√™m) ‚Üí \"book_room\"\n",
    "   - V√≠ d·ª•: \"Kh√°ch s·∫°n c·ªßa b·∫°n, t·ª´ 18/10 ƒë·∫øn 20/10\" ‚Üí book_room\n",
    "   - V√≠ d·ª•: \"2 ƒë√™m ·ªü ƒê√† L·∫°t\" ‚Üí book_room\n",
    "   - V√≠ d·ª•: \"Standard room\" ‚Üí book_room\n",
    "\n",
    "2. N·∫øu ƒëang trong cu·ªôc tr√≤ chuy·ªán ƒë·∫∑t ph√≤ng v√† kh√°ch ƒë∆∞a th√™m th√¥ng tin (tr·∫£ l·ªùi c√¢u h·ªèi) ‚Üí \"book_room\"\n",
    "   - Bot h·ªèi v·ªÅ ng√†y, kh√°ch tr·∫£ \"20/10\" ‚Üí book_room\n",
    "   - Bot h·ªèi v·ªÅ t√™n, kh√°ch tr·∫£ \"Nguy·ªÖn VƒÉn A\" ‚Üí book_room\n",
    "\n",
    "3. Ch·ªâ tr·∫£ \"unknown\" khi:\n",
    "   - L·ªùi ch√†o kh√¥ng li√™n quan booking: \"Xin ch√†o\", \"Hello\"\n",
    "   - C√¢u h·ªèi chung: \"Gi√° ph√≤ng bao nhi√™u?\", \"C√≥ wifi kh√¥ng?\"\n",
    "   \n",
    "4. \"cancel\" khi kh√°ch mu·ªën h·ªßy ƒë·∫∑t ph√≤ng\n",
    "5. \"check_booking\" khi kh√°ch mu·ªën ki·ªÉm tra booking ƒë√£ ƒë·∫∑t\n",
    "\n",
    "CH·ªà TR·∫¢ L·ªúI M·ªòT T·ª™ (kh√¥ng gi·∫£i th√≠ch):\n",
    "book_room\"\"\"\n",
    "\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        result = response.text.strip().lower()\n",
    "        \n",
    "        print(f\"ü§ñ Gemini Intent: '{text[:40]}...' ‚Üí {result}\")\n",
    "        \n",
    "        # Clean up response - t√¨m keyword\n",
    "        if \"book\" in result or \"book_room\" in result:\n",
    "            return \"book_room\"\n",
    "        elif \"cancel\" in result:\n",
    "            return \"cancel\"\n",
    "        elif \"check\" in result or \"check_booking\" in result:\n",
    "            return \"check_booking\"\n",
    "        elif \"unknown\" in result:\n",
    "            return \"unknown\"\n",
    "        else:\n",
    "            # Default to book_room n·∫øu kh√¥ng ch·∫Øc (v√¨ ƒë√¢y l√† app ƒë·∫∑t ph√≤ng)\n",
    "            print(f\"‚ö†Ô∏è Unclear LLM response: '{result}', defaulting to book_room\")\n",
    "            return \"book_room\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM intent detection error: {e}\")\n",
    "        # Smart fallback: n·∫øu c√≥ ng√†y th√°ng ho·∫∑c ƒë·ªãa ƒëi·ªÉm ‚Üí book_room\n",
    "        text_lower = text.lower()\n",
    "        if any(k in text_lower for k in [\"ƒë·∫∑t\", \"book\", \"reserve\"]):\n",
    "            return \"book_room\"\n",
    "        # Check c√≥ th√¥ng tin ng√†y th√°ng kh√¥ng\n",
    "        if re.search(r'\\d{1,2}[/\\-]\\d{1,2}', text):\n",
    "            return \"book_room\"\n",
    "        # Check c√≥ t·ª´ kh√≥a ƒë·ªãa ƒëi·ªÉm\n",
    "        if any(k in text_lower for k in [\"kh√°ch s·∫°n\", \"hotel\", \"ƒë√† l·∫°t\", \"h√† n·ªôi\", \"s√†i g√≤n\"]):\n",
    "            return \"book_room\"\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def llm_extract_slots(text: str, current_booking: BookingRequest, expected_slot: Optional[str] = None, conversation_history: List = None) -> BookingRequest:\n",
    "    \"\"\"\n",
    "    S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin t·ª´ c√¢u n√≥i t·ª± nhi√™n\n",
    "    Hi·ªÉu ƒë∆∞·ª£c ng·ªØ c·∫£nh: \"2 ƒë√™m\", \"tu·∫ßn sau\", \"nguy·ªÖn vƒÉn a\"...\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        # Fallback to rule-based\n",
    "        return extract_slots_from_text(text, current_booking)\n",
    "    \n",
    "    try:\n",
    "        # Build context\n",
    "        current_data = current_booking.dict()\n",
    "        filled_slots = {k: v for k, v in current_data.items() if v is not None}\n",
    "        \n",
    "        history_str = \"\"\n",
    "        if conversation_history:\n",
    "            history_str = \"L·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y:\\n\"\n",
    "            for role, msg in conversation_history[-4:]:\n",
    "                history_str += f\"{'USER' if role == 'user' else 'BOT'}: {msg}\\n\"\n",
    "        \n",
    "        expected_info = f\"\\n‚ö†Ô∏è QUAN TR·ªåNG: Bot v·ª´a h·ªèi v·ªÅ slot '{expected_slot}'. N·∫øu user tr·∫£ l·ªùi ng·∫Øn, ∆∞u ti√™n g√°n v√†o slot n√†y!\" if expected_slot else \"\"\n",
    "        \n",
    "        prompt = f\"\"\"B·∫°n l√† tr·ª£ l√Ω AI tr√≠ch xu·∫•t th√¥ng tin ƒë·∫∑t ph√≤ng kh√°ch s·∫°n.\n",
    "\n",
    "{history_str}\n",
    "\n",
    "Th√¥ng tin ƒê√É C√ì:\n",
    "{json.dumps(filled_slots, ensure_ascii=False, indent=2)}\n",
    "{expected_info}\n",
    "\n",
    "Tin nh·∫Øn M·ªöI t·ª´ kh√°ch h√†ng:\n",
    "\"{text}\"\n",
    "\n",
    "NHI·ªÜM V·ª§: Tr√≠ch xu·∫•t c√°c th√¥ng tin ƒë·∫∑t ph√≤ng (n·∫øu c√≥):\n",
    "- city: th√†nh ph·ªë/ƒë·ªãa ƒëi·ªÉm (v√≠ d·ª•: \"ƒê√† L·∫°t\", \"H√† N·ªôi\", \"Kh√°ch s·∫°n c·ªßa b·∫°n\", \"·ªü ƒë√¢y\")\n",
    "- checkin: ng√†y nh·∫≠n ph√≤ng (format dd/mm, t√≠nh t·ª´ h√¥m nay 20/10/2025)\n",
    "- checkout: ng√†y tr·∫£ ph√≤ng  \n",
    "- room_type: lo·∫°i ph√≤ng (VIP, Deluxe, Standard)\n",
    "- guest_name: t√™n ng∆∞·ªùi ƒë·∫∑t (chu·∫©n h√≥a ch·ªØ hoa: \"nguy·ªÖn vƒÉn a\" ‚Üí \"Nguy·ªÖn VƒÉn A\")\n",
    "- contact: s·ªë ƒëi·ªán tho·∫°i ho·∫∑c email\n",
    "\n",
    "L∆ØU √ù ƒê·∫∂C BI·ªÜT:\n",
    "- \"t·ª´ 18/10 ƒë·∫øn 20/10\" ‚Üí checkin=\"18/10\", checkout=\"20/10\"\n",
    "- \"18-20/10\" ‚Üí checkin=\"18/10\", checkout=\"20/10\"\n",
    "- \"2 ƒë√™m\" t·ª´ ng√†y X ‚Üí checkout = X + 2 ng√†y\n",
    "- \"Kh√°ch s·∫°n c·ªßa b·∫°n\", \"·ªü ƒë√¢y\", \"hotel\" ‚Üí city=\"Kh√°ch s·∫°n\"\n",
    "- \"std\", \"standard\", \"th∆∞·ªùng\" ‚Üí room_type=\"Standard\"\n",
    "- \"vip\", \"luxury\" ‚Üí room_type=\"VIP\"\n",
    "- N·∫øu bot h·ªèi \"{expected_slot}\" v√† user tr·∫£ l·ªùi ng·∫Øn ‚Üí ∆∞u ti√™n g√°n v√†o slot ƒë√≥\n",
    "\n",
    "TR·∫¢ L·ªúI ƒê√öNG FORMAT JSON (kh√¥ng markdown, kh√¥ng gi·∫£i th√≠ch):\n",
    "{{\n",
    "  \"city\": \"gi√° tr·ªã ho·∫∑c null\",\n",
    "  \"checkin\": \"gi√° tr·ªã ho·∫∑c null\",\n",
    "  \"checkout\": \"gi√° tr·ªã ho·∫∑c null\",\n",
    "  \"room_type\": \"gi√° tr·ªã ho·∫∑c null\",\n",
    "  \"guest_name\": \"gi√° tr·ªã ho·∫∑c null\",\n",
    "  \"contact\": \"gi√° tr·ªã ho·∫∑c null\"\n",
    "}}\"\"\"\n",
    "\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        result_text = response.text.strip()\n",
    "        \n",
    "        print(f\"ü§ñ Gemini Slots: {result_text[:100]}...\")\n",
    "        \n",
    "        # Extract JSON from response\n",
    "        if \"```json\" in result_text:\n",
    "            json_str = result_text.split(\"```json\")[1].split(\"```\")[0]\n",
    "        elif \"```\" in result_text:\n",
    "            json_str = result_text.split(\"```\")[1].split(\"```\")[0]\n",
    "        else:\n",
    "            json_str = result_text\n",
    "        \n",
    "        extracted = json.loads(json_str)\n",
    "        \n",
    "        # Update booking with extracted data\n",
    "        for key, value in extracted.items():\n",
    "            if value and value != \"null\" and hasattr(current_booking, key):\n",
    "                current_value = getattr(current_booking, key)\n",
    "                if not current_value:  # Only update if not already filled\n",
    "                    setattr(current_booking, key, value)\n",
    "        \n",
    "        print(f\"‚úÖ Extracted: {json.dumps({k:v for k,v in extracted.items() if v and v != 'null'}, ensure_ascii=False)}\")\n",
    "        \n",
    "        return current_booking\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM slot extraction error: {e}\")\n",
    "        if 'result_text' in locals():\n",
    "            print(f\"   Response: {result_text[:200]}\")\n",
    "        # Fallback to rule-based\n",
    "        return extract_slots_from_text(text, current_booking)\n",
    "\n",
    "\n",
    "print(\"‚úÖ LLM-powered Intent Detector & Slot Extractor s·∫µn s√†ng (Gemini AI)\")\n",
    "print(f\"   Status: {'üü¢ ENABLED' if LLM_ENABLED else 'üî¥ DISABLED (fallback to rules)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1635bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Question Generator s·∫µn s√†ng (LLM + API t∆∞ v·∫•n)\n"
     ]
    }
   ],
   "source": [
    "def generate_question(missing_slot: str, current_data: Dict, conversation_history: List, asked_slots: set) -> str:\n",
    "    \"\"\"\n",
    "    Sinh c√¢u h·ªèi t·ª± nhi√™n ƒë·ªÉ h·ªèi slot c√≤n thi·∫øu\n",
    "    V·ªõi LLM: c√¢u h·ªèi s·∫Ω contextual v√† t·ª± nhi√™n h∆°n\n",
    "    Kh√¥ng LLM: d√πng template c√≥ s·∫µn\n",
    "    \"\"\"\n",
    "    if not LLM_ENABLED:\n",
    "        # Fallback: template questions\n",
    "        if missing_slot == \"room_type\":\n",
    "            return consultant_room_type_prompt()  # G·ªçi h√†m t∆∞ v·∫•n t·ª´ API\n",
    "        return SLOT_QUESTIONS.get(missing_slot, \"Vui l√≤ng cung c·∫•p th√™m th√¥ng tin.\")\n",
    "    \n",
    "    try:\n",
    "        # N·∫øu l√† room_type, lu√¥n d√πng t∆∞ v·∫•n t·ª´ API\n",
    "        if missing_slot == \"room_type\":\n",
    "            return consultant_room_type_prompt()\n",
    "        \n",
    "        # Build context\n",
    "        filled = {k: v for k, v in current_data.items() if v}\n",
    "        history_str = \"\\n\".join([\n",
    "            f\"{'USER' if role == 'user' else 'BOT'}: {msg}\" \n",
    "            for role, msg in conversation_history[-3:]\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"B·∫°n l√† chatbot ƒë·∫∑t ph√≤ng kh√°ch s·∫°n th√¢n thi·ªán, chuy√™n nghi·ªáp.\n",
    "\n",
    "L·ªãch s·ª≠ h·ªôi tho·∫°i:\n",
    "{history_str}\n",
    "\n",
    "Th√¥ng tin ƒë√£ c√≥:\n",
    "{json.dumps(filled, ensure_ascii=False, indent=2)}\n",
    "\n",
    "B·∫°n c·∫ßn h·ªèi th√™m: {missing_slot}\n",
    "\n",
    "Slot meanings:\n",
    "- city: th√†nh ph·ªë/ƒë·ªãa ƒëi·ªÉm kh√°ch s·∫°n\n",
    "- checkin: ng√†y nh·∫≠n ph√≤ng\n",
    "- checkout: ng√†y tr·∫£ ph√≤ng\n",
    "- guest_name: t√™n ng∆∞·ªùi ƒë·∫∑t ph√≤ng\n",
    "- contact: s·ªë ƒëi·ªán tho·∫°i ho·∫∑c email\n",
    "\n",
    "H√£y t·∫°o M·ªòT c√¢u h·ªèi ng·∫Øn g·ªçn, t·ª± nhi√™n b·∫±ng ti·∫øng Vi·ªát ƒë·ªÉ h·ªèi th√¥ng tin \"{missing_slot}\".\n",
    "D√πng x∆∞ng h√¥ \"em\" cho bot, \"anh/ch·ªã\" cho kh√°ch.\n",
    "Kh√¥ng l·∫∑p l·∫°i th√¥ng tin ƒë√£ bi·∫øt.\n",
    "\n",
    "Ch·ªâ tr·∫£ l·ªùi c√¢u h·ªèi, KH√îNG gi·∫£i th√≠ch th√™m.\"\"\"\n",
    "\n",
    "        response = llm_model.generate_content(prompt)\n",
    "        question = response.text.strip()\n",
    "        \n",
    "        # Clean up\n",
    "        if question.startswith('\"') and question.endswith('\"'):\n",
    "            question = question[1:-1]\n",
    "        \n",
    "        return question\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM question generation error: {e}\")\n",
    "        if missing_slot == \"room_type\":\n",
    "            return consultant_room_type_prompt()\n",
    "        return SLOT_QUESTIONS.get(missing_slot, \"Vui l√≤ng cung c·∫•p th√™m th√¥ng tin.\")\n",
    "\n",
    "\n",
    "def consultant_room_type_prompt() -> str:\n",
    "    \"\"\"\n",
    "    Sinh c√¢u h·ªèi t∆∞ v·∫•n lo·∫°i ph√≤ng d·ª±a tr√™n d·ªØ li·ªáu API th·ª±c\n",
    "    G·ªçi API ƒë·ªÉ l·∫•y danh s√°ch ph√≤ng, gi√°, v√† t·∫°o g·ª£i √Ω\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = api_client.get_rooms(page_size=100)\n",
    "        if not result[\"success\"]:\n",
    "            raise RuntimeError(result.get(\"error\", \"API error\"))\n",
    "        \n",
    "        items = result[\"data\"].get(\"items\", [])\n",
    "        if not items:\n",
    "            return \"Anh/ch·ªã mu·ªën ƒë·∫∑t lo·∫°i ph√≤ng n√†o? (VIP/Deluxe/Standard)\"\n",
    "        \n",
    "        # T√≠nh gi√° min theo lo·∫°i ph√≤ng\n",
    "        prices = {}\n",
    "        for r in items:\n",
    "            name = (r.get(\"roomTypeName\") or \"\").strip()\n",
    "            price = r.get(\"basePriceNight\") or 0\n",
    "            if name and price:\n",
    "                prices[name] = min(prices.get(name, 10**12), price)\n",
    "        \n",
    "        # T·∫°o g·ª£i √Ω t∆∞ v·∫•n\n",
    "        lines = [\"Em c√≥ c√°c l·ª±a ch·ªçn sau ƒë√¢y, anh/ch·ªã th√≠ch phong c√°ch n√†o ·∫°?\"]\n",
    "        for name, p in sorted(prices.items(), key=lambda x: x[1]):\n",
    "            bullet = \"- üíé\" if any(k in name.lower() for k in [\"vip\", \"deluxe\", \"cao c·∫•p\"]) else \"- üè®\"\n",
    "            lines.append(f\"{bullet} {name}: t·ª´ {p:,} VNƒê/ƒë√™m\")\n",
    "        \n",
    "        lines.append(\"\\n(Anh/ch·ªã c√≥ th·ªÉ tr·∫£ l·ªùi: 'Standard' ho·∫∑c 'VIP' ho·∫∑c 'Deluxe')\")\n",
    "        return \"\\n\".join(lines)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è API consultant error: {e}\")\n",
    "        return \"Anh/ch·ªã mu·ªën ƒë·∫∑t lo·∫°i ph√≤ng n√†o? (VIP/Deluxe/Standard)\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Question Generator s·∫µn s√†ng (LLM + API t∆∞ v·∫•n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284acc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üß™ TEST: Gemini Intent Detection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_cases = [\n",
    "    (\"Kh√°ch s·∫°n c·ªßa b·∫°n, t·ª´ 18/10 ƒë·∫øn 20/10\", None, \"book_room\"),\n",
    "    (\"T√¥i mu·ªën ƒë·∫∑t ph√≤ng VIP\", None, \"book_room\"),\n",
    "    (\"20/10\", [(\"bot\", \"Ng√†y tr·∫£ ph√≤ng l√† ng√†y n√†o ·∫°?\")], \"book_room\"),\n",
    "    (\"Xin ch√†o\", None, \"unknown\"),\n",
    "]\n",
    "\n",
    "for text, history, expected in test_cases:\n",
    "    result = llm_detect_intent(text, history)\n",
    "    status = \"‚úÖ\" if result == expected else \"‚ùå\"\n",
    "    print(f\"{status} '{text[:40]}...' ‚Üí {result} (expected: {expected})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ TEST: Gemini Slot Extraction\")  \n",
    "print(\"=\"*70)\n",
    "\n",
    "test_booking = BookingRequest()\n",
    "text = \"Kh√°ch s·∫°n c·ªßa b·∫°n, t·ª´ 18/10 ƒë·∫øn 20/10\"\n",
    "result = llm_extract_slots(text, test_booking, None, None)\n",
    "\n",
    "print(f\"Input: '{text}'\")\n",
    "print(f\"Extracted slots:\")\n",
    "for key, value in result.dict().items():\n",
    "    if value:\n",
    "        print(f\"  - {key}: {value}\")\n",
    "\n",
    "print(\"\\n‚úÖ All Gemini tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b339bfd",
   "metadata": {},
   "source": [
    "## ‚úÖ Test Gemini Intent & Slot Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333a1ca",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ LLM-Powered Intent Detector & Slot Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e319f",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ C·∫•u h√¨nh Google Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93f814d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://ac849b4d27679614de.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "* Running on public URL: https://ac849b4d27679614de.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ac849b4d27679614de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://ac849b4d27679614de.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch Gradio app\n",
    "demo.launch(\n",
    "    share=True,  # T·∫°o public link n·∫øu ch·∫°y tr√™n Colab\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== LLM Configuration ==============\n",
    "# S·ª≠ d·ª•ng Gemini (Google) - mi·ªÖn ph√≠ v·ªõi API key\n",
    "# L·∫•y API key t·∫°i: https://makersuite.google.com/app/apikey\n",
    "\n",
    "# Option 1: Set environment variable (khuy·∫øn ngh·ªã cho production)\n",
    "# export GEMINI_API_KEY=\"your-api-key-here\"\n",
    "\n",
    "# Option 2: Hardcode (ch·ªâ d√πng ƒë·ªÉ test, kh√¥ng commit l√™n Git)\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")  # Thay b·∫±ng key c·ªßa b·∫°n n·∫øu c·∫ßn\n",
    "\n",
    "# Initialize LLM\n",
    "LLM_ENABLED = False\n",
    "llm_model = None\n",
    "\n",
    "if HAS_GEMINI and GEMINI_API_KEY:\n",
    "    try:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        llm_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        # Test connection\n",
    "        response = llm_model.generate_content(\"Hello\")\n",
    "        LLM_ENABLED = True\n",
    "        print(\"‚úÖ LLM (Gemini) ƒë√£ s·∫µn s√†ng!\")\n",
    "        print(f\"   Model: gemini-1.5-flash\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Gemini: {e}\")\n",
    "        print(\"   H·ªá th·ªëng s·∫Ω d√πng rule-based fallback\")\n",
    "else:\n",
    "    if not GEMINI_API_KEY:\n",
    "        print(\"üí° ƒê·ªÉ b·∫≠t LLM:\")\n",
    "        print(\"   1. L·∫•y API key: https://makersuite.google.com/app/apikey\")\n",
    "        print(\"   2. Set: GEMINI_API_KEY = 'your-key-here'\")\n",
    "        print(\"   3. Ch·∫°y l·∫°i cell n√†y\")\n",
    "    print(\"‚ö†Ô∏è LLM disabled - s·ª≠ d·ª•ng rule-based processing\")\n",
    "\n",
    "# Helper function cho LLM calls\n",
    "def call_llm(prompt: str, temperature: float = 0.3, max_tokens: int = 500) -> Optional[str]:\n",
    "    \"\"\"G·ªçi LLM v·ªõi prompt, tr·∫£ v·ªÅ text response\"\"\"\n",
    "    if not LLM_ENABLED or not llm_model:\n",
    "        return None\n",
    "    try:\n",
    "        response = llm_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=temperature,\n",
    "                max_output_tokens=max_tokens\n",
    "            )\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM error: {e}\")\n",
    "        return None\n",
    "\n",
    "def call_llm_json(prompt: str, temperature: float = 0.1) -> Optional[Dict]:\n",
    "    \"\"\"G·ªçi LLM v√† parse k·∫øt qu·∫£ JSON\"\"\"\n",
    "    result = call_llm(prompt, temperature=temperature)\n",
    "    if not result:\n",
    "        return None\n",
    "    try:\n",
    "        # Extract JSON t·ª´ markdown code block n·∫øu c√≥\n",
    "        if \"```json\" in result:\n",
    "            json_str = result.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in result:\n",
    "            json_str = result.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        else:\n",
    "            json_str = result.strip()\n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è JSON parse error: {e}\")\n",
    "        print(f\"   Raw response: {result[:200]}\")\n",
    "        return None\n",
    "\n",
    "print(f\"ü§ñ LLM Status: {'ENABLED' if LLM_ENABLED else 'DISABLED (using fallback)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b19689",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ C·∫•u h√¨nh LLM (Gemini/OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa604a",
   "metadata": {},
   "source": [
    "### üìä So s√°nh c·∫£i ti·∫øn\n",
    "\n",
    "| T√≠nh nƒÉng | Tr∆∞·ªõc (Rule-based) | Sau (LLM-powered) |\n",
    "|-----------|-------------------|-------------------|\n",
    "| **Intent Detection** | Keyword matching | Context-aware LLM |\n",
    "| **\"20/10\" sau h·ªèi checkout** | ‚ùå Nh·∫ßm th√†nh √Ω ƒë·ªãnh m·ªõi | ‚úÖ Hi·ªÉu l√† tr·∫£ l·ªùi |\n",
    "| **Slot Extraction** | Ch·ªâ xem c√¢u hi·ªán t·∫°i | ‚úÖ Xem to√†n b·ªô context |\n",
    "| **\"2 ƒë√™m\", \"tu·∫ßn sau\"** | ‚ùå Kh√¥ng hi·ªÉu | ‚úÖ Parse t·ª± nhi√™n |\n",
    "| **Lowercase name** | ‚ö†Ô∏è C√≥ th·ªÉ b·ªè qua | ‚úÖ Chu·∫©n h√≥a Title Case |\n",
    "| **C√¢u h·ªèi** | Fixed templates | ‚úÖ Sinh t·ª± nhi√™n theo context |\n",
    "| **T∆∞ v·∫•n room type** | Text ƒë∆°n gi·∫£n | ‚úÖ L·∫•y gi√° t·ª´ API + g·ª£i √Ω |\n",
    "| **V√≤ng l·∫∑p v√¥ h·∫°n** | ‚ö†Ô∏è C√≥ th·ªÉ x·∫£y ra | ‚úÖ Tr√°nh v·ªõi expected_slot |\n",
    "| **Hi·ªÉu typo, vi·∫øt t·∫Øt** | ‚ùå | ‚úÖ (VD: \"std\" ‚Üí Standard) |\n",
    "| **Chi ph√≠** | Free | Free (Gemini free tier) |\n",
    "| **T·ªëc ƒë·ªô** | <100ms | ~1-2s |\n",
    "\n",
    "### üîß Gi·∫£i ph√°p k·ªπ thu·∫≠t cho v·∫•n ƒë·ªÅ b·∫°n g·∫∑p:\n",
    "\n",
    "**V·∫•n ƒë·ªÅ:** V√≤ng l·∫∑p v√¥ h·∫°n khi tr·∫£ l·ªùi \"20/10\" cho c√¢u h·ªèi checkout\n",
    "\n",
    "**Nguy√™n nh√¢n c≈©:**\n",
    "- Rule-based parser ch·ªâ nh√¨n message hi·ªán t·∫°i\n",
    "- Kh√¥ng bi·∫øt bot v·ª´a h·ªèi g√¨\n",
    "- \"20/10\" ‚Üí t·ª± ƒë·ªông g√°n v√†o `checkin` n·∫øu ch∆∞a c√≥\n",
    "\n",
    "**Gi·∫£i ph√°p m·ªõi:**\n",
    "1. **Expected Slot Tracking:** Memory l∆∞u slot ƒëang h·ªèi\n",
    "2. **LLM Context-aware:** Xem to√†n b·ªô h·ªôi tho·∫°i ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh\n",
    "3. **Priority Fill:** ∆Øu ti√™n fill expected_slot tr∆∞·ªõc\n",
    "4. **Asked Slots Set:** Tr√°nh h·ªèi l·∫°i slot ƒë√£ h·ªèi\n",
    "\n",
    "**K·∫øt qu·∫£:**\n",
    "```\n",
    "Bot: Ng√†y tr·∫£ ph√≤ng l√† ng√†y n√†o ·∫°?\n",
    "User: 20/10\n",
    "‚Üí LLM hi·ªÉu: ƒë√¢y l√† tr·∫£ l·ªùi cho checkout (kh√¥ng ph·∫£i intent m·ªõi)\n",
    "‚Üí Fill checkout = 20/10\n",
    "‚Üí Chuy·ªÉn h·ªèi guest_name (KH√îNG h·ªèi l·∫°i checkout)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd634c8",
   "metadata": {},
   "source": [
    "## üîß Test Cases (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff178b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to√†n b·ªô flow v·ªõi Real API\n",
    "print(\"üß™ Test Full Dialog Flow v·ªõi Real API:\\n\")\n",
    "\n",
    "test_conversation = [\n",
    "    \"T√¥i mu·ªën ƒë·∫∑t ph√≤ng Standard\",\n",
    "    \"·ªû kh√°ch s·∫°n, t·ª´ 18/10 ƒë·∫øn 20/10\",\n",
    "    \"Nguy·ªÖn VƒÉn A\",\n",
    "    \"0912345678\"\n",
    "]\n",
    "\n",
    "test_state = init_memory()\n",
    "test_history = []\n",
    "\n",
    "for i, msg in enumerate(test_conversation, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Turn {i} - User: {msg}\")\n",
    "    test_history.append((\"user\", msg))\n",
    "    test_history, test_state = handle_user_message(msg, test_history, test_state)\n",
    "    bot_response = test_history[-1][1]\n",
    "    print(f\"\\nBot: {bot_response[:200]}...\")  # Hi·ªÉn th·ªã 200 k√Ω t·ª± ƒë·∫ßu\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\\n‚úÖ Test completed with Real API integration!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
